# 1. The Unity of Normativity

*Ralph Wedgwood*

### **Abstract and Keywords**

What is normativity? It is argued here that normativity is best understood as a property of certain concepts: normative thoughts are those involving these normative concepts; normative statements are statements that express normative thoughts; and normative facts are the facts (if such there be) that make such normative thoughts true. Many philosophers propose that there is a single basic normative concept—perhaps the concept of a reason for an action or attitude—in terms of which all other normative concepts can be defined. It is argued here that this proposal faces grave difficulties. According to a better proposal, what these normative concepts have in common is that they have a distinctive sort of conceptual role—a reasoning-guiding conceptual role. This proposal is illustrated by a number of examples: different normative concepts differ from each other in virtue of their having different conceptual roles of this reasoning-guiding kind.

Keywords: normativity, concepts, reasoning, conceptual roles, reasons

## **1.1 Senses of "Normative"**

What is normativity? How should we demarcate the domain of normative phenomena, and distinguish it from other non-normative domains? Of course, the term "normative" is a technical term; it is not in regular use by ordinary citizens on the street. So, philosophers who use the term need to make it clear in what sense they are using it. In fact, as I shall explain, not all philosophers use the term in the same sense. So, it is incumbent on me to clarify in what sense exactly I am using the term. (Since I mean to engage in a debate with other philosophers, I shall attempt to use the term in one of the senses that has become common among philosophers.)

Dictionaries define what is "normative" as what involves or pertains to a "norm." So, to understand the various technical meanings that philosophers have given to the term "normative," we may start by exploring the meanings that have been given to the word "norm."1

Philosophers seem to use the word "norm" in three main senses. In the first sense, a "norm" is something that in some way serves as a *model* or *standard*—that is, something that serves to *guide* people's thinking or behavior. The epistemologists John Pollock and Joseph Cruz (1999: 124) use the word in this sense when they speak of the "epistemic norms" that guide the processes in which we form or revise our beliefs. According to Pollock and Cruz, these "epistemic norms" are simply the procedures that we follow when thinking and reasoning competently. They explicitly compare the role that these norms play in our thinking to the role that *computer programs* play in guiding the operations of computers; and they insist that this role is crucially unlike the role played by an explicit set of rules in the thinking of a person who intentionally sets out to follow those rules.

**(p. 24)** In the second sense that is in use among philosophers, the word "norm" refers to what may be called *social norms*. Philip Pettit (1990) has proposed an illuminating definition of such social norms: a social norm is a *regularity* in the behavior of the members of a population that nearly all members of that population conform to—where this widespread conformity exists at least in part because nearly all members of the population *approve of* conforming to the regularity and *disapprove of* deviating from the regularity. This second sense of "norm" plays an important role in the branches of philosophy that describe and evaluate social institutions, such as the philosophy of law. For example, the "rules of obligation" discussed in the legal philosophy of H. L. A. Hart (1961: 85f.) seem to be social norms of this sort.

Arguably, everything that counts as a norm in the second sense must also count as a norm in the first sense too—since it is plausible that if a regularity counts as a norm in the second sense, it must also serve as a standard that in some way guides the thinking or behavior of the members of the relevant population. The phenomena that count as "norms" in at least one of these two senses seem to include: social and institutional rules—such as the rules of games, the rules that constitute legal systems, and the standards of etiquette —and publicly articulated policies and plans of various kinds, such as the rubrics of examinations; the commands of military leaders; or even a household's agreed shopping list. In recent years, these phenomena have been described as exemplifying "*formal* normativity."2

Within ethics, however, a third sense of the term "norm" has now become common. When used in this third sense, a "norm" is a *general principle* about how people *ought* to think or act—where the term "ought" is understood in a sense that makes it appropriate to voice a distinctly serious sort of *criticism* of those who fail to think or act as they ought to (this is the sense of "ought" in which it seems to be *akratic*—in a distinctive way, *irrational*—to act contrary to one's own beliefs about how one ought to act).3 It seems that this third sense of "norm" emerged from the first, since general principles about how we ought to think or act can sometimes serve to guide our thinking or behavior. We can see the emergence of this third sense where Kant (1785: 390) describes the moral law as the "guideline and supreme norm for making correct judgments about morals." Here Kant uses the word "norm" as a near-synonym for "guideline," and so he here seems to be using it in the first of the three senses that we listed above. But even though he uses the term in this first sense, he is applying the term to the *moral law*—which is a norm in the third

sense as well, since the moral law is presumably a general principle about how rational agents ought to act.

"Normativity" in this third sense is sometimes called "*robust* normativity," to distinguish it from the "formal normativity" that we have discussed earlier.4 At all events, it is in this third "robust" sense that I shall be using the term "normative" here.

## **(p. 25) 1.2 Normativity as a Feature of Concepts**

In the third sense, as I have just characterized it, a norm is a general principle about how people ought to act or to think. My formulation is deliberately ambiguous between three possible ways of interpreting what a "principle" is.

**a.** On one interpretation, a principle is a *linguistic* item, like a sentence (a string of words of a certain kind), or perhaps a speech act (such as an assertion) that is performed by uttering such a sentence in an appropriate context.

**b.** On a second interpretation, a principle is a general *fact* or *state of affairs*—the sort of item that is built up out of individuals, properties, and relations, and might make such a sentence true (relative to an appropriate context).

**c.** On a third interpretation, a principle is a *proposition* or *thought*—the sort of thing that is built up out of *concepts*, and can be the object of mental attitudes of various kinds, such as belief and the like.

In this section, I shall argue that, of these three interpretations, the third interpretation (c) is what we need to achieve an adequate understanding of normativity. In other words, normativity is fundamentally a feature of thoughts or propositions (or of the concepts that those thoughts or propositions are composed of); it is not fundamentally a feature of linguistic items like words, sentences, or speech acts, nor a feature of the constituents of the world like facts or states of affairs (or the properties and relations that those facts or states of affairs are composed of).

First, the sentences that can be used to make normative statements typically involve highly context-sensitive vocabulary. The sentence "He should be working in the library tonight" may in some contexts mean that working in the library is part of a course of action that the person in question has *overriding reason* to take; but in other contexts, it may only mean that it is *highly probable* that the person in question is working in the library. In contexts of the first sort, the sentence seems to have a normative meaning, while in contexts of the second sort its meaning is, at least arguably, non-normative. Similarly, one may say that a person is virtuous by saying that she is "good," but when one says that something is "gone for good," one is not referring to virtue, but simply saying that the thing in question is gone for evermore; again, the first utterance seems to be a normative statement, while the second seems to be a non-normative statement.

In general, the mere fact that a sentence involves terms like "should" or "good" is not enough to determine whether an utterance of the sentence on a particular occasion

counts as a normative statement or not. In general, it seems that whether or not the utterance of a sentence counts as a normative statement does not depend purely on the sentence itself; it depends on the *thought* or *proposition* that is expressed by the sentence on that occasion.

**(p. 26)** Secondly, there also seem to be problems with the view that what is fundamental to normativity is a certain family of normative *properties* or *relations*—or the normative *facts* or *states of affairs* that are built out of those normative properties and relations. For the sake of argument, let us assume that intrinsically normative states of affairs do indeed exist. Even so, the mere fact that a certain statement has a normative state of affairs as its content does not suffice to make the statement a normative statement; and the fact that a certain thought has a normative state of affairs as its content is also not enough to make it a normative thought.

The problem is that a normative state of affairs—or a normative property—could be presented in thought or in speech in the *wrong way* for the thought or statement in question to count as normative. There are various ways of arguing for this point. Some philosophers, for example, accept a *reductive naturalist* position about normativity. According to this position, the nature of each normative property can be analyzed by identifying the property with naturalistic property—that is, a property that can be picked out in wholly non-normative terms. For instance, perhaps the nature of the normative property of *acting rightly* can be analyzed by identifying it with the property of *maximizing happiness* which (let us assume) is a naturalistic property that can be picked out in wholly non-normative terms. According to this view, the state of affairs of a certain action's maximizing happiness just *is* the state of affairs of the action's being right; and so it is itself a normative state of affairs. Thus, if you state or think that an action maximizes happiness, your statement or thought has this normative state of affairs as its content. But in making this statement or having this thought, you surely need not be making any normative statement or having any normative thought.

Some philosophers may respond that this point is simply a *reductio ad absurdum* of the reductive naturalist position. But even if that position is false, it still looks as if it should be possible, at least in principle, for there to be a thought or statement that has a normative state of affairs as its content, even though the normative state of affairs is presented in the *wrong way* for it to make the thought or statement into a genuinely normative thought or statement. For example, suppose that some extraterrestrial life forms visit Earth, and begin secretly studying human beings. These extraterrestrials observe our use of the word "good," and consider various hypotheses about what property this word stands for. Eventually, these extraterrestrials introduce a word in their language, "schmood," by stipulating that it refers to that property (whatever it is) that the human word "good" stands for. Then if the extraterrestrials have a thought that they might express by describing some item as "schmood," the content of their thought is in fact the normative state of affairs that the item in question is good. However, it could be that when these aliens have this thought, it is not itself a normative thought at all.

For these reasons, then, it seems best to understand normativity as fundamentally a feature of certain *concepts*—the *normative concepts*. Normative thoughts and judgments are thoughts and judgments involving these concepts; normative statements are statements that express such normative thoughts; and normative states of affairs and normative properties and relations are the items (if such there be) that make such normative thoughts true. These normative concepts include all concepts that can be **(p. 27)** expressed by the relevant uses of terms like "ought," and all other concepts of fundamentally the same kind. The question that I shall try to answer here is what distinguishes the normative concepts from the non-normative concepts, and what all normative concepts have in common.

## **1.3 Paradigmatically Normative Concepts**

In the previous section, I suggested that the normative concepts include all concepts that can be expressed by "the relevant uses of terms like "ought". But which uses of "ought" are relevant here?

As we have already seen, it seems plausible that the term "ought" can express non-normative concepts as well as normative concepts. When we say "He ought to be working in the library tonight", we might only mean that it is highly *probable* that he is working in the library tonight. When the term is used in this way, it arguably does not express a normative concept.

The same point seems to hold even more clearly of the word "should," which in many contexts can express the same range of concepts as "ought." Here is the opening line of Rupert Brooke's poem "The Soldier":

If I should die, think only this of me: . . .

This occurrence of "should" clearly does not express a normative concept. (One reason for thinking this is that this occurrence of "should" cannot be replaced by "ought to" without radically changing the sense.) Similar points hold of the words in other languages that can express the same concepts as "should" in English.5 So which uses of "ought" do express genuinely normative concepts?

Philosophers seem to have in mind a particular way of using "ought" as the use that expresses the most *paradigmatically* normative concepts. Specifically, it seems, they are the concepts that are expressed by what I shall here call the "all-things-considered practical 'ought.' "

What exactly is this kind of "ought"? This all-things-considered "ought" is not the same as any distinctively *moral* "ought." If there is a distinctively moral "ought," judgments involving this moral "ought" would be normative or evaluative judgments of a special kind judgments based on considerations such as rights and duties, the importance of being fair and helpful toward others, and so on. But not every judgment **(p. 28)** about what one "ought" to do is a judgment of this kind. For example, if I judge that I ought to buy a new

pair of shoes, this need not be a moral judgment. I need not be violating anyone's rights, or neglecting any of my duties, or failing to be sufficiently fair or helpful toward others, if I didn't buy a new pair of shoes. Perhaps no one else would be entitled to blame me if I didn't. But it can still be true that I ought to buy a new pair of shoes.

H. A. Prichard (2002: 126) claimed that the word "ought" has at least two "totally different meanings, the one moral and the other not"—where to say in this non-moral meaning that a person "ought" to perform an action is to say that the action is "the act which will lead to the realization of his purpose." Even if Prichard's claim is true, there seems to be at least one further sense of "ought" that is neither narrowly moral nor narrowly "instrumental" in this way.

Here is an argument for this point given by Garrett Cullity and Berys Gaut (1997: 1). Consider a case where you know that you are morally required to do *X* and not *Y*, while the act that will lead to the realization of your purpose involves not doing *X* but doing *Y* instead. In this case, you might well ask yourself, "Ought I to do what I am morally required to do, *X*? Or ought I to do what will realize my purpose, *Y*?" Neither of these questions seems equivalent to the trivial question, "Ought I to do what I ought to do?" So, it seems that "ought" cannot occur here in a narrowly moral sense, or in a narrowly instrumental sense; it must be occurring in a more general normative sense.6 For this reason, a statement of the form "*A* ought to φ" need not mean either that *A* is morally required to φ, or that it would best serve *A*'s interests or purposes for *A* to φ; it can mean that *A* ought to φ *all things considered*—that is, given *all* relevant considerations (which might include both moral and non-moral considerations), *A* ought to φ.

When understood in this way, a statement of the form "*A* ought to φ" seems at least roughly equivalent to a certain interpretation of the corresponding statement "There is conclusive reason for *A* to φ" or "*A* has most reason to φ."7 When the term "reason" is used in this way, it refers to what philosophers often call "normative reasons" (or "justifying reasons"). Such normative reasons are routinely distinguished both from "pure explanatory reasons" (such as *the reason why the bridge collapsed*) and from "motivating reasons" (such as *Martin's reason for flying to Ireland on Tuesday*). A normative reason for an agent to perform a certain action, or to have a certain attitude, need not explain why the agent performs that action or has that attitude, or motivate the agent to perform the action or have the attitude; it merely in some sense *counts in favor of* or *supports* or *recommends* that action or attitude.

**(p. 29)** We may take it as our starting assumption for investigating normative concepts, then, that the paradigmatic normative concepts are the concepts expressed by occurrences of this "all-things-considered practical 'ought,' " and also by this way of talking about what there is "conclusive reason" or "most reason" for an agent to do, which seems at least roughly equivalent to the all-things-considered practical "ought." In making this assumption, we need not commit ourselves to the thesis that there is exactly one concept expressed by all occurrences of the all-things-considered practical "ought." However, many concepts are expressed by the all-things-considered practical "ought," our key

starting assumption is just that these concepts are paradigmatically normative concepts, and any concept that is of fundamentally the same kind as these paradigmatic concepts is also a normative concept.

## **1.4 The Definitional Approach**

As I have just said, the normative concepts are those that are of "fundamentally the same kind" as the paradigmatic normative concepts. But what is it for a concept to belong to this kind? What unifies all the concepts of this kind? What is it exactly that they have in common?

It might seem promising to hypothesize that there is a single basic normative concept in terms of which all other normative concepts can be defined. This could then explain what unifies all normative concepts: all normative concepts are unified by their definitional relationships to this central basic normative concept. (Alternatively, it might be thought that there is a small group of basic normative concepts—perhaps two or three such concepts in terms of which all normative concepts can be defined; then the normative concepts would be unified by their definitional relationships to this small family of basic concepts.)

For example, according to T. M. Scanlon, the basic normative concept is the concept of a *normative reason*—the concept of a consideration that counts in favor of some action or attitude. As Scanlon (2014: 2) says, he is "inclined to believe" that "reasons are fundamental" in the "sense of being the only fundamental elements of the normative domain, other normative notions such as *good* and *ought* being analyzable in terms of reasons."

Other philosophers have made other suggestions about what the central normative concept is. For example, in some of his earlier work, Allan Gibbard (1990: 36–54) explored the hypothesis that the basic normative concept is the concept of what is "rational" or "makes sense." Other philosophers, like Judith Thomson (2008), might be tempted to think that the central basic normative concepts are the notions of what it is for something to be *good* as a member of a certain *kind*.

If a philosopher claims that all normative concepts can be defined or "analyzed" in terms of a certain basic concept, we need to know exactly what sort of "definition" or "analysis" the philosopher has in mind. There are in fact many different sorts of **(p. 30)** "definition" that could be in question here. For example, ever since Aristotle (*Posterior Analytics* 93b29–94a10), philosophers have distinguished between *real* definitions and *nominal* definitions—where a nominal definition is a way of conveying the *meaning of a word* to someone who does not yet understand the word, and a real definition is a metaphysical account of the *nature* or *essence* of the kind or property that is being defined.

However, our present project is an attempt to demarcate the distinctive family of *concepts* that count as normative concepts. So the kind of definition that we need to focus on are the definitions that articulate the distinctive necessary features of the *concepts* that are being defined. The crucial difference between concepts and properties is that con

cepts are the constituents of our thoughts, while properties are exemplified by items in the world. So, if the concept in question is expressed by a predicate of the form ". . . is *F*," then the sort of definition that we need to focus on will not set out to reveal what is distinctive of the property of being *F*—that is, what it is for something in the world really to *be F*. Instead, this sort of definition needs to explain the concept—that is, to explain what it is for a thinker to *think* of something as being *F*.

However, it is also widely assumed among philosophers that a definition of the concept of being *F* will give *non-circular necessary and sufficient conditions* for being *F*. That is, in effect, the definition will imply a universally quantified biconditional of the form "For all *x, x* is *F* if and only if A(*x*)"—where the phrase "A(*x*)" does not contain any simple term the meaning of which in this context consists simply in its expressing the very concept *F* that is being defined.

How could a definition of this sort explain what it is for a thinker to think of something as *F*? Various answers to this question might be suggested here. It might be that to think of something *x* as *F* is simply to think of it as being such that A(*x*). Or it might be that the ability to think of anything as *F*—as many philosophers would put it, *possession* of the concept *F*—presupposes an implicit grasp or appreciation of this definition.

In some recent writings, the proponents of a definition or conceptual analysis have claimed that possession of the relevant concept consists in certain "judgmental and inferential dispositions," and that the definition in question in some way "summarizes" these dispositions.8 Presumably, to say that this definition "summarizes" these dispositions is to say that the judgments and inferences that manifest these dispositions are exactly the same as those that could be made on the basis of this definition. So, the claim that any particular definition "summarizes" these judgmental and inferential dispositions could only ever be justified on the basis of a precise description of these dispositions. But if we had a precise description of these dispositions, it would be this description—and not the definition—that would give the most fundamental account of what it is to possess the relevant concept. Thus, if this claim is justified, the definition has no real significance as an account of the nature of the concept—that is, of what it is for a thinker to possess the concept. For this reason, I shall assume that if a definition of the **(p. 31)** concept *F* really explains what it is for a thinker to think of things as *F*, it must be because the definition must be in some way grasped or appreciated (whether explicitly or implicitly) by anyone who possesses the concept. When a definition meets this condition, I shall say that it is a *conceptual* definition.

Given that it is a conceptual definition of this sort that is in question here, the approach that seeks to define all normative concepts in terms of a small privileged set of allegedly basic concepts faces an obvious objection. There in fact seem to be remarkably few concepts possession of which involves any kind of grasp or appreciation of a definition or analysis of the concept. Perhaps possession of certain kinship concepts, like *nephew* or *grandmother*, involves implicitly grasping certain definitions of these concepts; and perhaps there are also certain highly theoretical concepts such that everyone who possesses

these concepts must implicitly appreciate that a certain *theory* serves as an implicit definition of these concepts.

However, such cases seem to be the exception rather than the rule. In many other cases, it seems that a different sort of account of our possession of the concept is more plausible. For example, our possession of many concepts involves some kind of *recognitional* ability—that is, an ability to form justified beliefs involving the concept on the basis of sensory experience—and this sort of recognitional ability would not necessarily put us in a position to grasp any definition of the concept at all. So, prima facie, it is not clear why it should be particularly plausible that there is any definition of the allegedly non-basic normative concepts that must be grasped (whether explicitly or implicitly) by all thinkers who possess these concepts.

Admittedly, even though there are few concepts that we possess in virtue of grasping or appreciating a definition in this way, it is not implausible that there are several conceptual truths linking different normative concepts together. For example, it has seemed plausible to many philosophers that it is a conceptual truth that something is admirable if and only if there is a reason of a certain kind for admiring it.9 So perhaps, despite the initial doubts that I have just canvassed, it may in the end be defensible to claim that these conceptual truths can be used to define all the normative concepts in terms of a small number of basic concepts.

As I shall argue here, however, this approach faces grave difficulties. One problem is how to account for the basic concepts in terms of which all the others are defined. One solution to this problem suggested by the so-called classical theory of concepts would maintain our possession of such basic concepts would have to consist purely in something like *direct acquaintance* with the property or relation that the concept refers to. This may well have been the view of ethical concepts held by G. E. Moore (1903). However, few contemporary philosophers are eager to defend the idea that we have direct acquaintance with normative properties and relations. In the absence of any credible account of how we actually achieve this direct acquaintance with normative reality, **(p. 32)** this idea seems to be a pseudo-explanation—a grandiloquent relabeling of the problem rather than a solution to it.

Some philosophers seem to claim that our grasp of the most basic normative concept might be an utterly primitive phenomenon, of which no further illuminating account can be given.10 This claim is especially liable to seem plausible if it is confused with the claim that this concept itself is one that has no non-circular conceptual definition. In fact, however, the two claims need to be distinguished. A colour-concept like *red* has no non-circular conceptual definition, but it is surely still possible to give an illuminating account of what our possession of the concept consists in—in terms of our ability to form justified beliefs involving the concept on the basis of our visual experience.

In fact, the claim that our possession of a concept is an utterly primitive phenomenon seems to make the very idea of our possession of this concept deeply mysterious: according to this claim, we somehow latch onto this concept—and onto the object or property or

relation that the concept stands for—as if by magic, in a way of which no further account can be given. (It is presumably because of the mysteriousness of the idea of such an utterly primitive grasp of a concept that the classical theory of concepts resorted to the idea of direct acquaintance with the relevant object or property or relation.)

Suppose, then, that there is some way of explaining what our grasp of the allegedly basic normative concept consists in. Then we should ask: why can't we give an account of *all* normative concepts in the same way? This would in fact be the way to give the most unified account of all normative concepts—not by invidiously discriminating among these concepts, privileging some as more basic than the rest, and then defining the non-basic concepts in terms of the most basic, but by interpreting them all as concepts of the same kind, and giving the same kind of account of them all.

In recent years, one version of the definitional approach has been particularly popular. This is the "reasons first" approach, which has been defended by theorists like T. M. Scanlon (2014). According to this approach, the notion of a *normative reason* for an action or attitude is the most primitive normative concept, in terms of which all other normative notions can be defined.11 In fact, however, this approach faces a series of especially grave difficulties. One simple problem is that relatively few languages even have a word or phrase that corresponds precisely to the English word "reason." For example, ancient Greek—one of the canonical languages of Western moral philosophy—possesses no simple equivalent of this word, whereas it undoubtedly contains a rich array of words that correspond to "good," "right," "ought," and the like. In effect, the only way in ancient Greek of talking about reasons is by using explicitly explanatory terms (of which ancient Greek has many), and talking about *why* a certain action or choice is right or fine, or about *why* a virtuous agent would act as she **(p. 33)** should. This seems to make it doubtful whether the notion of a normative reason is as fundamental a concept as some theorists have proposed.

More seriously, it is doubtful whether the proponents of this definitional approach have succeeded in even identifying the basic concepts in terms of which they propose to analyze all other normative concepts. The typical procedure of these philosophers is just to start using an expression from ordinary language—such as phrases like "You have a reason to do such-and-such"—in the hope that just by using these expressions, we can all latch onto the relevant concept. But the danger is that in fact the expressions in question are context-sensitive or polysemous, and as a result express different concepts in different contexts. Philosophers may then end up equivocating, shifting back and forth between different concepts without noticing the shifts.

In fact, it seems that this is exactly the situation with the term "reason" in ordinary English. I have already suggested that there is a connection between some of the concepts that can be expressed by "reason" and some of those that can be expressed by "ought": roughly, as I proposed, one ought to φ in a given situation if and only if φ-ing is part of the response that one has overriding reason to make to that situation. But there is evidence that "ought" is a highly context-sensitive term, and expresses different (though systematically related) concepts in different contexts.

The reason for thinking that the modal terms like "ought" and "should" express different concepts in different contexts is simply that we can easily imagine a sentence involving these terms for which there are two contexts, which do not differ at all with respect to the reference of all the other terms in the sentence, such that the sentence is intuitively true in the first context and false in the second.12

For example, there are distinctively *agential* forms of "ought" and "should," which focus on the situation of a particular agent at a particular time; these are instances of what John Broome (2013: 22) calls the "owned *ought*." But there are also *non-agential* kinds of "ought" and "should," such as what might be called the " 'ought' of general desirability." This kind of "should" is illustrated by Wordsworth's poem *London 1802*, which begins with the lines:

> Milton! Thou shouldst be living at this hour: England hath need of thee . . .

In Broome's terms, this "should" is not "owned" by any particular agent: Wordsworth is definitely not asserting of any particular agent that *they* have the responsibility of bringing it about that Milton is alive in 1802; he is simply saying that in the situations that are in relevant way *most desirable*, Milton is alive in 1802.

Another distinction between different kinds of "ought" is illustrated by the phenomena that have been discussed in recent years under the heading of the "wrong kind **(p. 34)** of reason." In one sense, just as it is true to say that "You ought to be at the meeting by noon" because you have conclusive reasons to *act* in such a way as to make it the case that you are at the meeting by noon, it may also be true to say "You ought to believe that there is a largest prime number" if you have conclusive reasons to *act* in such a way that there is a largest prime number (perhaps because a demon has threatened to destroy the world unless you believe this). Even if, in this sense, it is true that you ought to believe that there is a largest prime number, there also seems to be another sense in which—because the proposition that there is a largest prime number is provably false—it is *not* true that you ought to believe this.

Finally, it also seems that there are both *objective* and *subjective* forms of "ought." For example, what you in an objective sense "ought" to do in a given situation may depend on facts that you are not even in a position to know in that situation, while what you in a more subjective sense "ought" to do is determined by facts that are in some way accessible to you within the situation in question.

Given the connections that I have proposed between "ought" and "reasons," it seems plausible that the term "reason" will be polysemous or context-sensitive in many if not all of the same ways as "ought": so, it seems, there are not just normative reasons, but objec tive and subjective normative reasons, theoretical and practical reasons, and no doubt more kinds of reasons besides.

In this way, it seems to me, the proponents of the "reasons first" approach have not succeeded in identifying any special central sense of "reason." Moreover, even if they have identified such a special sense of "reason," it seems at best arbitrary to claim that this sense of "reason" is basic, and all the rest are derivative. Indeed, discriminating invidiously among the concepts that can be expressed by these terms seems to be worse than merely arbitrary: it seems positively implausible, because the different concepts all seem to be parallel in a way.

In what way exactly do these concepts seem to be parallel? One obvious similarity is the fact that they can all so easily be expressed by the same term—while ordinary speakers never have the impression, in using these terms to express these concepts, that they are really using two different terms that are alike in sound, but differ in meaning (as "bank" in English means both *river bank* and *money bank*). Indeed, it seems that a number of philosophers have failed to distinguish between these different normative concepts.13 It seems to me that the best explanation of why these philosophers have failed to notice the distinctions between these concepts is that they are all concepts of fundamentally the same kind, forming a tightly interconnected family of concepts. This seems much more plausible than that these philosophers have somehow failed to distinguish between one of the privileged basic concepts and the other non-basic concepts.

**(p. 35)** For these reasons, I suggest that the definitional approach, which aims to explain what unifies all normative concepts by finding a single central basic concept (or a small set of two or three such concepts), in terms of which all other concepts can be defined, faces grave difficulties. In the rest of this chapter, I shall explore a different approach.

## **1.5 The Conceptual Role Approach**

According to the approach that I wish to explore, the distinguishing feature of normative concepts is their distinctive *conceptual role*. The basic idea is one that has become familiar—the idea that at least some normative concepts have a distinctive "action-guiding" conceptual role. This is the idea that I shall try to develop here.

This idea has been particularly prominent in the work of expressivists and non-cognitivists. By "expressivists," I mean theorists who deny that it is an explanatory fundamental feature of normative statements that they play any sort of representational or referential role, and instead claim that the meaning of these statements is to be explained in terms of the mental states that are "expressed" by means of these statements. By "noncognitivists," I mean theorists who deny that the mental states expressed by normative statements are fundamentally of the same kind as ordinary beliefs, and instead claim that they are in some way distinctively non-cognitive mental states, such as intentions or desires or emotions or the like.

In fact, I believe that the basic idea that normative concepts are distinguished by their action-guiding role is not committed to any such expressivist or non-cognitivist approach. On the contrary, my own view is that we can combine this basic idea with a resolutely representationalist and cognitivist approach. Specifically, my view is that it is precisely this action-guiding conceptual role of normative concepts that determines what property or relation these normative concepts represent or refer to, and that in consequence there is no difficulty with identifying the mental state that is expressed by normative statements with a perfectly ordinary state of belief.14

For the purposes of the present discussion, however, we can leave this issue to one side, without taking sides in the debates between expressivists and representationalists, and between cognitivists and non-cognitivists. I shall simply outline a way of interpreting normative concepts that is inspired by this idea that they have a distinctive action-guiding role, without addressing the question of whether or not this approach is best developed within an expressivist or non-cognitivist framework.

On the face of it, however, this approach faces some challenging problems. One problem is that we apply normative concepts, not only to available courses of action, but more broadly to all sorts of performances, ways of thinking, and states of affairs. For example, when Wordsworth proclaims that Milton should be alive in 1802, he is not **(p. 36)** claiming that any *action* should be performed that would bring it about that Milton is alive in 1802.

A natural solution to this challenge is to broaden the basic idea so that it claims, not that all normative concepts are action-guiding, but that they are "reasoning-guiding." Perhaps, Wordsworth's view that Milton should be alive in 1802 guides him, not necessarily toward action, but at least toward a kind of *attitude*—the attitude of regarding it as part of the *most desirable* imaginable states of affairs that Milton is alive in 1802. However, this solution runs into a second problem.

This second problem is just that it is not clear whether there are any concepts that are not in some sense "reasoning-guiding." For example, from the premise "It is necessary that *p*" we can infer *p*. So why isn't the concept of necessity just as "reasoning-guiding" as any of the normative concepts—in the sense that the premise "It is necessary that *p*" "guides us" toward having a certain *attitude* toward the conclusion *p*?

To solve these problems, we will need to articulate a sense in which normative concepts are "reasoning-guiding" that is broad enough to include all normative concepts, but narrow enough to exclude intuitively non-normative concepts (like the concept of *necessity*). This is what I shall attempt to do in the next two sections.

## **1.6 "Reasoning-Guiding" Conceptual Roles: The General Idea**

In this section, I shall explain how we can generalize the idea of the "action-guiding" character of some normative concepts so that it can cover all normative concepts. In particular, I shall generalize the traditional idea of "action-guiding" concepts in three ways.

The first way in which I propose to generalize the idea that normative concepts are essentially "action-guiding" is something that I have already suggested. Strictly speaking, even if some normative concepts are essentially "action-guiding," it seems that these concepts would have to guide action by means of guiding the agent's *intentions*. Since the kind of reasoning in which we form and revise our intentions is known as "practical reasoning," the idea that some normative concepts are essentially action-guiding implies that these normative concepts have a guiding role in *practical reasoning*. So, a natural way to generalize this idea is to shift from focusing narrowly on practical reasoning to focusing on reasoning in general. In short, we should shift from the idea that normative concepts are action-guiding to the idea that they are reasoning-guiding.

This suggests that one way in which different normative concepts differ from each other is in the kind of reasoning within which they have a guiding role. Different kinds of reasoning can be distinguished by the different kinds of attitudes that can be formed by means of these kinds of reasoning: for example, intentions are formed by means of practical reasoning, beliefs by means of theoretical reasoning, and so on.

**(p. 37)** More specifically, I propose that every atomic proposition involving a normative concept in effect focuses on what I shall call a *reasoning problem*. 15 In general, we can think of each reasoning problem as consisting of (a) a kind of attitude and (b) a set of alternative possible objects for that attitude. I shall assume here that the kind of attitude (a) that features in the reasoning problem is fixed by the particular normative concept in question, but the set of alternative possible objects for the attitude (b) must be picked out by some other constituent of the normative proposition. In effect, every thinker who entertains such a normative proposition must, in doing so, also consider or think about some such set of alternative possible objects for the relevant attitude.

For example, every atomic proposition involving an all-things-considered practical "ought" focuses on a *practical* reasoning problem—the problem of deciding what to do in a certain situation. Each practical reasoning problem can be thought of as consisting of (a) the attitude of *intention* and (b) a set of *alternative courses of action*, each of which might be an object of intention. In effect, every such set of alternative courses of action specifies an agent and a situation—specifically, the situation in which those courses of action are available to the agent. (So, in effect, some atomic propositions involving the practical "ought" focus on the situation that you are in right now, while others focus on the situation that Socrates was in during his trial in 399 BC; and so on.)

Atomic propositions involving other kinds of "ought" focus on reasoning problems of other kinds. For example, atomic propositions involving a *theoretical* "ought" focus on a theoretical reasoning problem—the problem of what to *believe* about a certain question. Propositions involving the "ought" of *general desirability* focus on reasoning problems that concern what states of affairs to welcome or to *regard as most desirable*. In similar ways, propositions involving other normative concepts may focus on other kinds of reasoning problems.16

The second way in which I propose to generalize the idea that normative concepts are distinguished by their action-guiding role is designed to capture the difference between the more "objective" and the more "subjective" occurrences of normative concepts. Here we need the idea of what we might call an *epistemic perspective.* Each such epistemic perspective can be thought of as consisting in a certain set of propositions, and a set of possible beliefs or other doxastic attitudes toward those propositions. Every atomic proposition involving a normative concept refers at least implicitly to such an epistemic perspective. I shall assume here that (as with the set of alternatives that we have just discussed) this epistemic perspective is not fixed by the particular normative concept **(p. 38)** that is involved, but is instead referred to by some other constituent of the normative proposition.

It seems to be possible for thinkers to consider perspectives other than those that they currently occupy. (Indeed, it is plausible that this is one of the functions of so-called "indicative conditionals" in natural language, to consider the epistemic perspective that would result from updating the perspective that would otherwise be salient in the conversational context on the assumption that the conditional's antecedent is true.) In effect, then, according to the proposal that I am making here, entertaining an atomic normative proposition involves considering or thinking about such an epistemic perspective.

This enables us to characterize the difference between the "objective" occurrences of normative concepts and more "subjective" occurrences. Propositions involving "objective" occurrences of normative concepts refer to the *omniscient* perspective—a perspective that involves complete confidence in every truth and complete disbelief in every falsehood. By contrast, propositions involving the more "subjective" occurrences of normative concepts refer to non-omniscient epistemic perspectives—such as perspectives that are characterized by a significant degree of ignorance and uncertainty about the relevant questions.

I have proposed that each of these epistemic perspectives consists in a set of propositions and in a possible system of beliefs or doxastic attitudes toward those propositions. So, one feature of each of these perspectives is a certain role that is played within this system of beliefs and attitudes by the particular normative concept in question—the propositions involving this normative concept that are included, and the belief-like attitudes that the perspective includes toward those normative propositions.

The third way in which I shall generalize the idea that normative concepts are distinguished by their action-guiding role is by allowing for a range of different *kinds of guidance*, as I shall put it, that these concepts may provide. Formally, we may think of each kind of guidance as a *function* from the epistemic perspective (and in particular from the role that the normative concept plays in that perspective) to a certain *response* to the reasoning problem.

For instance, in some cases, in the content of the normative belief that forms part of the relevant epistemic perspective, the relevant normative concept is applied to a *member* of the set of alternatives that forms part of the reasoning problem. In these cases, the normative belief guides the reasoner toward having some kind of *attitude* toward that member of the relevant set of alternatives. For example, the content of the belief might be "I ought to buy a new pair of shoes," in which case the belief guides the reasoner toward having an *intention* to buy a new pair of shoes.

In other cases, in the content of the normative belief, the normative concept is applied to a proposition that concerns the reasoner's *attitudes* toward members of this set of alternatives. In these cases, the belief guides the reasoner toward directly *realizing* the proposition in question. For example, the belief might be "I ought to choose to buy a new pair of shoes," in which case the thought may guide the reasoner directly toward *choosing* to buy a new pair of shoes (and not toward having an intention to choose to buy a new pair of shoes).

**(p. 39)** A further difference among these kinds of guidance will account for the distinctions between (a) concepts of the sort that can be expressed by deontic modal terms like "ought" and "should," (b) value-concepts—of the sort that can be expressed by evaluative terms like "good," "better," "worse," and so on—and (c) other normative concepts, such as the concepts that can be expressed by talking about "reasons" in favor of various actions or attitudes, and the like.

In general, it seems plausible that the ways of using a concept that feature in the concept's essential conceptual role must all be *rational* ways of using the concept.17 So the ways in which, according to the concept's distinctive conceptual role, the concept guides the reasoner toward responding to the relevant reasoning problem, relative to the relevant epistemic perspective, must all be ways in which it is rational for the reasoner to respond to that reasoning problem, relative to that epistemic perspective. The guidance that each normative concept provides is a kind of rational guidance for responding to the relevant reasoning problem, relative to the relevant epistemic perspective.

Unfortunately, without more specific information about these "kinds of guidance," this characterization is not sufficient to distinguish normative concepts from non-normative concepts. Presumably, whenever we do reasoning of any kind, we respond to some reasoning problem in the light of an epistemic perspective. So we have not yet distinguished the distinctive way in which normative concepts are "reasoning-guiding" from the way in which all concepts are reasoning-guiding. In the next section, I shall propose a more specific account of normative concepts. Inevitably, this account will have several controver

sial implications—and unfortunately, I will not be able to defend these controversial implications here. Still, I hope that this proposal will at least illuminate the kind of theory that could be developed.

## **1.7 A Probabilistic Conception of Rationality**

One well-known and influential conception of rationality is essentially *probabilistic*. According to this conception, the relevant epistemic perspectives can be modeled by means of probability functions. (To simplify matters, let us assume that each of the relevant epistemic perspectives can be modeled by a *unique* probability function.) Together with a value of some kind, a probability function can be used to define a notion of *expected value*. According to this probabilistic conception of rationality, rational reasoning is always guided by some kind of expected value. In this section, I shall propose an interpretation of normative concepts that is designed to fit with this probabilistic conception of rationality.

**(p. 40)** Specifically, according to this conception of rationality, for every reasoning problem, and for every epistemic perspective, there is a certain kind of *value* such that a rational reasoner's response to that problem, relative to that epistemic perspective, is guided by the kind of expected value that is defined in terms of that value and the probability function that models that perspective. More precisely, for every reasoning problem and every epistemic perspective, there are *two* such kinds of expected value defined in terms of the probability function that models that epistemic perspective: the first kind of expected value is exemplified by the *attitudes* that constitute possible answers to that reasoning problem, and the second kind of expected value is exemplified by the *objects* of these attitudes that constitute possible answers to that problem.18

For example, when the reasoning problem in question is a problem of practical reasoning, the first kind of expected value would be exemplified by the possible *choices* or *intentions* that the agent might make in the situation in question—while the second kind of expected value would be exemplified by the *acts* or *courses of action* that are the objects of these possible choices. The former value is a feature of the possible choices—the degree to which those choices are *correct* or *appropriate* or *rational* or the like; the latter value, on the other hand, is a feature of the available acts that might be chosen—the degree to which those acts are *feasible and choiceworthy* or *good things to do*. To simplify our discussion, however, I shall ignore this first kind of value, and focus only on the second kind of value, which is exemplified by the *objects* of the attitudes that count as possible answers to the reasoning problem.

Within this approach, it is easiest to start with an account of evaluative concepts—that is, of the concepts that can be expressed by terms like "good," "bad," "better," "worse," and so on—specifically, of the concepts that stand for values that are exemplified by the alternatives that are the objects of the possible attitudes that would count as answers to the relevant reasoning problem. I shall comment later on how this approach could be extended to cover the other normative concepts.

According to my proposal, each value-concept is tied to a certain kind of reasoning problem, and every atomic proposition involving this concept refers, at least implicitly, to a set of alternatives and an epistemic perspective. The essential conceptual role of the valueconcept consists in the way in which, relative to this set of alternatives and this epistemic perspective, the rational reasoner is guided in her responses to the reasoning problem by the relevant kind of expected value.

A more precise definition of the notion of expected value can be given in the following way. We must also assume that the propositions that this probability function is defined over include propositions that involve normative concepts. In particular, these propositions include hypotheses involving the evaluative concept in question, about the *degree* to which the alternatives in question exemplify the relevant value.19 **(p. 41)** Certain hypotheses of this form will constitute a *partition*—a set of hypotheses such that (according to the probability function) it is certain that exactly one member of this set is true. The expected value of each of these alternatives is the probability-weighted sum of the degrees of value that the alternative has according to these hypotheses, weighting each of these degrees of value by the probability of the hypothesis that the alternative will have that degree of value.

Specifically, the way in which the rational reasoner is guided by this kind of expected value has two aspects. First, the rational response (relative to this epistemic perspective) involves having attitudes that constitute a kind of *ranking* of the relevant alternatives, corresponding to the ranking of these alternatives in terms of expected value. For example, in some cases, this response involves a set of *preferences* of some kind that ranks these alternatives in terms of this kind of expected value. Secondly, the rational response will not only involve a ranking of this sort, but also (relative to this epistemic perspective) having one of the attitudes that counts as a possible *answer* to the reasoning problem: specifically, it will have involve having one of the attitudes the object of which is ranked as *optimal*, out of those that are regarded within the reasoning problem as available.

For example, the concept of *being a good thing to do, all things considered* is tied to a *practical* reasoning problem. With such practical reasoning problems, the rational response (relative to the epistemic perspective in question) will involve having the attitude of *intending* one of the courses of action that is ranked as optimal (out of the relevant set of alternatives).20

In this account, the conceptual role of each normative concept does not just involve its conceptual role in relation to the epistemic perspective that the agent actually occupies. It involves its conceptual role in relation to any epistemic perspective that the agent can think about. Of course, if the reasoner does not actually occupy an epistemic perspective, but only considers or thinks about that perspective, then the kind of expected value defined by the probability function that models that perspective will only guide the reasoner toward a sort of *conditional* response to the reasoning problem. For example, she will not have an unconditional intention to take one of the courses of action that counts as optimal in terms of this kind of expected value; she will only have a sort of conditional **(p. 42)**

intention to take such a course of action—conditional on the assumption of this epistemic perspective.

On this approach, then, the essential conceptual role of the concept consists of a *general* role that the concept plays in relation to *any* epistemic perspectives that we can think about in the right way. This feature of the approach enables it to explain how we can understand normative propositions that refer to (or quantify over) any such epistemic perspectives whatsoever. This is how the approach gives a unified account of both "objective" and "subjective" occurrences of normative concepts.21 On this approach, they are occurrences of the very same concept, relativized to different epistemic perspectives: "objective" occurrences involve the normative concept's being relativized to the omniscient epistemic perspective, while a more "subjective" occurrence involves the normative concept's being relativized to a non-omniscient epistemic perspective, which incorporates some degree of uncertainty and ignorance about the relevant questions.

According to my proposal, then, this is, in general, the distinctive conceptual role of the normative concepts that stand for the kinds of value that are exemplified the alternatives that are the objects of the attitudes that are possible answers to the underlying reasoning problem. As mentioned above, these concepts can be expressed by evaluative terms like "good" and "better" and the like.

The simplest way of characterizing the conceptual role of other normative concepts will be in terms of their inferential relations to these evaluative concepts. For example, the normative concepts that can be expressed by "ought" and "should" may all just be in effect notions of what is *necessary* for what is *optimal* in terms of such a value (out of the relevant range of alternatives). There will be many different concepts of this kind, depending on the different sort of "optimality" and "necessity" that is involved.

The distinctive conceptual role of the concepts that are expressed by terms such as "reason" or the like can be characterized in such a way as to make these concepts in effect into notions of factors that play a certain kind of *explanatory* role in relation to certain facts concerning these values. This may either be the explanatory role of contributing toward making it the case that some item exemplifies a value to some degree, or it may be the explanatory role of being a factor that a good reasoner would respond to in reasoning well. These—I propose—are the concepts that can be expressed by speaking of normative reasons for actions or attitudes.22 In this way, we can sketch an account of the distinctive conceptual roles of all normative concepts, in terms of this probabilistic conception of rationality.

As I have mentioned already, this account of normative concepts will be undeniably controversial. There are several reasons for this. One way in which this account is controversial is that it incorporates a maximizing and possibilist conception of the concepts that are expressed by deontic modal terms like "ought." This is the interpretation of **(p. 43)** "ought" as what is (in the relevant way) necessary for what is (in the relevant way) optimal. This approach need not take evaluative notions to be "prior to" the concepts that can be expressed by "ought" (there is, for example, no suggestion that anyone could possess

the relevant value-concepts without also being capable of deploying the kind of concepts that are expressed by "ought"). Nonetheless, on this approach, evaluative notions have a big role in explaining the concepts that are expressed by "ought."

Some philosophers might think that for these reasons, this account of normative concepts is committed to a questionable kind of "consequentialism" or "teleology" about "ought." In my view, this is a mistaken interpretation of this account. The account has nowhere used the notion of the "consequences" of any item, nor has the account anywhere committed itself to the principle that the fundamental bearers of value are whole possible worlds, while other items have value only insofar as they in some way promote or raise the chances of such possible worlds. On the contrary, the account presupposes that the relevant values are directly instantiated by the relevant alternatives themselves (not just by their "consequences"). In addition, the relevant kind of value can also be both agentand time-relative; it does not have to be the kind of agent-neutral value that has typically been invoked by consequentialists in ethics. Much more needs to be said to give an illuminating explanation of why this account is not committed to controversial forms of consequentialism. But the features of the account just highlighted should provide the beginnings of such an explanation.

As it has been stated so far, this account also assumes that every sort of value comes in "degrees" that can be measured on an interval scale. This assumption is undoubtedly controversial, but fortunately, it seems possible to relax this assumption. We need only assume that the epistemic perspective's degrees of belief in hypotheses about the value in question define *some* kind of expected value. It may be that strictly speaking, there is no unique real-valued expected value function that guides the rational reasoner, but only a looser collection of facts about this sort of expected value. Formally, we could model this looser collection of facts by means of a *set* of real-valued functions of the kind that I have described—the set of real-valued functions that are compatible with everything that is represented in the epistemic perspective itself. This should make it less controversial to claim that the distinctive conceptual role of these value-concepts is to guide the reasoner by means of a kind of expected value.

Finally, a further way in which this account is controversial is that, strictly speaking, it is inconsistent with the classical version of decision theory. According to orthodox decision theory, rational preferences and choices are guided by expected *utility*, where the notion of utility is meant to be, not a normative or evaluative concept of any kind, but a purely psychological concept—a measure of subjective preference. Expected utility is not defined in the way in which I have defined expected value—in terms of degrees of belief in hypotheses about utility itself. On the contrary, it is defined in terms of degrees of belief about propositions of other kinds, together with the agent's degrees of subjective preference for those propositions.23

**(p. 44)** In fact, this classical version of decision theory faces a number of grave difficulties. Why should my subjective preferences have that kind of authority over me? Why shouldn't I sometimes resist these preferences, and follow what I believe to be best in

stead? These problems do not arise for the suggestion that a rational agent is guided by her attitudes toward propositions that involve a normative concept like an appropriate concept of what is "best"; unlike with a purely psychological concept such as "utility," it is built into the very nature of such a normative concept that it is what has the relevant sort of authority over the agent. In short, once we consider the suggestion that rational choices are guided by our attitudes toward propositions involving such normative concepts, this suggestion may seem more plausible than the classical theory that rational choice is guided by expected utility.

## **1.8 Conclusion**

The account of normative concepts that I sketched in the previous section is undoubtedly controversial. But it would have some advantages: in particular, it could give a unified account of normative concepts, as the concepts that play a reasoning-guiding role of a certain distinctive kind in rational reasoning.

Other philosophers may reject this probabilistic conception of rational reasoning. But if they have any definite conception of rational reasoning, they should be able to characterize a kind of "guidance" that will make it seem plausible (at least to adherents of that conception of rationality) that the distinctive conceptual role of normative concepts is to provide rational guidance of that sort. So in this way, my proposal that normative concepts are reasoning-guiding concepts could in principle be detached from this probabilistic framework and developed in a different way. In light of the difficulties that I canvassed in the first half of this chapter for other attempts to give a precise general characterization of the domain of the normative, the thought that they are in some special way essentially reasoning-guiding concepts still seems like the most promising line of investigation to pursue.

## **References**

Broome, John (2013). *Rationality through Reasoning*. Oxford: Wiley-Blackwell.

Cullity, Garrett, and Berys Gaut (eds) (1997). *Ethics and Practical Reason*. Oxford: Clarendon Press.

**(p. 45)** Finlay, Stephen (2014). *Confusion of Tongues: A Theory of Normative Language*. New York: Oxford University Press.

Finlay, Stephen (forthcoming). "Defining Normativity." In David Plunkett, Scott Shapiro, and Kevin Toh (eds), *Dimensions of Normativity: New Essays on Metaethics and Jurisprudence*. Oxford: Oxford University Press.

Gibbard, Allan (1990). *Wise Choices, Apt Feelings*. Oxford: Clarendon Press.

Hart, H. L. A. (1961). *The Concept of Law*. Oxford: Oxford University Press.

Kant, Immanuel (1785). *Grundlegung zur Metaphysik der Sitten* [Groundwork of the Metaphysics of Morals]. Repr. in Royal Prussian Academy of Sciences (ed.), *Gesammelte Schriften*, vol. 4, 385–464 (Berlin: Reimer, 1903).

McPherson, Tristram (2011). "Against Quietist Normative Realism." *Philosophical Studies* 154(2): 223–40.

Moore, G. E. (1903). *Principia Ethica*. Cambridge: Cambridge University Press.

Parfit, Derek (2011). *On What Matters*, vol. 2. Oxford: Oxford University Press.

Pettit, Philip (1990). "*Virtus Normativa*: Rational Choice Perspectives." *Ethics* 100: 725– 55.

Pollock, John, and Cruz, Joseph (1999). *Contemporary Theories of Knowledge*, 2nd edn. Totowa, NJ: Rowman & Littlefield.

Prichard, H. A. (2002). *Moral Writings*, ed. J. MacAdam. Oxford: Clarendon Press.

Railton, Peter (1999). "Normative Force and Normative Freedom: Hume and Kant, but Not Hume *versus* Kant." *Ratio* 12: 320–53.

Scanlon, T. M. (1998). *What We Owe to Each Other*. Cambridge, Mass.: Harvard University Press.

Scanlon, T. M. (2014). *Being Realistic about Reasons*. Oxford: Oxford University Press.

Sidgwick, Henry (1907). *The Methods of Ethics*, 7th edn. London: Macmillan.

Smith, Michael (1994). *The Moral Problem*. Oxford: Blackwell.

Thomson, Judith (2008). *Normativity*. Chicago: Open Court.

Wedgwood, Ralph (2001). "Conceptual Role Semantics for Moral Terms." *Philosophical Review* 110(1): 1–30.

Wedgwood, Ralph (2006). "The Meaning of 'Ought'." In Russ Shafer-Landau (ed.), *Oxford Studies in Metaethics*, vol. 1, 127–60. Oxford: Oxford University Press.

Wedgwood, Ralph (2007). *The Nature of Normativity*. Oxford: Clarendon Press.

Wedgwood, Ralph (2009). "The 'Good' and the 'Right' Revisited." *Philosophical Perspectives* 23: 499–519.

Wedgwood, Ralph (2017). *The Value of Rationality*. Oxford: Oxford University Press.

## **Notes:**

[^1]: For some illuminating comments on the origins of the word "norm," see Railton (1999: 321).

[^2]: The terminology of "formal normativity" was introduced by McPherson (2011: §3).

[^3]: One early occurrence of this third sense in English is in the work of Henry Sidgwick (1907: 398).

[^4]: For an illuminating discussion of "robust normativity," see esp. Finlay (forthcoming).

[^5]: For example, consider the use of the German word *sollte* in the last two lines of Goethe's play *Torquato Tasso*: "*So klammert sich der Schiffer endlich noch / Am Felsen fest, an dem er scheitern sollte*." Here *sollte* clearly means something like "was likely to."

[^6]: Admittedly this argument is not uncontroversial. In particular, Finlay (2014: 150–75) would object to this argument. Unfortunately, I do not have time to address Finlay's objections here.

[^7]: I say "roughly equivalent" because, strictly speaking, I think that *A* ought, in this sense, to φ whenever φ-ing is *part* of what *A* has most reason to do—while it is not clear that *A* always has most reason to φ whenever φ-ing is part of what *A* has most reason to do. But this complication does not matter for our present purposes.

[^8]: For a clear example of this approach, see Smith (1994: 30).

[^9]: This is the central claim of the "fitting attitude analysis" of value (also known as the "buck-passing" account); see Scanlon (1998: 97).

[^10]: See e.g. Scanlon (2014: 2) and Parfit (2011: 272).

[^11]: For a more extended argument against the "reasons fundamentalist" approach of philosophers like Scanlon, see Wedgwood (2017: ch. 4).

[^12]: For a more extended discussion of the different concepts that can be expressed by "ought," see Wedgwood (2007: sect. 5.1).

[^13]: For some philosophers who claim (implausibly as it seems to me) that "ought" is not polysemous or context-sensitive in these ways, see Broome (2013: 12–25), who seems to think that there is just one kind of "owned 'ought,' " and Thomson (2008: 207–31), who seems to think that there is only one kind of normative "ought."

[^14]: See Wedgwood (2001, 2006, 2007: ch. 4).

[^15]: I say "every atomic proposition" because logically complex normative propositions may in effect *quantify* over such reasoning problems, instead of referring to any particular problem.

[^16]: I believe that this approach can be extended to the "purpose-relative 'ought' " that we find in such statements as "He ought to use a Phillips screwdriver to open that safe." Here the decision problem is *how (best) to open the safe*; the attitude defining the decision problem is an attitude of *conditional intention*—intending a course of action *as* a means of opening the safe, *conditionally* on the hypothesized intention of opening the safe; the relevant possible objects of this attitude are the various courses of action available to the relevant agent at the relevant time. (Many philosophers would interpret this kind of "ought" as exemplifying merely "*formal* normativity," but it is not obvious to me that interpretation is correct.)

[^17]: For more on this general approach to giving an account of the nature of a concept, see Wedgwood (2007: ch. 4).

[^18]: For a brief discussion of the distinction between these two kinds of normative concepts, see Wedgwood (2009: 508 and 516).

[^19]: If every atomic normative proposition refers, at least implicitly, to an epistemic perspective, we need to specify which perspectives are referred to in the normative propositions that themselves form part of the content of that epistemic perspective. The simplest approach is to suppose that it is always the *omniscient* perspective—which is modeled by the probability function that assigns 1 to every truth and 0 to every falsehood. In a sense, then, every epistemic perspective involves speculating, with greater or lesser degrees of confidence, about what the omniscient perspective would be. (It is possible to generalize the approach further, but I shall not attempt at this point to explain all the technicalities that would be involved.)

[^20]: As I suggested in n. 16, the purpose-relative normative concepts—like the concept of *being a good way of opening the safe*—is tied to a kind of purpose-relative reasoning problem—reasoning about how best to achieve the relevant end *E* (conditionally on the hypothesized intention of achieving *E*). Otherwise, however, *mutatis mutandis*, it seems that the account of these purpose-relative normative concepts can parallel the account that I have just suggested for the all-things-considered practical normative concepts.

[^21]: I now believe that this approach is preferable to the one that I took in my earlier work (Wedgwood 2007: sect. 5.2)

[^22]: See Wedgwood (2017: ch. 4) for a more extensive discussion of how to interpret the concepts that can be expressed by the term "reason."

[^23]: Here is a further objection: it may seem that rational believers are guided by their expectations of the *truth-values* of the propositions that are the objects of their belief, and one might wonder whether the concept of truth—a normative notion. But perhaps it is not implausible that there is a normative notion of truth—a notion of the feature of a proposition that makes it objectively correct to believe it—and that this is the notion that we would possess in virtue of our ability to be guided in our beliefs by expectations of truthvalues.

---

# 2. The Unity of Reasons

*Mark Schroeder* 

### **Abstract and Keywords**

This chapter is concerned with the question of what unifies reasons for action and reasons for belief, sometimes called practical and epistemic reasons. According to some views, reasons for belief are a special case of reasons to do something, and so epistemic reasons are a special case, very broadly speaking, of practical reasons. According to other views, reasons for action are a special case of reasons to draw some conclusion, and so practical reasons are a special case of epistemic reasons. This chapter considers some of the evidence that bears on whether either of these claims is correct, or whether instead practical and epistemic reasons have something else in common.

Keywords: reasons, epistemic, practical, John Horty, default logic

*Over the last three quarters of a century, reasons have come to occupy a prominent and central place in the normative study of action, belief, intention, and the emotions. According to some, reasons are the key element that is distinctive of normativity itself.1 In this chapter I will be concerned with the question of what unifies reasons for action and reasons for belief, sometimes called *practical* and *epistemic* reasons. If it is true that reasons are the key element that is distinctive of normativity itself, then my question is the question of what unifies normativity itself. But even if this grandiose claim on behalf of the centrality of reasons is false, and reasons are just one normative relation among others, my question is still interesting in its own right. And as we will see in what follows, it is closely related to many other interesting and important questions.

## **2.1 General Preliminaries**

When I ask what is unified about reasons for action and reasons for belief, here is what I have in mind. The question that I will be interested in can be put intuitively, but not quite accurately, as the question of whether reasons for belief are just a special case of reasons for action, reasons for action are just a special case of reasons for belief, or neither. This way of putting my question makes intuitive sense, because it frames my question as one of priority, and questions of priority are familiar to philosophers. But **(p. 47)** it is not quite

accurate, because the two things whose priority I am interested in are not exactly belief and action.

The first priority view in which I will be interested is motivated by the thought that a reason to listen more carefully and a reason to believe that Beatrice will show up tomorrow are both reasons to *do* things, in some very broad sense of "do." On this broad sense of "do," anything that can be expressed by a verb phrase is something that you can do. After all, "listen more carefully" and "believe that Beatrice will show up tomorrow" are both verb phrases, and verb phrases correspond, intuitively, to things that you do, in some very loose sense. So it is natural to think that what unifies reasons for action and reasons for belief is that they are both reasons to do things. On this view, what makes reasons for action and reasons for belief different is precisely that actions and beliefs are different sorts of things that you can do. I will describe this view, somewhat inaccurately, as the view that reasons for belief reduce to reasons for action, or the *practical priority thesis*, for short. This isn't exactly accurate, of course, because the view does not hold that beliefs are actions; but the view does hold that all reasons are reasons to *do* things, in some broad sense, and that that is the source of what they have in common. But it is a *close* gloss, because whereas philosophers always think about reasons for action as reasons to do things, this is something that we often forget or ignore when thinking about reasons for belief.

Reasons for belief are in general reasons to believe *something—*some proposition. So, for example, while a reason to believe that Beatrice will show up tomorrow is, along one dimension, a consideration that supports a state of mind, *believing that Beatrice will show up tomorrow*, it is also, along another dimension, a consideration that supports a certain *content—that Beatrice will show up tomorrow*. So when we think about reasons for belief, it is natural to think of them as supporting, not something that we *do*, but rather a *proposition—*the thing *believed*. The second priority view in which I will be interested is the thesis that reasons for *action* are all really a special case of reasons in support of propositions (as the objects of belief). On the version of this view that will occupy me in what follows, a reason to listen more carefully is a reason in support of the proposition that *you ought to listen more carefully*. Or, put more intuitively but less precisely, it is a reason to believe that you ought to listen more carefully. Since this view treats reasons to act in various ways as reasons to believe that you ought to act in those ways, it is naturally (though not quite accurately) described as the view that reasons for action reduce to reasons for belief—or the *epistemic priority thesis*, for short.

So in what follows, I will be interested in whether what reasons for action and reasons for belief have in common is that both are cases of reasons to *do* things*—*to act versus to believe*—*or whether both are reasons in support of *conclusions—*propositions that can be believed, of which one interesting special case comprises propositions about what one ought to do. As we will see in what follows, part of the interest in asking our question in this way is that there are some striking apparent parallels between how reasons for ac

tion compete with one another*—*parallels that challenge *both* priority theses, in very similar ways.

## **(p. 48) 2.2 Further Qualifications: Belief First**

According to some people, there are reasons for belief that do not, intuitively, support the content that is to be believed in the way that other reasons for belief support the content that is to be believed. For example, Pascal famously argued that we should each believe in God on decision-theoretic grounds.2 If Pascal's argument gives us any reason to believe in God, it is not a reason that does so by intuitively supporting the conclusion that God exists. So, clearly, the view that I have described according to which reasons for action reduce to reasons for belief must be understood as excluding reasons like Pascal's. It is not enough to have a reason to listen more carefully for there to be a decision-theoretic argument that it is advisable for you to believe that you ought to listen more carefully. There must actually be a reason that supports (in whatever way reasons support conclusions) the conclusion that you ought to listen more carefully.3

The view that I am interested in, on which reasons for action reduce to reasons for belief, is very similar, if not quite identical, to the view that reasons for action are just evidence that one ought to act.4 These views are similar, because once we exclude Pascalian considerations and other putative reasons for belief that do not support the proposition that is to be believed, it is natural to think that what is left is *evidence*. On this natural view, the way in which reasons support propositions is precisely by being evidence for them; and so in reducing all reasons to the way in which reasons for belief support propositions, we are really reducing them to evidence. Consequently, many of the advantages of or obstacles for the thesis of *reasons as evidence* will be advantages of or obstacles to the thesis that reasons for action and reasons for belief are unified through reasons for belief. Because others have written about both these advantages and these costs, I will not rehearse most of them here.5

However, I will mention a few considerations that I think are important. Reasons to act in some way*—*say, to listen more carefully*—*need to compete against contrary reasons. The very feature of reasons that has led them to occupy so much attention in normative disciplines over the last three quarters of a century is precisely that they compete in this way. Among the reasons with which your reason to listen more carefully will compete, of course, will be reasons for you to not listen more carefully. And so if your reasons to listen more carefully are all reasons to believe that you ought to listen more carefully, then your reasons to not listen more carefully will all be reasons to **(p. 49)** believe that you ought to not listen more carefully. But now note that when comparing reasons, we normally presume that if your reasons to do something outweigh the reasons not to do it, then that is what you ought to do. So now it seems to follow that if your reasons to believe that you ought to listen more carefully outweigh your reasons to believe that you ought to not listen more carefully, then it is true that you ought to listen more carefully.

But so far from being guaranteed to be true, I think that this is clearly false. It may not even be true that you ought to *believe* that you ought to listen more carefully; for though your reasons to believe this outweigh your reasons to believe *one* alternative proposition —namely that you ought to not listen more carefully—there are other possibilities, including that it is indifferent whether you listen more carefully or do not. And even when your reasons to believe are evenly matched with your reasons to believe contrary propositions, you still may not be rationally permitted to believe, because it may be best to remain agnostic. So the thesis that reasons for action reduce to reasons for belief raises troubling consequences if we assume that facts about the weight of reasons for action can be read off of facts about the weight of reasons to believe.

There is a second reason why I am inclined to be skeptical of the idea that reasons for action can be construed as reasons in support of the conclusion that one ought to act. It is that there are more options, when it comes to belief, than there are possible conclusions. For every conclusion, there is the option of believing it. But there is also the option of remaining agnostic. If we hold that all reasons support conclusions, then we leave this option out of those which are supported by reasons. This doesn't show that the answer to what we ought to believe cannot be read off of the reasons in support of all of the other options*—*the ones that are a matter of believing some conclusion. But it makes me deeply suspicious.6

Finally, due to familiar considerations about the *de se*, even if it is true that reasons to act are always reasons to believe that you ought to act in that way, it is still not likely that reasons to believe that you ought to act in some way are all reasons to act in that way. When John Perry sees the shopper trailing sugar around the grocery store, he acquires a reason to believe that he ought to stop his cart and close the leak.7 But it does not seem that he has yet acquired a reason to stop his cart and close the leak*—*his reasons need to support believing *de se* of himself that he ought to stop his cart and close the leak.

In what follows, I'll assume that these and other apparent obstacles for the thesis that reasons for action reduce to reasons for belief may be easily patched. This is because I'll be interested in a more general kind of problem for the kind of unity of reasons conferred by *either* of the priority theses that I've been considering.

## **(p. 50) 2.3 Case Study: Horty on Reasons as Defaults**

In his elegant and insightful book, *Reasons as Defaults*, Jeff Horty presents a sophisticated system for thinking about how reasons work together to determine what an agent ought to do or believe. Horty's system has a combination of features which make it particularly apt for use as a case study in investigating our question: it is precise, tractable, and is used by Horty to make predictions both about reasons for action and about reasons for belief. It is the most precise and well-worked-out view about how reasons combine to determine what we ought to do or to believe, and several of the structural features that it

encodes are independently plausible. We can therefore use Horty's framework in order to draw out the consequences of those independently plausible structural features for our priority question, and the same will apply for other frameworks that succeed at encoding the same structural features.

The way that Horty's system works is that it employs a particular system of default logic, which is used under a pair of interpretations to tell us about how reasons combine to determine what we ought to do or believe. The uninterpreted default logic is just a formal system that can be thought of as generating, for any given set of defaults and background information, one or more of what are called "extensions." So ignoring the role of the background information, the uninterpreted system looks like the following:

|  | の、 |  |
|--|----|--|

Horty goes on to offer two distinct interpretations of this system, each of which takes it to tell us something about reasons. On the first interpretation*—*the *epistemic* interpretation *—*we interpret the set of defaults as telling us something about what *contents* are supported by reasons, and we interpret the extensions as telling us something about what to believe. And on the second interpretation*—*the *practical* interpretation*—*we interpret the set of defaults as telling us something about what *actions*, or more generally what things we might *do*, are supported by reasons, and we interpret the extensions as telling us something about what we ought to do. So Horty's idea is that the very same "gray arrow" of default logic can adequately represent both how reasons supporting contents determine what to believe and how reasons to do things support what to do:

![](_page_61_Figure_5.jpeg)

**(p. 51)** It is an immediate consequence of these dual intended interpretations of Horty's system that it makes for a highly natural way to test the question of which, if either, of our two priority theses is true. Since his system tells us, on the practical interpretation, how reasons to do things determine what we ought to do, and it also tells us, on the epistemic interpretation, how reasons for conclusions tell us what we may believe, either priority thesis is compatible with Horty's full picture only if adding it to the picture preserves conclusions about what an agent ought to do or to believe.

In other words, the "priority of reasons for action" thesis can be true only if we get the same conclusions as to what an agent ought to believe if we first characterize reasons for belief as reasons to do something and then work our default logic under its "action" interpretation, as if we work our default logic directly under its "epistemic" interpretation:

| "Epistemic" defaults |  | What to believe |
|----------------------|--|-----------------|
|                      |  |                 |
| "Practical" defaults |  | What to do      |

Likewise, the "priority of reasons for belief" thesis can be true only if we get the same conclusions as to what an agent ought to do if we first characterize reasons for action as reasons in favor of the conclusion that one ought so to act, and then work our default logic under its "epistemic" interpretation, as if we work our default logic directly under its "action" interpretation, so that the answer to what an agent ought to do is the same as the answer to what she may believe that she ought to do.

![](_page_62_Figure_3.jpeg)

Horty himself briefly considers the question as to whether reasons for conclusions or reasons to do things are prior, and explicitly opts for neutrality:

The account set out here is intended to be independent of any of these theses, or others, concerning the relation between practical and epistemic reasons; it can be adapted, I believe, to accommodate a variety of positions on the topic. (2012: 18)

But whether Horty's account is genuinely neutral on this question will depend on whether each of the competing positions can be successfully formulated within his system, rather than on his explicit aims. And the only way to evaluate this is to check for ourselves. Fortunately, doing so will be highly instructive about some general problems for either of the kinds of unity that our priority theses offer.

**(p. 52)** In order to evaluate this question, we need to understand at least a little bit about how Horty's system works. Its main idea, as I noted, is to use a kind of prioritized default logic in order to represent reasons and determine what an agent ought to do, or what conclusions she may draw from her existing information. The original idea of default logic was to capture defeasible inference by adding to deductive logic a set of "default" inferences*—*inference rules that can be followed by default, but which may be defeasible in different ways. The structure of a default logic works by telling us which of these default rules of inference are to be followed in a given situation, and hence what an agent may defeasibly conclude, given her hard information. The set of propositions which the agent may conclude was originally referred to as an *extension*, because it defeasibly extends the hard information with which she begins. This traditional interpretation of default logic is the epistemic interpretation, because it characterizes the *contents* of the beliefs the agent

is permitted, or ought, to form on the basis of default rules which characterize those contents.

What Horty observed is that we can use the same kind of formal system to represent, not which conclusions an agent ought to believe, but which actions she ought to perform. As before, we work with a set of hard background information and a set of default rules; but instead of thinking of the rules as telling us which propositions the agent may conclude, by default, on the basis of her existing information, we think of them as telling us what things the agent ought, by default, to do on the basis of her existing information.8 And then we interpret the *extensions* that are determined by the logic as telling us which things the agent ought to do. This is the practical or action interpretation of the same system.

It is a key feature of Horty's treatment—and a symptom of an important and system-independent general fact that will be of great importance for us later—that the very same system of default logic yields plausible conclusions about what an agent ought to believe under the epistemic interpretation, and also yields plausible conclusions about what an agent ought to do under the practical interpretation. I'll illustrate this in a moment, and later we will return to see how this reflects independent parallels between how epistemic and practical reasons compete. But first we need to get just a glimpse of how the mechanics of Horty's default logic work, because that is necessary in order to see why it yields the conclusions that it does.

## **2.4 Horty's Default Logic**

The most important concept in the framework is that of a *scenario*. Formally, scenarios are just sets of default rules, but intuitively, we are to think of them as candidates for **(p. 53)** the rules which are currently active in deliberation. Given a fixed body of background information and a strict partial ordering among a background set of default rules (which intuitively tell us which reasons are weightier), only some possible scenarios fit intuitive criteria to be *appropriately* active in deliberation—and these Horty calls "proper." Proper scenarios do not include default rules whose conclusions conflict with the background information (this prevents the system from telling you to believe something you know to be false, or to do something you know that you will not do) or with the conclusions of defaults with a higher priority (this restricts us to paying attention to the weightiest reasons), and they do not include default rules that do not apply (are not *triggered*, as Horty says) given the existing information. *Reasons* are then defined relative to a scenario, as the premises of defaults that are triggered in that scenario. Given this definition, what the restrictions on "proper" scenarios are really telling us, intuitively, is that the "proper" scenarios are the sets of defaults that are candidates to represent all of the reasons in some situation that are not outweighed. The basic formal structure of the system is then completed, by using proper scenarios to define the all-important notion of an *extension*. An *extension* is just the logical closure of the conclusions of a proper scenario, together with the background information.

We can illustrate the framework with a simple, abstract example, which will come in handy later. Suppose that we have the default rules δ = A→C, δ = B→~C, and δ = C→D, of which δ has the highest priority, and that our background information includes both A and B. Any subset of {δ ,δ ,δ } will be a scenario—a candidate for the active rules in deliberation—but only one of these is *proper*, {δ ,δ }. δ must be included in a proper scenario, because it is triggered by our background information and its conclusion doesn't conflict either with our background information or with the conclusion of any default of a higher priority. But by including δ , we add C to our information, and that triggers δ . So δ must be included as well. But δ can't be included, because it is defeated by the higherpriority δ . Our background information is {A,B} and C and D are the conclusions of {δ ,δ }. So the only extension that we get is the logical closure of {A,B,C,D}. 1 2 3 1 1 2 3 1 3 1 1 3 3 2 1 1 3

On the original, epistemic interpretation of default logic, extensions were so named because they were thought of as possible consistent ways of extending the background information by default reasoning. On this interpretation, we could think of A as the proposition that Alice said that C, B as the proposition that Bob said that ~C, and C as the proposition that Caroline said that D, where the priority of δ over the other defaults represents the fact that Alice is a more reliable source of testimony than the others. In that case, the framework tells us that it is reasonable, if we know both A and B, to conclude both that Caroline said that D and that D is true. This makes sense. 1

We can also give this very same example a practical interpretation. This time, let A be the proposition that Alice told you to pick up Caroline after school, B the proposition that Bob told you not to, C the proposition that you pick up Caroline after school, and D the proposition that you drive to the school. Now the default rules are interpreted as **(p. 54)** telling us that Alice's and Bob's instructions both provide you with reasons to act, though Alice's instructions have higher priority, and if you're picking up Caroline, that's a reason to drive. Under this interpretation, the system tells us that what you ought to do is to both pick up Caroline and drive. Again, this makes sense.9

## **2.5 Conflicts and Chaining**

As we've seen, Horty's way of thinking about how reasons support conclusions works by interpreting the very same underlying logical system in two different ways—really, at two different *levels*. When we want to think about what you ought to *do*, we interpret the defaults as having conclusions that are propositions about what you do, and we interpret the resulting extensions as including propositions that *are* what you ought to do. In our example, we have a default whose conclusion is the proposition that you pick up Caroline after school; and that conclusion gets into our extension, so we conclude that you ought to pick up Caroline after school. In contrast, when we want to think about what you ought to *believe*, we don't interpret defaults as having conclusions that are propositions about what you believe. Instead, we think of defaults as having conclusions that are possible *contents* you might believe. And we interpret the resulting extensions not as telling us what you believe, but as giving us the *contents* that you may believe.

We've also seen that despite the fact that these interpretations work on different levels, each yields intuitively plausible results. This is because there are striking parallels between how reasons for action and reasons for belief behave, but these parallels occur at different levels. Let's take these parallels one at a time, just focusing on those that are exhibited by our example. The first parallel concerns when reasons come into *conflict*. With respect to reasons for action, reasons engender a conflict, either directly or indirectly, when they support incompatible things you might *do*. For example, Alice's request and Bob's request come into conflict, because Alice asks you to pick up Caroline, and Bob asks you not to. Since you can't both pick up Caroline and not do so, that puts these reasons into competition with one another, so that only the better one wins out. Similarly, if Ryan has a reason to visit his father in the hospital, because he is sick, and a reason not to buy a plane ticket, because it is expensive, these reasons can come into conflict if the only way to visit his father is to buy a plane ticket.10 When the only way to visit his father is to buy a plane ticket, visiting his father and not buying a plane ticket are incompatible. That is why these reasons come into conflict, and so he should do only what is supported by the better reason.

**(p. 55)** Reasons for belief also generate conflicts in the face of incompatibility. But in this case, it is incompatibility of the *contents* of the beliefs that matters, not incompatibility in *having* the beliefs. If P and Q cannot both be true, or are guaranteed by your background knowledge to not both be true, then any reasons you have to believe P will compete with reasons you have to believe Q, and you should only believe what is better supported by reasons. But just because you *cannot* both believe P and believe Q, it does not obviously follow that these are not both things that you should believe. Similarly, if you can only believe P if you believe Q, it does not follow that reasons to believe P must compete against reasons against believing Q. So reasons for belief compete on the basis of incompatibility, just as reasons for action do; but it seems to be the incompatibility of their *contents* that matters, not the incompatibility of the beliefs themselves. This supports Horty's strategy of dealing with each in parallel.

This parallel in how reasons conflict is exhibited in the schematic example that I've used. On both the epistemic and practical interpretations, the defaults A→C and A→~C come into conflict, and so no stable scenario includes both—only whichever has higher priority. But our schematic example also illustrates a second plausible parallel between the belief and action cases. That is because in our example, when we have the default A→C in a stable scenario, we also get the default C→D in that scenario, provided that it is not conflicted or defeated. We may call this phenomenon *chaining*. What chaining tells us, very roughly speaking, in the epistemic case, is that when you are confronted with Alice's and Bob's testimony, you should conclude both that Caroline said that D *and that D*. Without chaining, we would only get the result that you should conclude that Caroline said that D. We might still be able to say that once you conclude *that*, you should be able to conclude that D; but chaining allows us to say that you may already draw that conclusion.11

Similarly, chaining at the level of action tells us that when you are confronted with Alice's and Bob's instructions, what you should do is both pick up Caroline and drive. Without chaining, we only get the conclusion that you should pick up Caroline. We would still be able to say that once you pick up Caroline, you ought to drive, but chaining allows us to say that this is already what you should be doing. Again, we have an intuitive parallel phenomenon, which arises at the level of what you *do* in the case of action, but at the level of the *content* of your belief, in the case of belief, rather than at the level of what you are doing, in having that belief. Again, this both supports and explains the plausibility of Horty's two-level approach, and suggests that the features that motivate his approach must have parallels even in alternative views that differ substantially in detail. So plausibly, whatever conclusions we can draw from considering Horty's approach will have analogues for other theories.

## **(p. 56) 2.6 Testing Our Priority Theses**

The point of introducing Horty's system, recall, was as an illustrative case study in the defensibility of each of the priority theses that we have been considering, among which Horty explicitly desires to remain neutral. According to the epistemic priority thesis, what appear to be reasons to do things really need to be understood as reasons in support of the proposition that you ought to do those things. And so, for this thesis to be correct, there must be a way of translating practical default rules into epistemic default rules.

Since the epistemic priority thesis says that reasons to act are reasons in support of the proposition that you ought to act, the obvious way to interpret this translation is as holding that each practical default rule, R→A, representing a possible reason for you to do A, should reduce to the corresponding epistemic default rule, R→OUGHT(A), representing a possible reason to believe that one ought to do A. In Horty's system, we can easily test to see whether this is an adequate reduction, by checking to see whether applying the epistemic interpretation to a default logic containing rules like R→OUGHT(A) gives us the same conclusions about what an agent ought to do as applying the practical interpretation directly to a default logic containing the corresponding rules of the form, R→A.

But it is now easy to see that, at least without the help of some further auxiliary assumptions, this is not so. Recall our earlier example, which we said should lead to the conclusion that OUGHT(C) and OUGHT(D), but not to the conclusion that OUGHT(~C). By the proposed reduction, our original example should reduce to the epistemic defaults δ = A→OUGHT(C), δ = B→OUGHT(~C), and δ = C→OUGHT(D), with δ ranked highest and with background information that includes both A and B. (This, recall, is because according to the epistemic priority thesis, reasons to do things are "really" epistemic reasons in support of the contents that one ought to do those things.) But whereas our original set of defaults resulted in the extension that is the deductive closure of {A,B,C,D}, on the basis of the proper scenario consisting of defaults δ and δ , our new set of defaults yields {δ ,δ } as its only proper scenario, and so it does *not* lead to the conclusion that 1 2 3 1 1 3 1 2

OUGHT(D), but *does* lead to the conclusion that OUGHT(~C) as well as OUGHT(C). So this result is problematic in two different ways.

The first of these problems—the failure to conclude that OUGHT(D)—derives from the fact that the premise of default δ is no longer the same as the conclusion of δ , and so we no longer get the *chaining* of defaults that triggers δ , once δ is active. And the second problem—the derivation of OUGHT(~C) as well as OUGHT(C)—derives from the fact that since, at least on Horty's own view (as argued in Horty 2012: ch. 4) that OUGHT(C) and OUGHT(~C) are consistent, defaults δ and δ are no longer in *conflict* with one another. Each of these corresponds, unsurprisingly, to one of the two parallels that we observed in the last section between reasons for action and reasons for belief that helped to motivate treating reasons for action and reasons for belief in parallel, in the first place. 3 1 3 1 1 2

**(p. 57)** A structurally analogous set of problems besets the priority of practical reasons, in this framework.12 On this view, recall, reasons that support conclusions are really just a special case of reasons to do something—namely, to believe those conclusions. And so, analogously to the epistemic priority thesis, this view requires that there must be some translation of epistemic defaults into practical defaults. Since the practical priority thesis holds that epistemic reasons are reasons to believe, it is therefore most natural, at least on a first pass, to interpret this view as holding that each epistemic default A→B should really reduce to the "practical" default, A→BF(B), where "BF(B)" is interpreted as meaning that the agent in question believes that B.13 But now it should be easy to see that we will get exactly the same kind of problems for this proposal as for the reverse view. Because it is possible (even if it is not rational or advisable) for an agent to have contradictory beliefs, BF(C) and BF(~C) are not inconsistent.14 And so, translating conflicting epistemic defaults into practical defaults whose conclusions are about beliefs will not preserve competition between defaults. And because BF(C) doesn't entail C, the translation also upsets the chaining of defaults. Again, these problems arise directly from the two phenomena—conflicts and chaining—that we observed helped in the first place to motivate the parallel treatments of reasons for belief and reasons for action.

What we've been observing is that each of the features that seemed to play a recognizable role in motivating Horty's parallel treatments of reasons for belief and reasons for action are vitiated, in the absence of any auxiliary assumptions, by the most natural translations of defaults that respect each of the epistemic and practical priority theses. Considerations like these therefore make it highly natural to conclude that, on the right way of thinking about the picture behind Horty's interpretation of default logic as telling us the logic of how reasons come together to support conclusions, *both* of our priority theses are false: neither reasons to do things nor reasons to believe things are a special case of the other. And if neither is a special case of the other, then the only thing that reasons for action and reasons for belief have in common must be the logic by which they determine conclusions—Horty's prioritized default logic. If that is right, then there is nothing more to say in answer to what unifies reasons than that it is the way in which they come together to determine conclusions. So if reasons are in fact what unify the normative and in virtue of which things count as normative, then it turns out, on this view, that normativity

itself is nothing other than a matter of being determined by the kind of weighing characterized by Horty's prioritized default logic. And that would be a remarkable conclusion, indeed.

## **(p. 58) 2.7 Reviving Epistemic Priority**

The tentative conclusion of the last section is quite striking. However, in this section and the next I'll moderate the force of my conclusion from the last section, by showing what kind of flexibility Horty's system actually offers for addressing the problems that I raised with auxiliary assumptions—some of which turn out to be very interesting indeed. So, rather than being conclusive problems for our priority theses, we'll see that what Horty is really committed to is a surprisingly close relationship between the priority theses and these very interesting auxiliary assumptions.

In the last section, I pointed out two different kinds of problem with implementing each of the priority theses within Horty's system. One had to do with *conflicts* between defaults, and one had to do with the *chaining* of defaults. When we interpreted a reason to do C as a reason to believe that you ought to do C, we did so by representing the practical default rule A→C as the epistemic default rule A→OUGHT(C). The practical default rules A→C and B→~C potentially conflict, because C is inconsistent with ~C. This conflict is what prevents us from including both of these default rules in a proper scenario. But when we replace these rules with the epistemic rules A→OUGHT(C) and B→OUGHT(~C), there is no longer any conflict between these rules unless we assume that OUGHT(C) and OUGHT(~C) are inconsistent—which Horty himself doubts.15 Fortunately, however, many philosophers believe that all-things-considered conflicts in what an agent ought to do are in fact impossible. And adding this assumption solves our problem by making OUGHT(C) and OUGHT(~C) inconsistent. So it turns out that we can solve this problem by adding to Horty's system an auxiliary assumption which, though he rejects it, is at least a sufficiently natural assumption that many philosophers find it compelling. And this is an interesting surprise! Who would have thought that the plausibility of the epistemic priority thesis might be built on the assumption that there are no deontic conflicts?

But in fact, we can do even better for the epistemic priority view with respect to this problem. For even if we are willing to countenance deontic conflicts, we might still believe that these are unusual, or only to be allowed in exceptional cases. In Horty's system, it is natural to represent this by including a default rule for each thing C that we might do, which allows us to conclude, by default, that it is not the case that one ought to do both C and ~C. This rule has the form, ⊤→~(OUGHT(C)&OUGHT(~C)) (where ⊤ just means a tautology). If we assume that there is always this background reason to presume that we are not facing a conflicting obligation, and if we assume that it has a very high priority, then that will ensure that there is no proper scenario that includes both of the defaults A→OUGHT(C) and B→OUGHT(~C) unless these both have a priority even higher. So we will avoid concluding that there are conflicting obligations unless the reasons involved are very forceful.

**(p. 59)** Indeed, not only does this avert the problem, it does so in a particularly plausible way. When philosophers have argued for the possibility of deontic conflicts, they have appealed to cases in which the reasons on each side are particularly compelling. No one argues that there are genuine deontic conflicts by arguing that you ought to get pancakes instead of eggs because you are craving them, but also ought to get eggs instead of pancakes because you are craving them, too. They argue, instead, by appeal to cases in which you must choose between your commitment to family and to your country, or between which of your children to save from the Nazis. But if there is a strong default presumption, in all cases, that you are not facing a deontic conflict, then this is exactly what we should predict: for the only genuine deontic conflicts will be ones where the reasons on each side are each weighty enough to counterbalance the default presumption that this is not a deontic dilemma. So the appeal to a strong epistemic default that one is not facing a deontic dilemma actually gives us a very appealing diagnosis of why deontic dilemmas, when they exist, arise only when there are particularly compelling reasons in play, and never when the reasons are slight.16

The same techniques can be adapted to solve the "chaining" problem for the epistemic priority thesis. That problem, recall, was that if A is a reason to do C, and your doing C is, if true, a reason for you to do D, then the default logic effectively allows us to "chain" together the practical defaults A→C and C→D so that the latter makes it into scenarios that include the former, unless it is conflicted or defeated. But if we represent these practical default as the epistemic defaults A→OUGHT(C) and C→OUGHT(D), then we can no longer automatically "chain" these defaults together.17

However, just as we could regenerate the conflict between reasons by assuming that it is always part of the background information that it is not the case that you ought to do each of conflicting things, we can regenerate this chaining by assuming that it is always part of the background information that if you ought to do C, then you will do it. On this assumption, Horty's system guarantees that the epistemic defaults "chain" just as the practical defaults would. Unfortunately, of course, in contrast to the conflicts case, where many philosophers do believe that there can be no conflicting obligations, it is not at all plausible that it is always a fixed background fact that an agent will do what she ought. On the contrary, we know that many agents do not do what they ought.

But again, a retreat to default information is more plausible. Perhaps there is a compelling but defeasible reason for any agent to believe that she will do what she ought—a highly prioritized default of the form, ⊤→(OUGHT(C)⊃C). If so, then we will get "chaining" of the defaults A→OUGHT(C) and C→OUGHT(D) whenever the agent does not know as part of her background information, or have even more compelling reason **(p. 60)** to believe, that ~(OUGHT(C)⊃C).18 If she does have more compelling reason to believe that the default assumption that she will do what she ought is false, of course, we will no longer get this chaining. But in this case, this actually seems like a very plausible conclusion. In normal cases it is plausible that if you ought to pick up Caroline, and picking up Caroline gives you a good reason to drive, then you ought to drive. But if you aren't going to pick up Caroline, despite the fact that you ought to, it's not so obvious that you still ought to drive, if your only reason to drive is in order to pick up Caroline.19

So again, I think the auxiliary assumption that helps to dispel this problem is both interesting in its own right and yields an even more interesting treatment of when reasons should and should not "chain" in determining what you ought to do. Inconsistency and chaining are not the *only* interesting or attractive parallel properties of how reasons for belief and reasons for action combine in Horty's system; so what we've seen in this section only tells us part of what is necessary in order to revive epistemic priority, not what is sufficient. Nevertheless, when interesting and plausible claims turn up in surprising places, I think we should sit up and take notice.20

## **2.8 Reviving Practical Priority**

So far, we've seen that if we add some plausible auxiliary assumptions to Horty's system, the epistemic priority view begins to look more plausible after all. And these assumptions are both interesting and at least plausible in their own right, and lead to a more nuanced and plausible treatment of the phenomena that motivate the importance of conflicting reasons and chaining in the first place. Analogous points apply to the practical priority view.

On the primary interpretation that we have given of the practical priority view, recall, we aim to reduce epistemic reasons to practical reasons by interpreting each epistemic default rule, A→C, as the corresponding "practical" default, A→BF(C). So reasons supporting a conclusion to be believed are understood as reasons to *do* something—in favor of the agent in question believing that proposition. As with the epistemic priority thesis, we get prima facie problems with conflicting reasons and with chaining. To take the conflict case first, though the defaults A→C and B→~C can come into conflict, because C and ~C are inconsistent, the corresponding defaults A→BF(C) and B→BF(~C) do not automatically come into conflict.

As before, there are two ways in which we can try to solve this problem by appeal to auxiliary assumptions. We could build this conflict in either as part of the background **(p. 61)** information in the case, or by way of a default. In this case, the background information option would require that it is always part of the fixed background information that the agent in question does not have contradictory beliefs. But this is not particularly plausible —we know that agents, including ourselves, sometimes have contradictory beliefs (if you think agents never have beliefs in directly contradictory propositions, the problem readily generalizes to larger sets of inconsistent beliefs, which are surely possible).

So it is more plausible to try to solve this problem by assuming that there is a general, highly prioritized reason characterized by the default Ψ→~(BF(C)&BF(~C)). Since we are operating under the practical interpretation of default logic, this amounts to assuming that every agent always has a compelling reason not to believe contradictions. Not only is this assumption itself plausible, it has been explicitly defended as a central thesis about

the rationality of belief. Theorists like John Broome, for example, have argued that—at least if rationality is normative—there are general, high-level reasons against having contradictory beliefs like this.21

Of course, though a reason to not have contradictory beliefs has been defended by Broome, others, including Joseph Raz and Niko Kolodny, have argued that there are no such reasons, and whatever is wrong with believing a contradiction can be explained by the fact that there are compelling reasons against at least one of the two conflicting beliefs.22 But the practical priority thesis can be revived on this view as well, so long as we assume that all defaults of the form, BF(C)→~BF(~C), are always present and highly prioritized. This is essentially the view that I have defended elsewhere.23

The "chaining" problem for the practical priority thesis can also be solved using similar methods. That problem is that though the epistemic defaults A→C and C→D "chain" so that if you ought to believe C, then you also, defeasibly, ought to believe D, the corresponding practical defaults A→BF(C) and C→BF(D) do *not* automatically chain in this way. Once again, however, we can hardwire in this chaining, by building BF(C)⊃C in either to the background information or as a default conclusion. Of course, it's not plausible that it is always part of the background facts that whatever the agent believes is true, so the first option is out. But to say that there is a general, highly prioritized default of the form Ψ→(BF(C)⊃C) under the practical interpretation is just to say that there is a highly general, compelling reason for any agent to believe something only if it is true.

And again, this is a highly natural and plausible thesis. However, just as Raz and Kolodny doubt that there are special reasons against believing contradictions, it is reasonable to doubt whether there is a special reason to believe something only if it is true—after all, whatever is bad about believing false things could be explained by the **(p. 62)** *special* reasons not to believe them, given that they are false.24 Unlike the problem of conflicts, however, the problem of chaining cannot be solved by replacing the "wide-scope" default Ψ→(BF(C)⊃C) with a narrow-scope default of the form BF(C)→C or ~C→~BF(C). The latter default would not resuscitate chaining, and the former would yield the implausible consequence that when Alice tells you that Caroline said that D, not only should you believe that Caroline said that D and believe that D, but you should believe the latter *because* you should also make it the case that Caroline said that D. So this solution does appear to require postulating a general, high-level reason to believe things only if they are true.

However, there is an alternative, better solution to the problem of chaining for the practical priority thesis. It is to reject the translation scheme whereby we interpret the epistemic default A→C as the practical default A→BF(C). In its place, we should instead translate the epistemic default A→C as the practical default BF(A)→BF(C). This alternative translation preserves the idea that epistemic reasons are reasons in favor of doing something—believing that thing—but it adopts an alternative picture of what those reasons are. After all, it is plausible that when you have epistemic reasons for belief, it is in virtue of having other beliefs—or at least, other mental states of some kind. Our previous trans

lation interpreted the epistemic reasons as the *contents* of those beliefs. But this alternative translation interprets them as the proposition that you have those beliefs.

To adopt this alternative translation, we must also adopt a shift in how we think of what I have been calling the "background information." In our working epistemic example, the set {A,B} characterizes your background information—so A and B are things that you start by believing, and we are asking what else you should conclude. But if our epistemic default A→C is translated as the practical default BF(A)→BF(C), then it will not be triggered by this background set. So in addition to translating our epistemic defaults into practical defaults, we also need to translate our background information {A,B} into the new background set, {BF(A),BF(B)}, which we now think of as a list of your beliefs, rather than as a list of the contents of your beliefs. With these amendments on board, we no longer have a problem with chaining, because the defaults BF(A)→BF(C) and BF(C)→BF(D) chain together perfectly well.25

This new translation does nothing to help with the problem of conflicts, of course, because BF(C) and BF(~C) are still consistent. But it does mesh well with our previous solution to the problem of conflicts for the practical priority thesis. That solution, recall, was to propose that there are always highly ordered defaults of the form, BF(C)→~BF(~C). This is just to say, of course, that believing a proposition gives you a compelling reason not to believe its negation. With our old translation of epistemic defaults into practical defaults, epistemic reasons were the contents of your beliefs, and so this case was **(p. 63)** discontinuous. But with our new translation, epistemic reasons are propositions about what you believe. And so these two solutions dovetail nicely together. I take it that the best solution to the problems of conflicts and of chaining for the practical priority view will combine them.

Again, since conflicts and chaining are only two of the interesting parallel properties of how reasons for action and for belief in Horty's system, this discussion addresses only what is necessary, and not what is sufficient, to fully revive the practical priority thesis in this system. But again, when unexpectedly interesting ideas come up, it is worth taking notice.

## **2.9 Generalizing**

We've now seen, in sections 2.6, 2.7, and 2.8, that there are moves that can be made in order to resuscitate both the practical and epistemic priority theses, in the face of the problems about conflicts and about chaining. But it is important to appreciate that these two problems are just aspects of a more general problem—about how reasons for belief and reasons for action can do the right amount of work, in the way in which they compete against one another to determine what the agent ought to do and/or believe. Both the problem of conflicts and the problem of chaining result from reasons doing *too little* work. We want the reasons against doing C not just to support doing ~C, but also to compete with the reasons in favor of doing C. If they do not, then both C and ~C end up supported too easily—and this was the problem of conflicts. Similarly, there is at least some intuitive

plausibility to the phenomenon that I have called "chaining." In the absence of chaining, then, reasons do too little work in supporting conclusions of what to do or to believe.

But in addition to problems about reasons doing too *little* work, we should also worry about what happens if reasons do too *much* work. Take, for example, a simple means–end case from Ryan Millsap. The fact that Ryan's father is hospitalized is a reason for him to visit his father. Similarly, the fact that a plane ticket is expensive is a reason not to buy it. But in order to visit his father, he must buy a plane ticket. This background fact puts Ryan's reason to visit his father into competition with his reason not to buy a plane ticket. On some views it must do so by "transmitting" to a derivative reason to buy a plane ticket; in Horty's system, which has the virtue of generalizing very well to cases in which Ryan could visit his father without buying a plane ticket but only at extraordinary inconvenience, the competition happens directly. It happens because reasons to do things compete when they are for actions that are incompatible, given the background facts. This is a good result, because it guarantees that if Ryan ought to visit his father, then he also ought to buy the plane ticket, and that if he ought to not buy the plane ticket, then he ought to not visit his father. And those are good results to get.

But now suppose that Alice tells Ryan that C, and Bob tells Ryan that D. But suppose, as a background fact, that just as Ryan cannot visit his father without buying a plane **(p. 64)** ticket, he cannot believe that C and also believe that D. Now our practical priority thesis puts Ryan's reasons to believe that C and to believe that D into conflict—even if C and D are not incompatible. So it cannot turn out that Ryan ought to believe that C unless it turns out that he ought to not believe that D, and similarly, it cannot turn out that he ought to believe that D unless it turns out that he ought to not believe that C. But these are not good conclusions to draw about this case—what Ryan ought to believe about each proposition should not, intuitively, turn on which propositions he is capable of believing together, when there is no incompatibility between those proposition themselves. So the practical priority thesis still leads to reasons doing *too much* work with respect to what we should believe, even if we solve the problems about reasons doing *too little* work.

The epistemic priority thesis also still allows reasons to do too much work. To see how, suppose that Alice tells you to pick up Caroline, and Bob tells you to wear a suit. There is nothing incompatible about picking up Caroline and wearing a suit, but suppose that you have strong independent evidence that only one of these two actions is obligatory. The epistemic priority thesis puts these three reasons into conflict with one another. Because OUGHT(C), OUGHT(S), and ~(OUGHT(C)&OUGHT(S)) are an inconsistent triad, not all three can be supported by the reasons given by the defaults in a stable scenario. So if the evidence that you don't have both obligations is better than either Alice's or Bob's authority, then it can turn out only that you ought to pick up Caroline *or* that you ought to wear a suit, but not both—even though there is no conflict between them.

So the problems facing each priority thesis are merely illustrated, and not exhausted, by the problem of conflicts and the problem of chaining. They are in fact highly general, and the solutions considered in sections 2.7 and 2.8, though highly interesting in their own right, are not sufficiently general to the scope of the problem.

How, then, might these problems be solved? I don't have a good answer to this, and the issue is complex. On one kind of view, all of the work done by reasons can be divided between their impact on the question of whether to do what they favor directly, and their impact on what *other* reasons they *transmit* to. So on this view, Ryan's reason to visit his father bears only on the question of whether to visit his father but transmits to a separate, derivative reason to buy a plane ticket; and the reason against buying the plane ticket bears only on the question of whether to buy a plane ticket, but transmits to a reason not to visit his father. A proponent of the practical priority thesis might hope to solve the problem of epistemic reasons doing too much work by adding to her view that epistemic reasons are reasons in favor of doing a particular thing—having a certain belief—the view that they are a special kind of such reason—*epistemic* or "right-kind" reasons. She then might suppose that epistemic reasons *transmit* in different ways than non-epistemic reasons, even though they compete with one another in the same ways—or even that they transmit in all of the same ways, but that the resultant derivative reasons do not always qualify as "epistemic." Because Horty's framework does not distinguish between transmission and competition, but allows reasons to compete directly in these cases, it doesn't allow us to make moves like these, and is not particularly helpful **(p. 65)** for thinking them through. However, it is worth noting that Horty's framework successfully deals with a wide range of important cases for which there is no adequate treatment that appeals to transmission principles, and it remains an open question whether transmission principles can even be made to work at all without leading to absurd results. See Nair and Horty (Chapter 3 in this volume) for discussion.

## **2.10 Conclusion**

In this chapter, we've looked in detail at the most precise, tractable view currently available, which makes concrete predictions about how reasons—of either kind—combine to support conclusions about what we should do or believe. This view is heavily motivated by appeal to the parallels and differences between how reasons support conclusions and how they support things we can do. And we've seen that in this framework, any answer to the priority question with which we started must be accompanied by striking and important conclusions about independently interesting questions. This does not settle the question of how reasons for belief are related to reasons for action, but it does draw into focus some of the things that we need to understand better, in order to ultimately evaluate that question. Ultimately, answering these questions will help us to better understand how reasons for action and reasons for belief are like and unlike one another, and in turn, whether they exhibit any unity, and if so, of what kind.

## **References**

Broome, John (1999). "Normative Requirements." *Ratio* 12(4): 398–419.

Broome, John (2013). *Rationality Through Reasoning*. New York: Wiley-Blackwell.

Brunero, John (2009). "Reasons and Evidence One Ought." *Ethics* 119(3): 538–45.

Chisholm, Roderick (1963). "Contrary-to-Duty Imperatives and Deontic Logic." *Analysis* 24(2): 33–6.

Dancy, Jonathan (2004). *Ethics Without Principles*. Oxford: Oxford University Press.

Horty, John F. (2003). "Reasoning with Moral Conflicts." *Noûs* 37(4): 557–605.

Horty, John F. (2007). "Reasons as Defaults." *Philosophers' Imprint* 7(3): 1–28.

Horty, John F. (2012). *Reasons as Defaults*. Oxford: Oxford University Press.

Kearns, Stephen, and Daniel Star (2008). "Reasons: Explanations or Evidence?" *Ethics* 119(1): 31–56.

Kearns, Stephen, and Daniel Star (2009). "Reasons as Evidence." *Oxford Studies in Metaethics* 4: 215–42.

Kolodny, Niko (2005). "Why Be Rational?" *Mind* 114(455): 509–63.

Kolodny, Niko (2008a). "The Myth of Practical Consistency." *European Journal of Philosophy* 16(3): 366–402.

Kolodny, Niko (2008b). "Why Be Disposed to Be Coherent?" *Ethics* 118(3): 437–63.

Marušić, Berislav (2015). *Evidence and Agency: Norms of Belief for Promising and Resolving*. Oxford: Oxford University Press.

Millsap, Ryan (unpublished). Unfinished PhD dissertation, University of Maryland.

**(p. 66)** Parfit, Derek (2001). "Rationality and Reasons." In Dan Egonsson, Jonas Jesefsson, Björn Petersson, and Toni Rønnow-Rasmussen (eds), *Exploring Practical Philosophy*, 17– 39. Burlington, Vt.: Ashgate.

Parfit, Derek (2011). *On What Matters*. 2 vols. Oxford: Oxford University Press.

Pascal, Blaise (1966). *Pensées*. Translated by A. J. Krailsheimer. New York: Penguin.

Perry, John (1979). "The Problem of the Essential Indexical." *Noûs* 13(1): 3–21.

Piller, Christian (2001). "Normative Practical Reasoning." *Proceedings of the Aristotelian Society* 25 (suppl. vol.): 195–216.

Raz, Joseph (2005). "The Myth of Instrumental Rationality." *Journal of Ethics and Social Philosophy* 1(1): 1–28.

Scanlon, T. M. (1998). *What We Owe to Each Other*. Cambridge, Mass.: Harvard University Press.

Schroeder, Mark (2004). "The Scope of Instrumental Reason." *Philosophical Perspectives* 18 (Ethics): 337–64.

Schroeder, Mark (2007). *Slaves of the Passions*. Oxford: Oxford University Press.

Schroeder, Mark (2009). "Means–End Coherence, Stringency, and Subjective Reasons." *Philosophical Studies* 143(2): 223–48.

Schroeder, Mark (2012a). "Stakes, Withholding, and the Pragmatic Encroachment on Knowledge." *Philosophical Studies* 160(2): 265–85.

Schroeder, Mark (2012b). "The Ubiquity of State-Given Reasons." *Ethics* 122(3): 457–88.

Schroeder, Mark (2013). "State-Given Reasons: Prevalent, if not Ubiquitous." *Ethics* 124(1): 128–40.

Schroeder, Mark (2014). "Scope for Rational Autonomy." *Philosophical Issues* 23: 297– 310.

Schroeder, Mark (2015). "What Makes Reasons Sufficient?" *American Philosophical Quarterly* 52(2): 159–70.

Snedegar, Justin (2017). *Contrastive Reasons*. Oxford: Oxford University Press.

Thomson, Judith Jarvis (2008). *Normativity*. New York: Open Court.

van Roojen, Mark (2010). "A Fork in the Road for Expressivism." *Ethics* 120(2): 357–81.

## **Notes:**

[^000]: Special thanks to Jeff Horty, Daniel Star, Shyam Nair, Bruce Brower, Susanne Mantel, Ralph Wedgwood, Tim Henning, Benjamin Kiesewetter, Marc Lange, Mark Murphy, Ram Neta, Kate Nolfi, Hille Paakunainen, Geoff Sayre-McCord, Nate Sharadin, Kevin Scharp, Tim Schroeder, and to audiences at the University of North Carolina at Chapel Hill, Humboldt Universität zu Berlin, the Ohio State University, and the Murphy Institute of Tulane University.

[^1]: Compare, e.g. Scanlon (1998), Dancy (2004), Schroeder (2007), and Parfit (2011).

[^2]: Pascal (1966).

[^3]: Compare Parfit (2001) and Piller (2001).

[^4]: For versions of this view, see Thomson (2008) and Kearns and Star (2008, 2009).

[^5]: For interesting critical discussion, see Brunero (2009).

[^6]: I articulate these suspicions further in Schroeder (2012b, 2013), and put them to work in Schroeder (2012a, 2015). Compare also Snedegar (2017: ch. 6).

[^7]: Perry (1979).

[^8]: Strictly speaking, the default logic works in propositions, rather than actions; but for each action, there is the proposition that the agent in question performs that action. For other purposes, I happen to think that this is an important distinction, but I don't know of any reason to think that it is not orthogonal to the issues that interest me in this chapter. Thanks to Kevin Scharp for special discussion of this point.

[^9]: Horty actually offers two different practical interpretations, one of which is designed to allow for conflicts and one of which is designed to avoid them. These interpretations come apart only when there are multiple extensions. However, in this chapter I'll only consider cases with unique extensions.

[^10]: Compare Millsap (unpublished).

[^11]: One of the virtues of chaining is that it prevents us from sending you on loops of reasoning, whereby you step by step draw conclusions that in turn require you to undermine the earlier steps of that very reasoning. The idea that a stable scenario allows chaining tells us that the only conclusion that we *should* draw is one that will be stable in the absence of further new information.

[^12]: In calling these problems "structurally analogous," I do not mean to imply that the resources for solving them are exactly the same. In sections 2.7 and 2.8 we will see that the force of these problems and the resources for solving them are in fact somewhat different. Thanks to Kevin Scharp for discussion.

[^13]: In section 2.8 we will consider an alternative interpretation of the practical priority thesis.

[^14]: If you doubt that it is possible to believe each of directly contradictory propositions, note that the problem easily generalizes to larger sets of incompatible propositions, which are surely possible to believe.

[^15]: Horty (2003, 2012: ch 4).

[^16]: Horty's own treatment of deontic conflicts makes no such distinction—incomparable undefeated reasons result in conflicts no matter their weight.

[^17]: You may doubt whether practical chaining is worth preserving; it is certainly more controversial than epistemic chaining. However, we'll see that the most natural way of resuscitating practical chaining for the epistemic priority thesis actually leads to a weaker and more plausible version of chaining that is interesting in its own right. Thanks to Hille Paakunainen for discussion.

[^18]: This would give each agent a sort of transcendental argument that she is good—for on this picture, the very possibility of reasoning about what to do requires evidence that she will do what she ought. Compare especially Marušić (2015).

[^19]: Compare Chisholm (1963), whose eponymous paradox turns on this observation.

[^20]: Compare van Roojen (2010).

[^21]: Broome (1999) holds that there are reasons not to have inconsistent beliefs; Broome (2013) advocates the weaker, conditional thesis that there are such reasons if rationality is normative.

[^22]: Raz (2005) and Kolodny (2005, 2008a, 2008b).

[^23]: Compare Schroeder (2004, 2012b, 2014). Special thanks to Bruce Brower for pushing this point.

[^24]: Compare Schroeder (2004, 2014).

[^25]: Note that there is no similarly plausible alternative translation of the epistemic priority thesis, because there is no correspondingly plausible way of translating background information as things that we know ought to be the case.

---

# 3. The Logic of Reasons

*Shyam Nair and John Horty*

### **Abstract and Keywords**

We discuss the need for and prospects of a logic describing the relation among reasons and the outcomes they support. After noting some shortcomings of the dominant weighing conception of this support relation, we very briefly outline the basic idea behind two attempts at providing such a logic. We then describe a few topics that are ripe for further research: the logical relations among reasons themselves, the source and formal structure of priority relations among reasons, whether the strengths of multiple reasons can combine, and a problem concerning the strength of undercutting defeaters.

Keywords: accrual, reasons, logic, weight, defeat

## **3.1 Introduction**

Reasons figure large in our ordinary talk of deliberating about or justifying actions or conclusions. Suppose, for example, you want to convince a friend to dine with you at Obelisk tonight. Typically, you will offer reasons—there is a new chef, the reviews have been excellent. Or suppose you want to explain why you believe raccoons have been in the back yard. You will offer your evidence, again, typically, in the form of reasons—the garbage was broken into, those tracks look like raccoon prints.

In spite of their prevalence in our ordinary talk, however, reasons appear to play no role at all in the two predominant formal theories of deliberation and justification: standard logic and decision theory. In logic, for example, we learn how to establish that premises imply conclusions, sometimes in accord with formal rules of inference, sometimes through a model-theoretic definition. In decision theory, we learn how to rank proposed actions by expected utility, defined in terms of the possible outcomes of those actions, their probabilities, and their utilities. Neither of these well-established theories involves any appeal to our ordinary concept of a reason.

Perhaps this is as it should be—perhaps the concept of a reason is nothing but an artifact of folk psychology that should be eliminated from serious scientific discourse. Even so, it may still be useful to map out what logic there is underlying our talk of reasons: the architecture of our folk psychology is not without interest. But it is also possible that the concept of a reason is not eliminable at all, but central to an understanding of ourselves and the world we live in. This idea can be found at times in epistemology, and especially in ethics, where many writers take the notion of a reason as basic to the normative realm, a fundamental concept in terms of which other normative notions can then be analyzed. If this is correct, then understanding the logic of reasons is not just interesting, but crucial.

What would such a logic look like? Just as ordinary logics show us how premises interact to yield conclusions, a logic of reasons would have to show us, at the very least, **(p. 68)** how reasons interact to support the outcomes they do. Suppose, for example, that you have arranged to meet Emma for lunch. You therefore have a reason to do so, and so it seems that you ought to. But why, exactly? How does the reason generate the ought? Suppose that, on the way to meet Emma for lunch, you encounter your friend Max drowning in a canal. The duties of friendship, and perhaps other duties, now provide you with a reason to rescue Max—which would prevent you, however, from meeting Emma for lunch. It is natural to conclude that what you ought to do, in this situation, is rescue Max, rather than meet Emma. But again, why? How do these two reasons interact to support one outcome, rather than the other?

Or consider an epistemic case. Suppose Eric tells you that Tweety is a bird. Trusting Eric as you do, you now have a reason for the conclusion that Tweety is a bird, which itself forms a reason for the further conclusion that Tweety can fly—since birds, typically, can fly. But suppose also that Rachael, who is equally trustworthy, tells you that Tweety is a penguin. You now have a reason for the conclusion that Tweety is a penguin, which forms a reason for the further conclusion that Tweety cannot fly—since penguins cannot fly. Here, it is natural to accept both of the initial conclusions—that Tweety is both a bird and a penguin—but to reject the conclusion that Tweety can fly in favor of the conclusion that he cannot. But why? How do these various reasons interact to support the conclusions that Tweety is both a bird and a penguin, but a bird that cannot fly, rather than a penguin that can?

These are the kinds of questions that a logic of reasons must address. But of course, not every question concerning reasons is a matter of logic, in this sense, and many can safely be ignored. The logic of reasons need not concern itself with the nature of reasons, for example, just as standard logic is able to map out the logical relations among propositions without committing itself to any particular account of the nature of propositions. Nor need the subject consider the question of what reasons actually hold, or what reasons should be taken to bear on some situation, just as standard logic need not consider the question of what propositions are actually true. The logic of reasons is focused only on the question of how reasons—no matter what their nature, or where they come from support or justify the actions or conclusions they do.

Many philosophers, particularly those working in ethics, suppose that an answer to this question is provided by what we will call the *weighing conception*, according to which reasons support actions or conclusions by contributing a kind of metaphorical weight, and that, in case of conflict, the option with the greater weight should be selected.1 This idea can seem plausible if we limit our consideration to simple examples such as those considered so far. Why rescue Max, rather than meet Emma? Because, although you have reasons favoring both actions, your reason for rescuing Max is weightier—stronger, or more powerful—than your reason for meeting Emma. Why conclude that Tweety cannot fly, rather than that he can? Because your reason favoring **(p. 69)** the first conclusion, provided by the fact that Tweety is a penguin, carries more weight than your reason favoring the second, provided by the fact that Tweety is a bird.

The weighing conception founders, however, once we turn to situations in which the interactions among reasons are more complicated. To begin with, weighing is necessary at all only when options are incompatible—as when, for example, you believe that it is impossible both to rescue Max and to meet Emma. But which options are taken to be incompatible may itself depend on background beliefs, themselves based on further reasons. You may have arrived at your belief that rescuing Max rules out meeting Emma itself through the consideration of reasons, possibly involving the available transportation options, which had to be weighed against other reasons supporting a contrary conclusion. In that case, it would have been important for you to perform the weighing involved in deciding whether rescuing Max and meeting Emma are incompatible before deciding which of these actions to perform; you would not want to decide that you ought to perform both actions, for example, prior to reasoning about their compatibility, and then, possibly, conclude that they must be compatible because ought implies can.2 Even in situations in which the weighing conception is plausible, then, it is clear that the process of settling on actions or conclusions through a process of weighing reasons would have to be carefully structured, with certain decisions settled before others are considered.

But there are also situations in which the interactions among reasons do not seem to involve weighing at all. Reasons support outcomes, and *defeat* other reasons, preventing them from yielding conclusions they otherwise would. There are, however, at least two kinds of defeat. The metaphor of weighing applies most naturally when, as in the situations considered so far, a reason supporting one conclusion is *rebutted* by a stronger, or weightier, reason supporting a conflicting conclusion; but, as first noted by Pollock, there are also situations in which reasons are not actually rebutted by stronger reasons supporting conflicting conclusions, but simply removed from consideration, or *undercut*. 3 To illustrate, suppose once again that Eric tells you that Tweety is a bird, providing you with a reason for concluding that Tweety is in fact a bird, but this time, what Rachael tells you is that Eric is unreliable, or at least unreliable in his ability to distinguish birds from other objects. In that case, your reason, provided by Eric's assertion, for concluding that Tweety is a bird would be defeated, but not rebutted, since you have no stronger reason supporting the opposite conclusion—Rachael herself may insist that she does not know whether Tweety is a bird. Instead, your reason for concluding that Tweety is a bird is undercut, since it is based on Eric's assertion, but you have now learned that Eric is unreliable.

One reason might, also, simply weaken another without undercutting that reason, or removing it from consideration entirely.4 Suppose Eric says that Tweety is a bird but **(p. 70)** Susan denies this, claiming that Tweety is not a bird—imagine that Eric and Susan are both looking at Tweety from a distance. Here, you are presented with reasons supporting conflicting conclusions, but suppose that what Rachael tells you in this case is that Eric's vision is poor. Although this does not entirely undercut your reason for concluding that Tweety is a bird, it does weaken it, perhaps to the extent that you are willing to accept the conflicting conclusion supported by Susan's statement. Or, one reason might strengthen another.5 Suppose that, in the same situation, what Rachael now tells you is, not that Eric's vision is poor, but that Susan's is particularly good. Then, although the reason provided by Eric's statement is not weakened, the reason provided by Susan's statement is strengthened, again suggesting that you should settle on the conclusion that Tweety is a bird, though in a different way.

As these examples show, the interactions among reasons can be complex enough that it is hard to see how they could be understood through a model that allows only weighing. What other options are available, then, to help us understand the complexity? In recent years, two formal systems have been introduced with the goal of explicating the ways in which reasons interact to support the actions and conclusions they do. The first of these is the theory of defeasible reasoning developed in the seminal work of Pollock; the second is a more recent theory due to Horty, which adapts and develops the default logic introduced by Reiter to provide an account of reasons.6 Pollock's account is based on his earlier work in epistemology, and is applied primarily to problems in epistemology and computer science; there is a close connection between Pollock's theory of defeasible reasoning and his work on probabilistic reasoning. Horty's account begins with theories of default reasoning developed in computer science and is applied to problems in deontic logic, ethics, and legal reasoning, as well as epistemology; there is no connection to probabilistic reasoning, which seems less appropriate in the normative domain.

Setting aside incidental differences like these, however, the two accounts share some important similarities. Both are based on the idea of supplementing ordinary logic with new rules, according to which a proposition *X* is taken to favor, or support, an action or conclusion *Y*. Pollock refers both to these new rules themselves and to the premises of these rules as reasons, an ambiguity that introduces some confusion; Horty, following Reiter, describes them as default rules, or simply defaults, and refers only to their premises as reasons. There is, in both theories, an ordering on rules representing the priority, or strength, of the reasons they present, and the general idea is then to show how these rules interact with the rules of deductive inference **(p. 71)** to justify, or recommend, actions or conclusions, not just through deduction, but also on the basis of reasons. Moreover, both theories reflect the same general principle, which can be stated as follows: if the reason *X* supports the outcome *Y*, and it has been established that *X*, then we should accept *Y* as well, unless the reason *X* has been defeated—that is, either rebutted by a stronger reason supporting a conflicting conclusion, or removed from consideration as a reason, and so undercut. This idea is implemented in different ways in the two theories, though not so different that precise comparisons cannot be drawn. However, the implementations are complex enough, in both cases, to prevent useful summarization in a brief chapter. The presentations by the authors are accessible, in any case. And we would not want to give the impression that we think that work on the logic of reasons must follow the path mapped out in either of these theories—indeed, we feel that the field is wide open.

In the remainder of the chapter, therefore, we will concentrate on a number of issues bearing on the logic of reasons that are either not treated in the work of Pollock and Horty or whose treatment is, we feel, either inadequate or incomplete. These are: first, the question of whether it is necessary to understand logical interactions among reasons themselves, rather than simply between reasons and the actions or conclusions they support, and if so, what principles might govern these interactions; second, priority relations among reasons and the notion of reason accrual; and third, some problems posed by undercutting defeat.

## **3.2 Relations among Reasons**

We have been slipping back and forth, rather casually, between what might be called *practical* and *epistemic* reasons—reasons for actions versus reasons for conclusions. The information that Tweety is a bird might be said to provide an epistemic reason supporting the conclusion that Tweety flies. By contrast, when you promise to meet Emma for lunch, your promise is most naturally interpreted as providing a practical reason. It does not necessarily support the conclusion that you will meet Emma for lunch, but provides you with a reason for doing so.

Various theses could be advanced concerning the relation between these two kinds of reasons. One thesis is that epistemic reasons should be subsumed as a species under the genus of practical reasons. On this view, the reason for the conclusion that Tweety flies does not, in fact, support a proposition, but actually recommends an action: perhaps the action of *concluding* that Tweety flies. Another thesis is that practical reasons should be subsumed as a species under the genus of epistemic reasons. On this view, your reason to meet Emma for lunch does not recommend an action but actually supports a proposition: perhaps the proposition that you *ought* to meet Emma for lunch. Yet a third thesis is that neither practical nor epistemic reasons can be subsumed under the genus of the **(p. 72)** other, but that they are simply distinct kinds of reasons, though strikingly similar in many of their important logical properties.7

In addition to issues concerning relations between different kinds of reasons—practical and epistemic—there are also issues concerning logical relations among reasons. Standard logic, of course, explores logical relations among propositions, most notably the relation of entailment. The first issue, then, is whether there is any need at all to explore similar logical relations among reasons—or more starkly, are there logical relations among reasons themselves?

It is natural to assume so, and an argument can be supplied, deriving from the standard answer to the question of how reasons can support "ought" statements. The simplest form of this standard answer—found in Chisholm, for example—is that an agent ought to perform an action just in case there is an undefeated reason for the agent to perform that action.8 A more general form—found in Baier, Harman, Schroeder, and many others—is that an agent ought to perform an action just in case the reasons that favor performing that action outweigh the reasons that oppose doing so.9 Either form of the answer requires that, if an agent ought to perform an action, then that agent has a reason to perform that action—that there is a reason corresponding to each ought.

But now, imagine a situation in which I have promised to lend \$5 to a friend tomorrow and also to donate \$5 to charity, so that I have reasons to do both of these things. Suppose, also, that I have only \$15, with no immediate prospect of getting more, and that a movie costs \$7. It seems to follow, then, that I ought not to see a movie tonight. If there is a reason corresponding to each ought, then it follows that I must have a reason not to see a movie tonight. But where did this reason come from? It is generally assumed that this new reason is derived, somehow, from my existing reasons, to give \$5 each to my friend and to charity, together with certain facts about the situation in which I find myself: that I have only \$15 and a movie costs \$7. If one reason can, in fact, be derived from others, we can hope to discover the principles governing this entailment relation among reasons we can hope, that is, to discover principles governing the logical relations among reasons themselves.

Against this argument, it is worth noting that neither of the two existing formal systems that can be thought of as addressing the relation between reasons and conclusions those of Pollock and Horty—devotes any attention at all to questions concerning logical relations among the reasons themselves. Pollock does not even discuss the issue; Horty, while not denying that there may be logical relations among reasons, argues that there is no need to appeal to such relations in order to understand the way in which reasons support conclusions, either practical or epistemic.

## **(p. 73) 3.3 Conflicts among Reasons**

Still, many people have found it to be either necessary or helpful to appeal to logical relations among reasons.10 In this section, therefore, simply to illustrate the kinds of difficulties that must be faced by anyone hoping to develop a logical account of these relations, we consider one particular issue in more detail: the treatment of conflicting reasons.

We introduce this issue indirectly, by considering, first, some plausible patterns of inference in deontic logic as well as the problems they present in the presence of deontic conflicts, and then noting that both these patterns of inference and the problems they present would be relevant to a logic of reasons as well.11

Imagine, to begin with, that the laws of some country set the speed limit at 50 miles per hour. From this, we can conclude that drivers ought to drive no faster than 50 miles per hour—but it seems that we can conclude also that drivers ought to drive no faster than 100 miles per hour.12 This case illustrates the plausibility of the following principle of *single ought closure*, according to which we ought to perform whatever actions are entailed by the actions we ought to perform:

If an agent ought to do X, and doing X entails doing Y, then the agent ought to do Y.

Next, suppose that the laws require also that all citizens must either join the military or perform alternative service, but that some particular citizen, Smith, is committed to a pacifist religion that requires her not to join the military. From this, we can conclude that Smith, as a citizen, ought either to join the military or to perform alternative service, but that, as a pacifist, Smith ought not to join the military. It seems to follow, then, that Smith ought to perform alternative service.13

Single ought closure alone cannot explain this desirable conclusion, since performing alternative service is not entailed by either of the single oughts established thus far: joining the military or performing alternative service, or not joining the military. The conclusion would follow, however, if we could conjoin, or agglomerate, these separate oughts together into one, since performing alternative service does follow from: joining the military or performing alternative service, and also not joining the military. What this suggests is that we need an additional principle of *consistent ought (p. 74) agglomeration*, which allows us to conjoin single oughts together, at least when they are consistent:

If an agent ought to do X and the agent ought to do Y, where X and Y are consistent, then the agent ought to do X and Y.

This ought agglomeration principle and the previous ought closure principle, taken together, give us a tidy explanation of Smith's obligation. Since Smith ought to either join the military or perform alternative service, and Smith ought not to join the military, agglomeration allows us to conclude that Smith ought to either join the military or perform alternative service, and also not join the military. From this, closure then allows us to conclude that Smith ought to perform alternative service.

Now that we have seen some desirable inference principles, we are in a position to see why it is hard to reconcile the existence of conflicting obligations with these principles. Suppose you face conflicting obligations. Perhaps (1) You ought to meet Sam for a drink, but also (2) You ought not to meet Sam for a drink. The principle of single ought closure applied to (1) now yields (3) You ought to meet Sam for a drink or throw Sam into a canal. Since it is possible to meet Sam for a drink or throw Sam into a canal and not meet Sam for a drink, we may apply consistent ought agglomeration to (2) and (3), yielding (4): You

ought to meet Sam for a drink or throw Sam into a canal, and also not meet Sam for a drink. Finally, single ought closure, again, applied to (4) yields (5): You ought to throw Sam into a canal.

As this example shows, the two principles of single ought closure and consistent ought agglomeration, which are helpful for generating desirable conclusions in ordinary cases, also seem to support random, and unfortunate, conclusions when applied to conflicting oughts. And of course, one familiar reaction to this result, and others like it, is simply to deny that conflicting obligations, or oughts, are possible—the tension between these plausible principles of inference and conflicting oughts is often taken as a *reductio* of the idea that there might be conflicting oughts at all. We do not intend here to try to assess this reaction to this problem of conflicting obligations is correct; instead, our goal is to show only that problem can be generalized to apply, not just to conflicting oughts, but to conflicting reasons.

The generalization is straightforward. Earlier, we imagined a country with a 50 miles per hour speed limit—from which we concluded that drivers ought to drive no faster than 50 miles per hour, and so, by ought closure, no faster than 100 miles per hour. But it is natural to think that laws provide reasons as well as oughts, especially if we accept the idea, mentioned in the previous section, that oughts correspond to undefeated reasons, or to the most weighty sets of reasons. In this case, then, we must conclude that drivers have a reason not to drive faster than 50 miles per hour, and so a reason not to drive faster than 100 miles per hour. But where could this latter reason come from, since, we can assume, there is no law explicitly requiring drivers to drive less than 100 miles per hour? By analogy to our earlier proposal, it is plausible to suppose that this second reason is derived from the first through a principle of *single reason closure*, according to which:

If an agent has a reason to do X, and X entails Y, then the agent has a reason to do Y.

**(p. 75)** Let us return also to Smith, subject to the laws of her country, but also to pacifist commitments. Once again, it is natural to conclude that she has a reason, based on the laws, either to join the military or to perform alternative service, and another reason, based on her pacifism, not to join the military—and so, it seems, a reason to perform alternative service. But again, this latter reason does not follow from the others unless we can assume, in addition, a principle of *consistent reason agglomeration*, according to which:

If an agent has a reason to do X and the agent has a reason to do Y, where X and Y are consistent, then the agent has a reason to do X and Y.

With these two principles, just as before, we can understand how Smith's latter reason can be derived from the others. Reason agglomeration allows us to conclude, from Smith's separate reasons, first, to join the military or perform alternative service, and second, not to join the military, that Smith has, in addition, a single reason either to join the military or perform alternative service, and also not to join the military. And then from

this, single reason closure yields the conclusion that Smith has a reason to perform alternative service.

But since these two principles about reasons are structurally similar to the earlier principles about oughts, and the earlier principles yielded peculiar results when applied to conflicting oughts, it is easy to see that the current principles generate equally peculiar results when applied to conflicting reasons. Suppose, for example, that you have promised Sam to meet him for a drink, but also that you have promised Melissa not to meet Sam for a drink. Then (1) you have a reason to meet Sam for a drink, and (2) you have a reason not to meet Sam for a drink—and it is now possible, based on our principles, to mimic, for reasons exactly the same as set out earlier for oughts, to reach the conclusion that you have a reason to throw Sam into a canal. The principle of single reason closure applied to (1) now yields (3) You have a reason to meet Sam for a drink or throw Sam into a canal. Since it is possible to meet Sam for a drink or throw Sam into a canal and not meet Sam for a drink, we may apply consistent reason agglomeration to (2) and (3), yielding (4): You have a reason to meet Sam for a drink or throw Sam into a canal, and also not meet Sam for a drink. Finally, single reason closure, again, applied to (4) yields (5): You have a reason to throw Sam into a canal.

Now, as we mentioned, one popular reaction to this kind of problem in the case of oughts is to conclude simply that there can be no conflicting oughts—since the possibility of conflicting oughts, taken together with our very plausible principles, would yield such strange results. However, the analogous reaction is not available in the case of reasons: the whole point of reasons is that they can support an outcome without guaranteeing that outcome, thus allowing for different reasons to support conflicting outcomes, and to do so consistently.

Because the option of simply denying the possibility of conflicting reasons is not available, the tension with our reasoning principles is much more serious here than in the case of conflicting oughts. Here, with reasons, there is no choice other than to reject either reason closure or reason agglomeration. And this may be easy enough to do. What is harder, though, is to reject these principles while still allowing the patterns of **(p. 76)** inference they were originally introduced to support. Those writers, such as Pollock or Horty, who are able to proceed without positing logical relations among reasons can avoid this problem entirely; but those whose practical aims or theoretical commitments require logical relations among reasons must, eventually, confront the task of mapping out those relations.14

## **3.4 Weights and Priorities**

As we have seen, reasons are thought to come with weights, or more generally, to be arranged in a priority ordering. Two questions now arise concerning the priority relations among reasons: first, where do these the priorities come from, and second, what properties can the overall priority ordering be expected to satisfy?

Priorities among reasons can have different sources. In our initial penguin example, the priority between the two reasons provided by the fact that Tweety is both a bird and a penguin—supporting the conflicting conclusions that he can fly and that he cannot seems to derive from specificity: a penguin is a specific kind of bird, and so information about penguins in particular takes precedence over information about birds in general. But even in the epistemic domain, there are priority relations that have nothing to do with specificity. Reliability is another source. Suppose that Susan, a meteorologist, tells you that it will rain today, but that Eric, a mere person in the street, tells you that it will not; here, although both assertions provide reasons, it would be natural for you to view Susan as more reliable on this topic, and so to assign greater weight, or higher priority, to the reason provided by her assertion. And once we move from epistemic to practical reasons, then authority provides yet another source for priority relations. National laws typically override state or provincial laws, and more recent court decisions have more authority than older decisions; direct orders override standing orders, and because a colonel outranks a major, orders from the colonel override orders from the major.

Finally, one of the most important sources of priority is our very own reasoning about which reasons should have higher priority. Just as we reason about ordinary things in the world—birds, penguins, the weather—so we reason about our own reasons, offering further reasons for taking some of our reasons more seriously than others, and still further reasons for evaluating those. This is particularly evident in well-structured normative domains, such as the law, where the resolution of a dispute often involves explicit arguments concerning the relative importance of different considerations bearing **(p. 77)** on some issue. But it occurs also in the epistemic domain. Consider reliability, again. Suppose, in our previous example, that someone disagreed with your view that Susan is more reliable than Eric concerning the weather. What would you say to such a person? Most likely, you would offer further reasons for favoring the reliability of the meteorologist, and these reasons might themselves have to be buttressed by appeal to further reasons still.

A logic of reasons should provide an account of the way in which actions and conclusions are supported by reasons together with their priorities, while at the same time, the priority relations among reasons are established by the same process of reasoning they serve to guide. This may sound complicated—perhaps forbiddingly so, perhaps circular—but it turns out to be doable, and perhaps in more than one way. The issue was not addressed by Pollock, who adopts the common view that the weight of a reason is fixed, either by convention or as part of its nature, not something that is itself to be established through reasoning.15 But a manageable account is provided by Horty, based on previous work in the field of artificial intelligence and law.16 A different approach is sketched by Schroeder.17

We turn now to the properties that a priority ordering on reasons, whatever its source, might be expected to satisfy. Where *r, r*′, and *r*″ are reasons, it is natural, first of all, to suppose that this ordering should be *transitive*, so that, if *r*′ has a higher priority than *r* and *r*″ has a higher priority than *r*′, then *r*″ has a higher priority than *r*; and it seems equally natural to assume that the ordering satisfies the property of *irreflexivity*, according to

which it is not the case that *r* has a higher priority than *r*. An ordering relation that is both transitive and irreflexive is referred to as a *strict partial ordering*.

Should we assume any other properties in the priority orderings? In particular, should we assume that this ordering satisfies the property of *connectivity*, according to which we could suppose, for any distinct reasons *r* and *r*′, that either *r* or *r*′ has a higher priority than the other? Here we reach an important branch point in our discussion. On one hand, this connectivity assumption would allow for a straightforward resolution to any potential conflicts among default rules. What the assumption tells us is that, of any two such rules and their corresponding reasons, one is always stronger than the other; and so it would be natural, in case of a conflict, to settle the matter simply by favoring the stronger of the two. On the other hand, connectivity is not particularly plausible, in either the practical or the epistemic domain, and for two reasons.

First of all, some reasons seem simply to be incommensurable. The canonical example in the practical domain is Jean-Paul Sartre's description of a student during the Second **(p. 78)** World War who felt for reasons of patriotism and vengeance (his brother had been killed by the Germans) that he ought to leave home to fight with the Free French, but who also felt, for reasons of sympathy and personal devotion, that he ought to stay at home to care for his mother.18 Sartre presents the situation in a vivid way that really does make it seem as if the reasons confronting the student derive from entirely separate sources of value—duty to country versus duty to family—and cannot meaningfully be compared in importance.

It is more difficult to construct a plausible example of incommensurability in the epistemic domain, but consider a hypothetical election between two candidates in an isolated congressional district. Suppose that the Associated Press poll strongly favors Candidate 1 while an experienced local politician, who is neutral in the contest, confidently predicts a victory for Candidate 2. Modern statistical polling is exacting and scientific, but it can yield incorrect results in unfamiliar situations, where parameters might not have been set properly to reflect local circumstances. The politician, by contrast, has an intuitive and historically grounded sense of his community, which we can suppose he has relied on throughout his successful career, but opinions might have shifted in ways of which he is not aware, and which a survey would detect. A situation like this, then, would seem to present us with conflicting epistemic reasons, deriving from entirely different sources, which are at least arguably incomparable.

The second reason for questioning connectivity is that even if conflicting reasons are in fact comparable in strength, they might nevertheless violate the connectivity property, according to which one or the other must be stronger, simply by having equal strength. As an example from the practical domain, suppose you have inadvertently promised to have a private dinner tonight with each of two identical and identically situated twins, both of whom would now be equally disappointed by your cancellation; the situation can be made arbitrarily symmetrical.19 You now have two reasons, based on your promises, that favor two conflicting actions: having a private dinner with Twin 1, or having a private dinner

with Twin 2. Since these reasons are of exactly the same kind, they can meaningfully be compared in priority. But given the symmetry of the situation, it is hard to see how either should be assigned a higher priority than the other.

It is, again, a bit harder to find convincing examples of equally weighted, conflicting reasons in the epistemic domain, but consider this. Suppose you plan to have lunch with two friends, at a place selected by the two of them. Imagine that, as lunch time approaches, you receive two text messages, one from each friend. The first reads, "We'll be at Mark's Kitchen, meet us there," and the second, "We'll be at Everyday Gourmet, meet us there." A check of the time stamps shows that the two messages were sent simultaneously—and at this point your phone battery dies, so that you can neither inquire nor receive any further corrections. You are now faced with a practical decision: where should you go? But the answer hinges on an epistemic question: where will **(p. 79)** your friends be? And in considering this question you seem to be faced once again with two reasons, the text messages sent by your equally reliable friends, identical in strength but supporting conflicting conclusions.

## **3.5 Reason Accrual**

In light of the apparent counterexamples to connectivity, it seems tempting to conclude that the priority relation on reasons satisfies only the two strict partial ordering constraints, transitivity and irreflexivity, allowing for the possibility of reasons that are either incomparable or identical in priority. This conclusion would challenge the metaphor according to which the strength or force of a reason can be taken as a kind of weight, since it is so central to the notion of a weight that two weights can be compared, or combined. There are also, however, arguments that support the metaphor of reasons as possessing weights. The most powerful of these centers around the idea of reason accrual.

Consider an example: Max been invited to the wedding of a distant relative at a difficult time of year. He is not particularly close to this relative and, since the wedding falls at such an inconvenient time, would rather not go. But suppose he learns that the guests will include his two old aunts, Olive and Petunia, whose company he enjoys and who he knows would like to see him. Here it is perfectly sensible to imagine that, even though Max would choose not to attend the wedding if only one of the two aunts were going, the chance to see both Olive and Petunia in the same trip offers enough value to compensate for the inconvenience of the trip itself.

How can this example be understood from the standpoint of reasons? It is simplest to assume that Max is working with three reasons: the inconvenience of the trip, which favors not going, the prospect of seeing Olive, which favors going, and the prospect of seeing Petunia, which favors going. If we suppose that the inconvenience of the trip has higher priority than the prospect of seeing either aunt individually, then it appears that he should not go, since each of the reasons he has for going—seeing Olive, seeing Petunia is defeated by a stronger reason not to. But of course, this is the wrong result. Although

the inconvenience of the trip would outweigh the benefit of seeing either Olive or Petunia individually, it does not outweigh the benefit of seeing them together.

This is an example which the model that assigns weights to reasons fits very well. One can almost picture a scale on which the inconvenience of the trip is balanced against, and outweighs, the benefits of seeing Aunt Olive alone, and then watching as the value of seeing Aunt Petunia as well is added to the scale and the balance slowly tips to the other side, favoring the trip after all. The problem with the picture that assigns to reasons only priorities is that it does not explain how the priorities associated with a number of different reasons can be combined—much as weights can be combined—to defeat another reason that is capable of defeating each of the initial reasons, considered individually.

**(p. 80)** We might, of course, assume that the example should be understood as presenting Max with a fourth reason: not just the prospect of seeing Olive and the prospect of seeing Petunia, but the prospect of seeing both Olive and Petunia—which also favors going to the wedding, and which, we can suppose, carries a higher priority than the inconvenience of the trip. We would then reach the correct conclusion that Max should go to the wedding, since his only reason for not going, the inconvenience of the trip, would be defeated by a stronger reason for going.

In a way, though, this representation of the example simply relocates the issue. The question, now, concerns the relation between this new reason for going to the wedding, the presence of Olive and Petunia, and the previous reasons provided by the presence of Olive and the presence of Petunia. One option is to suppose that the new reason is entirely independent of the previous two. This option has the advantage of simplicity, and, as its sole disadvantage, a significant degree of implausibility: can we really say that the reason arising from the presence of Olive and Petunia together has nothing at all to do with the separate reasons arising from the presence of Olive and of Petunia?

The other option, of course, is to suppose that the complex reason arising from the presence of Olive and Petunia together, along with its place in the priority ordering, is derived, somehow, from the simpler reasons provided the presence of Olive and of Petunia, along with their priorities. This option carries more initial plausibility, but raises a number of difficult issues. Surely, not just any two reasons favoring some outcome can be combined to form a stronger reason favoring that outcome, and sometimes reasons that favor a particular outcome when taken individually favor another outcome entirely when taken together. Suppose, for example, that Symptom 1 is a reason for the administration of Drug A, since it suggests Disease 1, for which Drug A is appropriate, and that Symptom 2 is also a reason for the administration of Drug A, since it suggests Disease 2, for which Drug A is also appropriate; still, it might be that Symptoms 1 and 2 appearing together suggest Disease 3, for which Drug A is not appropriate.20

If reasons can indeed be composed into complexes, it is clear that the behavior of the complexes is not easily predictable from that of the components: some complex reasons, such as seeing Olive and Petunia together, form stronger reasons supporting the same conclusions as their components, while others, such as Symptoms 1 and 2, actually inter

fere with the support provided by their component reasons. Anyone favoring the option of reason composition would therefore, at some point, have to provide a careful description of the process, and of the constraints governing this process. Which reasons can properly be composed and which cannot? And how is the priority of a complex reason influenced by the priority of its components? These are difficult questions, and we are not aware of any successful attempt to answer them in the literature.21

## **(p. 81) 3.6 Undercutting Defeat**

A reason is undercut when it is, simply, removed from consideration—defeated, without being rebutted by any stronger reason supporting a conflicting conclusion. The concept was illustrated earlier by the situation in which Eric asserts that Tweety is a bird, but Rachael asserts that Eric is unreliable. Here, Rachael's assertion can be seen as undercutting Eric's assertion as a reason for concluding that Tweety is a bird, removing it from consideration, and so defeating it, without providing any reason at all for the contrary conclusion that Tweety is not a bird.

The relations between undercutting defeat and ordinary rebutting defeat can be complicated. In our previous example, Rachael's assertion functioned as an undercutter, providing a reason for removing Eric's assertion from consideration as a reason supporting the conclusion that Tweety is a bird. But suppose that Susan now asserts that Rachael is unreliable. In that case, Susan's assertion would function as an undercutter undercutter, providing a reason for removing Rachael's assertion from consideration as a reason for removing Eric's assertion from consideration as a reason for the conclusion that Tweety is a bird, and so allowing Eric's assertion to re-emerge as a reason. By contrast, suppose that Susan, who is more reliable than Rachael, had contradicted Rachael's statement by asserting that Eric is, in fact, reliable. Susan's assertion would then function as an undercutter rebutter, defeating Rachael's assertion by providing a stronger reason supporting a conflicting conclusion. Having been provided with simple examples of undercutter undercutters and undercutter rebutters, the reader is now invited to fashion for him or herself examples of rebutter undercutters, rebutter rebutters, and even more elaborate examples.

Although the concept of undercutting defeat was first highlighted by Pollock, as mentioned earlier, the idea (or a very similar idea) is also discussed in the literature on practical reasoning, where it is considered as part of the general topic of *exclusionary* reasons, introduced by Raz.22 Raz motivates the concept through a number of examples, but we consider here only the representative case of Colin, who must decide whether to send his son to a private school. We are to imagine that there are various reasons pro and con. On one hand, the school will provide an excellent education for Colin's son, as well as an opportunity to meet a more varied group of friends; on the other hand, the tuition **(p. 82)** fee is high, and Colin is concerned that a decision to send his own son to a private school might serve to undermine his support for public education more generally.

However, Raz asks us to imagine also that, in addition to these ordinary reasons pro and con, Colin has promised his wife that, in all decisions regarding the education of his son, he will consider only those reasons that bear directly on his son's interests. And this promise, Raz believes, cannot properly be viewed as just another one of the ordinary reasons for sending his son to the private school, like the fact that the school provides a good education. It must be viewed, instead, as a reason of an entirely different sort—a "secondorder" reason, according to Raz, for excluding from consideration all those ordinary, or "first-order," reasons that do not bear on the interests of Colin's son. Just as, once Rachael tells you that Eric is unreliable, you should disregard Eric's statement as a reason for concluding that Tweety is a penguin, Colin's promise should lead him, likewise, to disregard those reasons that do not bear on the interests of his son. An exclusionary reason, on this interpretation, is nothing but an undercutting defeater in the practical domain.

Given a collection of reasons, some of which undercut, or exclude, others, how are we to determine what actions or conclusions are supported? In fact, the logic mentioned earlier, due to Pollock and by Horty, both address this issue. Pollock's theory has broader coverage, since it provides an account of certain collections of reasons that Horty's theory fails to treat. For example, suppose Eric asserts that he is unreliable, so that his assertion provides us with a reason for the conclusion that he is unreliable, which is itself, then, an undercutter—a reason for removing his assertion from consideration as a reason for the conclusion that he is unreliable. Pollock's theory provides an account of this example; Horty's does not. On the other hand, Horty's theory offers a unified treatment of undercutting defeat in epistemology and exclusion in practical reasoning. In addition, since Horty allows reasoning about the priority of reasons, he is able to explore certain issues about how reasoning about priority interacts with reasoning about exclusion.

Pollock and Horty also differ about one narrow, but very interesting issue.23 It is part of the idea of ordinary rebutting defeat, of course, that a reason supporting a particular action or conclusion cannot be rebutted by a weaker reason. For example, if Eric says that Tweety is a bird and Rachael says that he is not, then if Rachael is less reliable than Eric, the reason supplied by Rachael's statement does not rebut that supplied by Eric's. But can a reason be undercut, or excluded, by a weaker reason? Where Rachael remains less reliable than Eric, again suppose that Eric says that Tweety is a bird, but that what Rachael says, this time, is that Eric is unreliable. Can the reason supplied by Rachael's statement, in this case, undercut the reason supplied by Eric's, even though it is weaker? In a way, it is hard to see why strength of reasons should matter at all, since Eric and Rachael are not even talking about the same things—Eric is talking about whether or not Tweety is a bird, while Rachael is talking about the entirely different topic of whether **(p. 83)** or not Eric is trustworthy. Nevertheless, it can seem odd that the less reliable Rachael should be able to undercut the more reliable Eric. Pollock offers an argument for why undercutters can be no weaker than the reasons they undercut, and builds this condition into his definition of undercutting defeat. Horty abandons this condition, questions Pollock's argument, and attempts to explain our intuitions of oddity in a different way.

The issue is, again, narrow, and somewhat technical, but it gives an indication of the kind of detailed question that anyone hoping to develop a logic of reasons must address.

## **References**

Baier, Kurt (1958). *The Moral Point of View: A Rational Basis of Ethics*. Ithaca, NY: Cornell University Press.

Brewka, Gerhard (1994). "Reasoning about Priorities in Default Logic." In *Proceedings of the Twelveth National Conference on Artificial Intelligence (AAAI-94)*, 940–5. Cambridge, Mass.: AAAI/MIT Press.

Cariani, Fabrizio (2013). "*Ought* and Resolution Semantics." *Nous* 47: 534–58.Chisholm, Roderick (1964). "The Ethics of Requirement." *American Philosophical Quarterly* 1: 147– 53.

Chisholm, Roderick (1974). "Practical Reason and the Logic of Requirement." In Stephan Körner (ed.), *Practical Reason*, 2–13. Oxford: Blackwell. Repr. in Joseph Raz (ed.), *Practical Reasoning* (Oxford: Oxford University Press, 1978).

Dancy, Jonathan (2004). *Ethics Without Principles*. Oxford: Clarendon Press.

Edmundson, William (1993). "Rethinking Exclusionary Reasons: A Second Edition of Joseph Raz's *Practical Reason and Norms*." *Law and Philosophy* 12: 329–43.

Gans, Chaim (1986). "Mandatory Rules and Exclusionary Reasons." *Philosophia* 615: 373– 94.

Goble, Lou (2004). "A Proposal for Dealing with Deontic Dilemmas." In Allessio Lomuscio and Donald Nute (eds), *Deontic Logic in Computer Science: 7th International Workshop on Deontic Logic in Computer Science, DEON 2004 (LNAI 3065)*, 74–113. Berlin: Springer-Verlag.

Goble, Lou (2014). "Prima Facie Norms, Normative Conflicts, and Dilemmas." In Dov Gabbay, John Horty, Xavier Parent, Ron van der Meyden, and Leendert van der Torre (eds), *Handbook of Deontic Logic and Normative Systems*, 241–351. London: College Publications.

Gordon, Thomas (1993). *The Pleadings Game: An Artificial-Intelligence Model of Procedural Justice*. PhD thesis, Technische Hochschule Darmstadt.

Harman, Gilbert (1975). "Reasons." *Critica* 7: 3–18. Repr. 1978 in Joseph Raz (ed.), *Practical Reasoning*. Oxford: Oxford University Press. Pagination refers to this version.

Horty, John (1993). "Deontic Logic as Founded on Nonmonotonic Logic." *Annals of Mathematics and Artificial Intelligence* 9: 69–91.

Horty, John (2012). *Reasons as Defaults*. New York: Oxford University Press.

Marcus, Ruth Barcan (1980). "Moral Dilemmas and Consistency." *Journal of Philosophy* 77: 121–36.

Moore, Michael (1989). "Authority, Law, and Razian Reasons." *Southern California Law Review* 62: 827–96.

Nair, Shyam (2016a). "Conflicting Reasons, Unconflicting Oughts." *Philosophical Studies* 173(3): 629–63.

Nair, Shyam (2016b). "How Do Reasons Accrue?" In Errol Lord and Barry Maguire (eds), *Weighing Reasons*, 56–73. New York: Oxford University Press.

**(p. 84)** Perry, Stephen (1987). "Judicial Obligation, Precedent, and the Common Law." *Oxford Journal of Legal Studies* 7: 215–57.

Perry, Stephen (1989). "Second-Order Reasons, Uncertainty, and Legal Theory." *Southern California Law Review* 62: 913–94.

Pollock, John (1970). "The Structure of Epistemic Justification." In *Studies in the Theory of Knowledge*, no. 4, 62–78. Oxford: Blackwell.

Pollock, John (1987). "Defeasible Reasoning." *Cognitive Science* 11: 481–518.

Pollock, John (1994). "Justification and Defeat." *Artificial Intelligence* 67: 377–407.

Pollock, John (1995). *Cognitive Carpentry: A Blueprint for How to Build a Person*. Cambridge Mass.: MIT Press.

Pollock, John (2001). "Defeasible Reasoning with Variable Degrees of Justification." *Artificial Intelligence* 133: 233–82.

Pollock, John (2009). "A Recursive Semantics for Defeasible Reasoning." Unpublished MS.

Prakken, Henry, and Giovanni Sartor (1995). "On the Relation between Legal Language and Legal Argument: Assumptions, Applicability, and Dynamic Priorities." In *Proceedings of the Fifth International Conference on Artificial Intelligence and Law (ICAIL-95)*, 1–10. New York: ACM Press.

Prakken, Henry, and Giovanni Sartor (1996). "A Dialectical Model of Assessing Conflicting Arguments in Legal Reasoning." *Artificial Intelligence and Law* 4: 331–68.

Raz, Joseph (1975). *Practical Reasoning and Norms*. London: Hutchinson. 2nd edn with new postscript published in 1990 by Princeton University Press, and repr. by Oxford University Press in 2002; pagination refers to the Oxford edn.

Raz, Joseph (1989). "Facing Up: A Reply." *Southern California Law Review* 62: 1153–235.

Reiter, Raymond (1980). "A Logic for Default Reasoning." *Artificial Intelligence* 13: 81– 132.

Sartre, Jean-Paul (1946). *L'Existentialisme est un Humanisme*. Paris: Nagel. Translated as *Existentialism is a Humanism* in W. Kaufmann (ed.), *Existentialism from Dostoevsky to Sartre*, 345–68. New York: Meridian Press, 1975.

Schroeder, Mark (2007). *Slaves of the Passions*. New York: Oxford University Press.

Skourpski, John (1997). "Reasons and Reason." In Garrett Cullity and Berys Gaut (eds), *Ethics and Practical Reason*, 345–68. Oxford: Oxford University Press.

Thomason, Richmond (2000). "Desires and Defaults: A Framework for Planning with Inferred Goals." In *Proceedings of the Seventh International Conference on Principles of Knowledge Representation and Reasoning (KR-2000)*, 702–13. Burlington, Mass.: Morgan Kaufmann.

## **Notes:**

[^1]: See e.g. Baier (1958: 102), Harman (1975: 112), and Schroeder (2007: 130).

[^2]: This process of reasoning is described as "wishful thinking" in Thomason (2000).

[^3]: See Pollock (1970) for an initial discussion of his distinction between rebutting and undercutting defeat; his own treatment of these ideas is developed in detail in later work, such as Pollock (1995).

[^4]: See the discussion in Dancy (2004: ch. 5).

[^5]: Again, see Dancy (2004: ch. 5).

[^6]: Pollock's initial account can be found in his (1987); this account was superseded by that of Pollock (1994), which is presented in more detail in Pollock (1995), generally taken as providing the canonical version of his theory. In fact, however, Pollock continued to refine his approach in later papers including (2001) and (2009). Horty's account is described most completely in his (2012); this account is based on the default logic introduced by Reiter (1980).

[^7]: The reader who is interested in these issues should consult Schroeder, Ch. 2 this volume, where they are discussed in detail.

[^8]: See Chisholm (1964: 149, 1974: 125).

[^9]: See e.g. Baier (1958: 102), Harman (1975: 112), and Schroeder (2007: 130).

[^10]: A special area of interest concerns the relations among non-instrumental and instrumental reasons—among, that is, reasons deriving directly from goals, or ends, and reasons bearing on means toward those ends. This topic is discussed in greater detail by Kolodny (Ch. 31 this volume).

[^11]: An encyclopedic discussion of normative conflicts in deontic logic can be found in Goble (2014).

[^12]: A similar example appears in Cariani 2013: n. 1.

[^13]: These examples comes from van Fraassen 1973: p. 18 by way of Horty 1993: p. 73 and Goble 2004: p. 80.

[^14]: As we have emphasized, the problem of conflicting reasons is structurally analogous to the problem of conflicting obligations in deontic logic. This suggests that it is promising to think that some of the proposals recently developed for handling conflicts within deontic logic might be adapted to handle conflicts among reasons as well. See, again, Goble (2014) for a survey of recent treatments of conflicting oughts within deontic logic; see Nair (2016a) for an attempt to adapt one of these to the problems presented by conflicting reasons.

[^15]: See e.g. Baier (1958: 106) for the suggestion that the strength of reasons is determined by the "social environment," as well as Skorupski (1997), who works with a model of reasons according to which the weight of a reason is, in a sense, part of its nature.

[^16]: See Horty (2012: ch. 5). The particular approach presented there draws on techniques introduced by Gordon (1993) in his analysis of legal reasoning; these techniques have been refined and developed by a number of people, notably including Brewka (1994) as well as Prakken and Sartor (1995, 1996).

[^17]: See the treatment of "weight recursion" in Schroeder (2007: ch. 5).

[^18]: The example is from Sartre (1946).

[^19]: The importance of symmetrical cases like this in practical reasoning was emphasized by Marcus (1980).

[^20]: As Dancy (2004: 15) writes, "reasons are like rats, at least to the extent that two rats that are supposedly on the same side may in fact turn and fight among themselves."

[^21]: Among writers who have discussed this issue, most take the first of our two options: Pollock (1995: 101–2) treats complex reasons, along with their priorities, as independent of the simpler reasons that might naturally be taken as their components; Schroeder (2007: ch. 7) works with a model in which weights are assigned directly to sets of reasons, rather than to individual reasons, but again does not relate the weight of a set of reasons to the weight of the singleton sets constructed from the reasons belonging to that set. A more recent discussion of this issue can be found in Nair (2016b).

[^22]: See Raz (1975: sect. 1.2) for his initial discussion. The topic has spawned an extensive secondary literature, notably including papers by Gans (1986), Moore (1989), and Perry (1987, 1989), subsequent elaborations by Raz himself, both in his (1989) and in a postscript to the second edition of his (1975), and a review of the latter by Edmundson (1993).

[^23]: See Pollock (1995: 103–4) and Horty (2012: 135–41).

---

# 4. The Language of “Ought,” and Reasons

*Aaron Bronfman and J. L. Dowell*

### **Abstract and Keywords**

The bulk of this chapter addresses the question: what is the proper semantics for deontic modal expressions in English? We consider a representative sample of recent challenges to a Kratzer-style formal semantics for modal expressions, as well as the rival views—Fabrizio Cariani's contrastivism, John MacFarlane's relativism, and Mark Schroeder's ambiguity theory—those challenges are thought to motivate. We argue that the challenges can be met and that the rival views face challenges of their own. Our overall conclusion is that a Kratzer-style semantics remains the one to beat. With this assumption in place, we turn to the question: what is the connection between true deontic modal statements and normative reasons? We argue that acceptance of Kratzer's semantics for deontic modals can, in many cases, leave open for substantive normative theorizing the question of whether an agent has a normative reason to comply with what she ought to do.

Keywords: contextualism, contrastivism, deontic modals, Kratzer, ought, reasons, relativism

## **4.1 Introduction**

Here we focus on two questions. What is the proper semantics for deontic modal expressions in English? And what is the connection between true deontic modal statements and normative reasons? Our contribution toward thinking about the first, which makes up the bulk of our chapter, considers a representative sample of recent challenges to a Kratzerstyle formal semantics for modal expressions,1 as well as the rival views—Fabrizio Cariani's contrastivism, John MacFarlane's relativism, and Mark Schroeder's ambiguity theory—those challenges are thought to motivate. Here we argue that a Kratzer-style view is able to meet all of the challenges we'll consider. In addition, we'll identify challenges for each of those rival views. Our overall conclusion is that a Kratzer-style semantics remains the one to beat.

With this assumption in place, we then ask how we should understand the relationship between true deontic modal statements and normative reasons. Should, for example, we hold that the truth of such a statement entails the existence of a normative reason for

some agent to comply? Here we argue that, in many cases, acceptance of Kratzer's semantics for deontic modals leaves open for substantive normative theorizing the question of whether an agent has a normative reason to comply with what she ought to do.

## **(p. 86) 4.2 Kratzer's Modal Semantics**

On Angelika Kratzer's canonical semantics for modal expressions, such expressions are themselves semantically neutral; they make a single contribution to the determination of a proposition on every occasion of use. What modulates the type of modality expressed teleological, bouletic, deontic, epistemic, or alethic—is the context of use. The plausibility of the resulting view lies in part in its power, its ability to provide simple and highly unified explanations of a wide range of language use. Together with broad cross-linguistic support, the simplicity of Kratzer's semantics has made it the view to beat.

What's distinctive of a Kratzer-style semantics is its treatment of modal expressions as quantifiers over possibilities. Typically, those domains of quantification are restricted, and when the needed restriction isn't represented explicitly in the linguistic material, it's provided by context. The contextual supplementation is twofold. First, context determines a modal base, *f*, a function from a world of evaluation to a set of worlds, the modal background.

Modal bases may be epistemic or circumstantial. An epistemic modal base is a function that takes a world of evaluation *w* and returns the set of worlds consistent with the body of information in *w* that has some property or properties. Which properties are relevant is determined by which *f* is contextually selected; for example, that function may take the information that has the property of being the speaker's at a designated time in the world of evaluation as an argument and give us the set of worlds compatible with that information. Or it may take the speaker's and that of her interlocutors. In principle, any number of different *f*s might get selected by context. A circumstantial modal base is a value for *f* that takes a world of evaluation as an argument and delivers a set of worlds circumstantially alike in particular respects. Here, too, what makes a circumstance among the relevant ones at a world of evaluation will depend upon which *f* is contextually selected; for example, a particular value for *f* may make circumstances that determine causal relations between actions and outcomes at the world of evaluation relevant. The modal background in that case would be the set of worlds alike with respect to those circumstances.

A second source of contextual supplementation is an ordering source, a function *g* from a world of evaluation *w* to the set of best worlds in the modal background. Which features of a world *w* in the modal background put it among or not among the best worlds depends upon the value for *g*. For example, *g* might rank *w* depending upon how well some salient agent acts in accordance with the reasons she has or the obligations that apply to her in *w*. Or it might rank *w* in terms of how well it approximates some impartial ideal. The resulting best worlds make up the modal's domain. "Ought," the modal of concern here, functions like a universal quantifier over its domain of quantification: "ought p" comes

out true at a context–world pair just in case all of the best worlds as determined by that context and world are *p*-worlds.2

**(p. 87)** One set of challenges to Kratzer's semantics we'll consider stems not from its contextualism but from its commitment, real or apparent, to the validity of two formal principles, Inheritance and (what we'll call) "if p, ought p," so it will be helpful to discuss the connection between those principles and her semantics here. Inheritance says that whenever *p* entails *q, ought p* will entail *ought q*. To see that Kratzer's semantic validates Inheritance, suppose that *p* entails *q* and that "ought p" is true. In that case, since all the best worlds are *p*-worlds, all the best worlds will be *q*-worlds as well. So, "ought q" will also be true.

If we combine Kratzer's semantics with her antecedent-restrictor theory of the indicative conditional,3 prima facie at least, we also validate "if p, then ought p." Here's why: on the antecedent-restrictor theory of conditionals, the function of the antecedent is to restrict the domain of a covert necessity modal in the consequent. So, to see whether a conditional of the form "if p, then q" is true, we see whether every (relevant) *p*-world is also a *q*-world. If it is, then the conditional is true. If we assume that in a conditional of the form "if p, ought q," "ought" displaces the covert modal,4 then Kratzer's semantics for modals and indicatives validates "if p, then ought p." The antecedent of such conditionals restricts the modal background of "ought p" to *p*-worlds. However the worlds in that background are ordered, the best ones will also be *p*-worlds. So, "if p, ought p" will be true for any *p*.

A second type of challenge, one that is a challenge to Kratzer's contextualism, stems from cases in which it seems that the truth of a statement expressed using a deontic modal must be information-sensitive in some way. Parfit's miners scenario is a much-discussed recent example. In that scenario, ten miners are all trapped in a single shaft of a flooding mine, either Shaft A or Shaft B. The agent in the scenario ("Agent") does not know which they're in; each is equally likely to contain the miners. Agent has just enough sandbags to fully block the water from flooding one shaft. Blocking A will save all the miners, if they're in A, but kill them all, if they're in B. Blocking B will save all the miners, if they're in B, but kill them all, if they're in A. Doing nothing, in contrast, distributes the water evenly between the shafts. In that case, exactly one miner will be killed and the remaining saved. In considering this case, most report that "Agent ought to do nothing" seems true. Notice, though, that its truth requires some form of information-sensitivity. After all, there's an option that is guaranteed to do better than doing nothing, namely, blocking the shaft the miners are in. The problem, of course, is that blocking the shaft the miners are in is not an action Agent can knowingly perform. Given her limited information, it is better that she do nothing.

We discuss the challenge information-sensitive "ought"s may seem to pose to contextualism in some detail in our section on John MacFarlane's work. Here we merely **(p. 88)** note the way to mark the distinction between information-sensitive and information-insensitive deontic modals that we'll rely on in that discussion for the purposes of concreteness.

(There may, of course, be other, better ways of marking that distinction within a Kratzerstyle framework.)

*Subjective "ought"*: So-called "subjective" deontic modals have information-sensitive ordering sources. Such ordering sources treat bodies of information as features of worlds relevant for their comparative ranking.

*Objective "ought"*: So-called "objective" deontic modals have information-insensitive ordering sources. Such ordering sources treat bodies of information as irrelevant to a world's comparative ranking.

## **4.3 Cariani's Contrastivism**

Not all challenges to Kratzer's canonical semantics are challenges to its contextualism. Fabrizio Cariani's contrastivist view, for example, can be given a contextualist construal (2013: 538). A contrastivist view about some range of sentences of the form "A ought to φ" is any that holds that the truth of an utterance of such a sentence at some context– world pair is determined by a comparison, in light of some salient norms, between *φ*-ing and a restricted range of A's alternative options. Cariani's contrastivism in particular departs from Kratzer's own view by denying that "ought" and "must" are best treated as universal quantifiers over sets of restricted possibilities. Instead, on his view, *A ought to φ* comes out true just in case all of A's best options, according to the salient norms, are ways of *φ*-ing and no way of *φ*-ing is below the relevant benchmark, a cut-off point in the ranking over options those norms induce. The benchmark's role is to distinguish permissible from impermissible options (Cariani 2013: 540). On a contextualist construal of this view, the range of options, their ranking, and the benchmark in that ranking would all be selected as a function of the context of use.

The fundamental difference between Cariani's view and Kratzer's own is in the role the benchmark plays in determining the truth of ought statements. To see this, notice that one sort of value Kratzer's ordering source can take is one that would rank each world *w* in the modal background in terms of what an agent does in *w*—for example, how well what an agent does in *w* can be expected to be promote some value, or whether the agent's act in *w* conforms to some salient rule. Such a ranking would have the effect of ranking the same all worlds in which the agent performs the same action. This would mean that such an ordering source would, in effect, rank options, in Cariani's sense.5 Since these **(p. 89)** core aspects of contrastivism are representable within a Kratzerian framework, we'll focus here on Cariani's contrastivism and its feature not representable in that framework, namely, its benchmark.

Why introduce a benchmark? Cariani argues that the canonical quantifier view is unable to provide plausible explanations for three puzzle cases because those cases involve apparent failures of principles to which any Kratzer-style semantics is committed. Inheritance, recall, holds that if *p* entails *q*, then ought *p* entails ought *q*. Cariani considers two

rather famous puzzles for Inheritance: Ross's puzzle and Professor Procrastinate. The addition of the benchmark allows Cariani's contrastivism to reject Inheritance and thus, he argues, to provide plausible explanations of our judgments in those cases.

In addition, he considers a puzzle from conditional ought statements of the form "if p, then ought p," which a Kratzer-style semantics appears to validate. The addition of the benchmark, he argues, also allows his contrastivism to better fit with our judgments about uses of sentences with that form.

### **4.3.1 The Puzzles and Cariani's Contrastivism**

Consider first Cariani's version of Ross's puzzle. In his case, we are discussing Joan, who has paid "hefty fees to go to a famous school" (Cariani 2013: 535). In such a case, it seems true to say:

(ATTEND) Joan ought to attend her classes.

But if (ATTEND) is true and Inheritance holds, the following is also true:

(ATTEND OR BURN) Joan ought to either attend her classes or burn down the philosophy department.

And the trouble, Cariani suggests, is that ATTEND OR BURN appears to be false, since it appears to communicate "the categorical information that Joan has two ways of doing what she ought to" (p. 535). The benchmark earns its keep by providing principled grounds for accepting ATTEND, while rejecting ATTEND OR BURN: ATTEND comes out true because every relevant, best option is a Joan-attends-class option, while no relevant way of attending class is impermissible. ATTEND OR BURN, in contrast, comes out false, since there is a way of Joan's attending-or-burning, namely, burning, that we may assume is impermissible relative to salient norms, and so falls below the benchmark.

Professor Procrastinate seems to pose a second challenge to Inheritance. In Cariani's version of Jackson and Pargetter's famous case, Professor Procrastinate is invited to write a review for a book he is uniquely well qualified to review. However, Procrastinate suffers from a tendency to leave projects incomplete. So, if he accepts, it is extremely **(p. 90)** likely he will not write the review. If he declines, someone else will write the review, albeit someone less qualified than himself. What should he do? Here, many find themselves inclined to regard ACCEPT AND WRITE as true:

(ACCEPT AND WRITE) Procrastinate ought to accept and write.

At the same time, many also regard ACCEPT as false:

(ACCEPT) Procrastinate ought to accept.

This poses a prima facie problem for fans of Inheritance, as "accept and write" entails "accept," so ACCEPT AND WRITE's truth would seem to entail ACCEPT's. In contrast, Cariani argues that his view is able to explain these intuitions. In deliberating about what Procrastinate should do, accepting without writing is a salient option that is presumably ranked below the threshold of permissibility. So, ACCEPT comes out false because there is a way of accepting, namely, accepting and not writing, that is impermissible. In contrast, ACCEPT AND WRITE comes out true, as all of the best options are accepting-andwriting options, while no way of accepting and writing is ranked below the benchmark.

Finally, Cariani argues, acceptance of the standard antecedent-restrictor theory of conditionals plus Kratzer's semantics "implies the logical validity of the schema 'if p, ought p' " (p. 536). If that's right, then the Kratzerian is committed to the truth of statements such as:

(POISON) If you drink a bucket of poison, you ought to drink a bucket of poison.

But POISON seems, at the very least, awkward to assert. In contrast, Cariani suggests, "what suffices to explain the falsity of [POISON, and so its awkwardness] on my view is that 'drinking a bucket of poison' is an impermissible relevant option—it is not only antecedently impermissible, but it is also conditionally impermissible" (p. 541).

### **4.3.2 Assessing Cariani's Contrastivism and Expanding the Range of Cases**

How should a Kratzerian respond to these puzzles? One way to comparatively assess semantic theories is to see how well each fits with speakers' reactions not only in the puzzle cases, but also in neighboring cases. Does it fit with speakers' reactions in those cases? If so, does it require additional explanatory resources to secure that fit? Absent a story about how the benchmark gets set for particular cases independently of generating results that fit with the data, it's hard to say definitively what Cariani's semantics predicts for particular, neighboring cases. Here we note a few such cases that place pressure on **(p. 91)** Cariani to revise his contrastivism in ways that make it more closely resemble Kratzer's canonical view.

First, it's important to notice that Cariani's view allows for suboptimal options that are above the benchmark.6 This creates room for a case like his Joan example, but in which the suboptimal option is above the benchmark. Here's one candidate for such a case: imagine, as before, we're wondering what Joan should do, given that she's paying hefty fees to attend a famous school. There's no assignment due tomorrow, nor is there an exam or a review for an exam. It still seems one can truly say:

(ATTEND) Joan ought to attend her classes.

But consider:

(ATTEND OR WATCH) Joan ought to either attend her classes or stay home and watch cartoons.

In a conversational context in which the value of Joan's educational opportunities is emphasized, asserting ATTEND OR WATCH is somewhat awkward, at least for one who holds that disjunctions such as ATTEND OR BURN and ATTEND OR WATCH communicate the information "that Joan has two ways of doing what she ought." Here, staying home and watching cartoons does not seem to be a way of doing what Joan ought. Even so, it may be that staying home, while suboptimal, is permissible. After all, Joan has no assignment due tomorrow, nor does she have an exam or an exam review. If so, then with the benchmark set as Cariani proposes, as the cut-off for permissibility, staying home will be a suboptimal option above the benchmark. But this will make ATTEND OR WATCH true, on his view: every optimal option is a way of either attending classes or staying home, and no way of attending classes or staying home is below the benchmark. Cariani will then need a non-truth-conditional explanation for why ATTEND OR WATCH is awkward to assert. Indeed, as we'll see, this is the Kratzerian's preferred option. For now, though, notice that, for Cariani, this is an explanation that fails to pattern with and requires different resources from his truth-conditional explanation for our willingness to assert ATTEND while being unwilling to assert ATTEND OR BURN.

Alternatively, Cariani might endorse a somewhat higher standard for the benchmark, placing it above staying home but below optimality. While this would render ATTEND OR WATCH false, and hence avoid the need for a non-truth-conditional explanation of its awkwardness, it stands to regenerate the issue for other sentences involving a suboptimal disjunct above the benchmark. For example, if attending her classes while occasionally texting is suboptimal, but above the benchmark, then: **(p. 92)**

(ATTEND OR TEXT) Joan ought to either attend her classes while paying close attention or attend her classes while occasionally texting.

will come out true. But this latter sentence remains awkward to assert in a context where the value of Joan's educational opportunities is emphasized, and so a non-truth-conditional explanation of its awkwardness will again be needed.

Cariani could avoid this kind of difficulty by setting the benchmark at optimality. However, this way of thinking of the benchmark has a representation in Kratzer's framework: the ordering source already distinguishes best from non-best worlds in a modal background. So addressing the problem in this way brings Cariani's view closer to Kratzer's own.

Consider now Professor Procrastinate and a few neighboring cases. In the original case, Cariani suggests, the ranking of the options is:

"Accept and write > do not accept > benchmark > accept without writing" (p. 541)

In that case, ACCEPT AND WRITE seems true, though ACCEPT false (or at least awkward to assert) because it is extremely unlikely that Professor Procrastinate would write the review. What, though, about asserting:

(DECLINE) Procrastinate ought to decline.

Or what about asserting:

(NOT THE CASE ACCEPT) It's not the case that Procrastinate ought to accept.

Certainly, when we are hearing ACCEPT as awkward to assert, DECLINE and NOT THE CASE ACCEPT sound fine—indeed, arguably more than fine, the right sort of things to say. But both will come out false in the context as described by Cariani, as none of the best options are declining options or not accepting options. This is puzzling: it's false that Procrastinate should accept, that it's not the case that he should accept, and that he should decline. Is there no fact of the matter, in this case, about what he should do? Setting the benchmark at optimality won't help here: DECLINE and NOT THE CASE AC-CEPT will each still come out false, both because it is still true that none of the best options are declining/not accepting options and now also because declining/not accepting will fall below the benchmark.

Or what about a case in which it's very likely that Procrastinate *would* write, though not impossible that he wouldn't? If the options, ranking, and benchmark for this case are the same as in Cariani's original, ACCEPT will still come out false, as it will still be true that there is a way of accepting, that is, accepting and not writing, that is a relevant option below the benchmark. But, in contrast to the original case, asserting ACCEPT here seems fine—indeed, the right thing to assert.

**(p. 93)** Or imagine, again in a case in which it is very likely that Procrastinate would write, one says:

(ACCEPT-AND-WRITE OR DECLINE) Procrastinate ought either to accept and write or to decline.

Here, holding the ranking, options, and benchmark fixed, ACCEPT-AND-WRITE OR DE-CLINE will come out true, on Cariani's account. But ACCEPT-AND-WRITE OR DECLINE seems awkward, as it seems to communicate, counterintuitively, that declining is a way for Procrastinate to do as he ought. Here, too, one response would be to join forces with the Kratzerian and provide some non-truth-conditional explanation for its awkwardness to assert. Or Cariani could hold that one of the benchmark, ranking, or options in this variation differ from those in the original case in some way that makes ACCEPT come out true here, for example, by holding that accepting and not writing is no longer a relevant option. But absent an independently plausible story about how those values get selected, and given that the possibility of his accepting and not writing has been raised and is being taken into account in his deliberations, such a response seems a bit ad hoc. Given the similarity of the cases, a more unified explanation would seem preferable.

Finally, recall Cariani's conditional ought sentence:

(POISON) If you drink a bucket of poison, you ought to drink a bucket of poison.

POISON is false on his view, because drinking a bucket of poison is impermissible and so below the benchmark. Consider now a variation on POISON:

(PAINLESS POISON) If you drink a bucket of poison, you ought to drink a bucket of painless poison.

Here, PAINLESS POISON seems true (though in some cases not advisable to assert). But if we assume in a normal case that drinking a bucket of poison is impermissible, then drinking a bucket of painless poison would seem to be impermissible as well. If that's so, then PAINLESS POISON will be false, on Cariani's view.

Cariani does have additional resources to distinguish the two, however. Elsewhere he considers a different variation on POISON that would also seem to come out true, on his view:

(COFFEE) If you drink a cup of coffee, you ought to drink a cup of coffee.

That's because drinking coffee is generally permissible. To explain the apparent awkwardness of asserting COFFEE, Cariani considers an antecedent restrictor view of conditionals together with a diversity condition. A diversity condition would require **(p. 94)** that for "you ought to φ" to be true, A must have non-φ options.7 Putting these together, in order for "if p, you ought to φ" to be true, there must be a non-φ option compatible with *p* (Cariani 2013: 553). This would allow him to explain the awkwardness of asserting POISON, in contrast to asserting PAINLESS POISON, by noting that POISON, given an antecedent restrictor view of conditionals, would fail to satisfy that diversity condition. PAINLESS POISON, however, would meet it: after we have thrown out all of the non-poison drinking options, one still might have both painless and painful poison drinking options. Notice, however, that this explanation of our unwillingness to assert POISON is one in which no appeal to the benchmark is made. The benchmark, though, is what marks the crucial difference between a Kratzerian view and Cariani's. This means that the most plausible explanation available from within Cariani's explanatory resources for why PAIN-LESS POISON sounds fine, in contrast to POISON, is equally available to the Kratzerian. This deprives iffy "ought"s such as POISON of their status as a source of evidence for Cariani's contrastivism over Kratzer's.

### **4.3.3 Kratzerian Solutions**

What should a Kratzerian say about these cases? As just noted and as Cariani acknowledges, a Kratzerian could equally appeal to a diversity condition to explain the awkwardness of asserting POISON in contrast to PAINLESS POISON.

Next, consider Joan, who has paid hefty fees to attend a famous school. As Cariani stipulates, attending class is an option that excludes the others; if she attends class, she will not stay at home, neither will she burn the department down. Consider the original case, in which ATTEND seems true. For this to be so, on Kratzer's view, all of the best worlds will need to be worlds in which Joan goes to class. This will mean that all of the best

worlds will be worlds in which Joan goes to class or in which she burns down the philosophy department (or in which she stays home and watches cartoons). So, relative to the parameter values that make ATTEND true, ATTEND OR BURN and ATTEND OR WATCH will be true as well. But if we hold that, to be a way of doing what one ought, an option must be represented among the best worlds, then neither burning down the department nor staying at home watching cartoons will be ways of doing as one ought. The explanation, then, for why ATTEND OR BURN and ATTEND OR WATCH seem awkward to assert is that, as Cariani notes, they seem to communicate that "Joan has two ways of doing as she ought." But she doesn't, on this way of thinking about what it takes for something to be "a way of doing as one ought."

So, while the Kratzerian is committed to the truth of ATTEND OR BURN and ATTEND OR WATCH, she isn't committed to the truth of all that asserting ATTEND OR BURN or AT-TEND OR WATCH would communicate. In particular, accepting with **(p. 95)** Cariani the assumption that "ought"-disjunctions communicate that an agent has two ways of doing as she ought, we have a short explanation for why asserting ATTEND OR BURN is awkward: it communicates, falsely, that burning down the philosophy department is a way for Joan to do as she ought. Prima facie, though, there is something further for the Kratzerian to explain that Cariani needn't. On Cariani's view, the reason why "ought p or q" communicates that an agent has two ways of doing as she ought is that it is part of the truthconditions for such sentences. Since, as we've seen, it isn't part of the truth-conditions of such sentences on Kratzer's semantics, we'll need some pragmatic explanation.

Providing a compelling case for the pragmatic explanation we favor is beyond the scope of this chapter. In particular, Cariani himself provides several arguments against a pragmatic strategy that would need to be addressed to fully mount such a case.8 Here we merely sketch the view we favor. But recall first that the above considerations suggest that, absent revision of how we are to think of the benchmark, Cariani's own view seems to require some non-truth-conditional explanation for the awkwardness of asserting disjunctions such as ATTEND OR WATCH or ACCEPT-AND-WRITE OR DECLINE.

Grice's first maxim of quantity enjoins speakers to make their assertions as informative as is "required for the purposes of conversation," while his second maxim of quality forbids them from asserting that for which they lack evidence. One way implicatures may be generated, he suggests, is when a speaker's providing as much information as the conversational purposes require would require asserting what she is not in a position to. In Grice's example,

A is planning with B an itinerary for a holiday in France. Both know that A wants to see his friend C, if to do so would not involve too great a prolongation of his journey:

**A:** Where does C live? **B:** Somewhere in the South of France. (Gloss: There is no reason to suppose that B is opting out; his answer is, as he well knows, less informative than is required to meet A's needs. This infringement of the first maxim of Quantity can be explained only by the supposition that B is aware that to be more informative would be to say something that infringed the second maxim of Quality. "Don't say what you lack adequate evidence for," so B implicates that he does not know in which town C lives.) (Grice 1989: 33)

In general, in asserting "p" when *p* is less informative than *q* and settling *whether q* is relevant for conversational purposes, a speaker implicates that she is not in a position to assert "q." On Kratzer's semantics, "ought p" is more informative than "ought p or q," since the former entails the latter, but not vice versa. If a speaker knew that *p* were the only way of doing as one ought, she would be in a position to assert "ought p." In **(p. 96)** asserting the weaker "ought p or q," a speaker implicates that she is not in a position to flat out assert either "ought p" or "ought q." So, if the speaker may be assumed to be knowledgeable about the situation, she implicates that neither *p* nor *q* is the sole way of doing as one ought, that is, that they are each ways of doing as one ought. Moreover, if a speaker is in a position to assert "ought p," she should do so instead of asserting "ought p or q," as in that case it is a more helpful instruction for doing as you ought.

One advantage of this explanation over Cariani's own is its unity: the explanation for why ATTEND OR BURN and ATTEND OR WATCH are awkward to assert is the same. In contrast, given his account of the benchmark as a cut-off for permissibility, Cariani would seem to hold that ATTEND OR BURN is awkward because false, while ATTEND OR WATCH and ACCEPT-AND-WRITE OR DECLINE are awkward for some non-truth-conditional reason.

Finally, what should a Kratzerian say about Professor Procrastinate? One thought would be that, when we are hearing ACCEPT AND WRITE as true, we are hearing it as an answer to a deliberative question like, "Which action, of the actions Professor Procrastinate could perform during the time it would take him to accept and write, can be expected to be most professionally responsible?" The Kratzerian can accommodate that: in such a case, she holds that a world *w*, in the modal background for ACCEPT AND WRITE, gets ranked on the basis of how well Procrastinate can be expected to discharge his professional responsibilities, given the action he performs in *w* during the relevant time period. All the best worlds in this ranking are worlds where Procrastinate accepts and writes, since given that Procrastinate accepts and writes, he is expected to perfectly fulfill his professional responsibilities, while no other course of action has this property. Because all the best worlds in the modal background for ACCEPT AND WRITE are accept and write worlds, ACCEPT AND WRITE comes out true.

In contrast, when we hear ACCEPT as false, we are hearing it as a candidate answer to a different question like, "Which action, of the actions Procrastinate could perform during the time it would take him to accept, can be expected to be most professionally responsible?" Here, a world *w* gets ranked on the basis of how well Procrastinate can be expected to discharge his professional responsibilities, given the action he performs in *w* during the

time it would take him to accept. None of the best worlds in this ranking are worlds where Procrastinate accepts, since given that Procrastinate accepts, it is very unlikely he will go on to write. Instead, the best worlds are all worlds where he declines. So, ACCEPT is false, while the following are each true:

(DECLINE) Procrastinate should decline.

(NOT THE CASE ACCEPT) It is not the case that Procrastinate should accept.

Of course, abandoning his explanation of this case and accepting ours is compatible with Cariani's semantic framework. But, since neither the benchmark nor a failure of Inheritance figures in that explanation, this would deprive him of appeal to Procrastinate as a source of evidence for Cariani's contrastivism over Kratzer's.

**(p. 97)** Summing up, we've suggested that, while Cariani's original view is able to fit with speakers' reactions to the original puzzle cases, it does much less well when we widen our scope to consider neighboring cases. In contrast, Kratzer's view, we've argued, plausibly fits with our reactions to the full range of cases. If we revise Cariani's account of how the benchmark is set, treating the new benchmark as a cut-off point for optimality rather than permissibility, the resulting view does much better. In particular, it is now able to provide truth-conditional explanations for the awkwardness of asserting ATTEND OR WATCH and ACCEPT-AND-WRITE OR DECLINE. But since such a cut-off point is already implicitly represented in Kratzer's framework, this way of making the view more plausible in effect brings it closer to her own.

Revising Cariani's contrastivism so that the benchmark is treated as a cut-off point for optimality does leave one remaining difference between the two views: are ATTEND OR BURN and ATTEND OR WATCH awkward to assert because false or because they each generate a false implicature? Assessing the comparative merits of these two views may rest on the ability of each to satisfy more general methodological principles, such as simplicity.

## **4.4 MacFarlane's Relativism**

John MacFarlane, based on joint work with Niko Kolodny, defends a relativist account of how the truth of deontic modal sentences is determined.9 On a contextualist semantics for some term, once the features of the context of utterance have been fixed, we need only a world to determine a truth-value for a declarative sentence containing it. In contrast, on a relativist account, we need something further. In the case of deontic modals, on MacFarlane's view, the further parameter value we need is a body of information. Parfit's miners scenario discussed above provides an illustration. On MacFarlane's view, a context–world pair is insufficient to determine a truth-value for "Agent ought to do nothing." In addition, we need a body of information, for example, Agent's information at the time of her deliberations. Different bodies of information will yield different truth-values, even holding a context and world fixed. For example, if the relevant body of information in

cludes the information that the miners are located in Shaft A, "Agent ought to do nothing" will come out false; relative to that body of information, "Agent ought to block A" seems true. Which body of information is relevant for determining truth is determined as a function of the context of assessment—the context from which the truth of a deontic modal utterance is assessed. If the information relevant from the context of assessment that Agent occupies when she asserts, "I ought to do nothing" is just her information, then, relative to that context of assessment, what she's said is true. However, if the information relevant at a different context of assessment is that of an **(p. 98)** assessor who knows the miners are in A, then, relative to that context of assessment, what Agent has said is false.

The information relevant at a context of assessment needn't be the assessor's, though. The variety of relativism MacFarlane defends is flexible: the body of information that partly determines the truth of a deontic modal sentence is that *relevant* at a context of assessment (MacFarlane 2014: 263). In some cases that information will be the assessor's, but in others it may be the information of the subject of the modal claim (p. 298).

For a contextualist, the relevance of bodies of information will be fixed by the context of utterance's contribution to the determination of content. Relativists, in contrast, are semantic invariantists; on their view, there can be no difference in the content of different uses of the same deontic modal sentence, at least none traceable to the contribution of the modal.10

MacFarlane's case for relativism has a negative and a positive component. First, he hopes to show that no well-worked-out rival to relativism fits with speakers' reactions to the full range of cases. Then he argues that relativism does. So, relativism is to be preferred as providing the best explanation of speakers' uses of such sentences.

Here our primary focus is on MacFarlane's challenges to contextualism. We'll argue that a suitably flexible, contextualist, Kratzerian view is able to fit with the full range of speakers' reactions to the challenge cases. We'll then briefly discuss his relativist-friendly explanations of some of the cases discussed, noting a few somewhat surprising features of those explanations. Finally, we'll note one common phenomenon that (we'll suggest) a contextualist view is better poised to explain. As we'll see, central to his case against the contextualist is the claim that contextualism can't explain the phenomenon exhibited by the much-discussed cases of faultless disagreement. Interestingly, though, the phenomenon his flexible relativism seems ill-suited to explain bears all of the hallmarks of such disagreement.

The fundamental problem with contextualism, MacFarlane argues, is that it does not explain the phenomenon of faultless disagreement between deliberators and advisors (or third-party assessors) in cases of modal sentences whose truth requires that they are information-sensitive in some way. We may think of MacFarlane's challenge as posing a dilemma for the contextualist. Disagreement requires a common subject matter. So when speakers share a strong sense that two parties sensibly disagree with their uses of "A ought to φ" and "no, A ought not to φ," a contextualist must hold that there is a single body of information each claim is sensitive to. But in some cases—namely, those involving

eavesdroppers of whose existence a speaker is unaware—it won't be plausible for both utterances to be sensitive to the same body of information. That's because holding that the body of information that the speaker's utterance is relative to includes that of the eavesdropper would make that speaker's assertion unwarranted. **(p. 99)** But the cases in question are those in which the speaker's utterance sounds fine. Since the eavesdropper's assertion is also fine, their disagreement is "faultless."

A contextualist could hold that the speaker's "ought" claim isn't relative to a body of information that includes the eavesdropper's and so is warranted, but only on pain of losing a common subject matter and, hence, an explanation for our sense of disagreement. In short, the contextualist may capture either the faultlessness of their respective claims or their disagreement, but not both.

Here is MacFarlane's example of such a case. Suppose you are deciding whether you ought to bet on Blue Blazer or Exploder, two horses in an upcoming race. You know that, in the past, Blue Blazer has proven itself the faster horse. In light of this you conclude,

(BLAZER) I ought to bet on Blue Blazer.

Suppose, though, that, unbeknownst to you, I am eavesdropping on your conversation from behind a bush. Unlike you, I know that today Blue Blazer will be suffering from the effects of a drug. MacFarlane holds that here "it makes sense for me to think that you are wrong, and to say,"

(EXPLODER) "No, you ought to bet on Exploder." (MacFarlane 2014: 284–5)

MacFarlane suggests that here I am sensibly disagreeing with you, but that your utterance can't have its content determined relative to a body of information that includes mine. If it were, your assertion of BLAZER would have been unwarranted. But your assertion seems just fine. If instead we hold that your assertion of BLAZER isn't relative to a body that includes my information, then you and I aren't disagreeing. So, whether the contextualist holds that your assertion is or isn't relative to a body of information that includes mine, there will be some feature of eavesdropping cases she won't be able to explain.

MacFarlane's own explanation of such cases requires that both the speaker's and the assessor's utterances are true evaluated at their own contexts of assessment. Uttering BLAZER is warranted because BLAZER is true evaluated at your context of assessment, while it "makes sense for me" to utter EXPLODER because it is true evaluated at mine. Finally, his view explains how the two disagree by positing a semantically invariant proposition, that you ought to bet on Blue Blazer, which is affirmed by your assertion of BLAZ-ER and denied by my assertion of EXPLODER (pp. 285–6).11

What should the contextualist say here? Notice first that the case is quite sketchy. Some ways of filling it out can easily be explained by contextualism. Here's one such case: imagine as before, I am eavesdropping on you behind some bushes. Before you utter BLAZER, I hear you say,

(WIN) Let's see; Blue Blazer has always won in the past. So, Blue Blazer will win.

**(p. 100)** Here it's natural to hear BLAZER as expressing an objective "ought," that given the circumstances, you ought to bet on Blue Blazer.12 If that's so, and I know that you are mistaken about what the circumstances are, I'm in a position to deny the very proposition the contextualist holds you have expressed. So long as your belief about what the circumstances are is reasonable, what you say with BLAZER is warranted, what I've said with EXPLODER is warranted, and our assertions express disagreement with one another. The availability of this way of filling out MacFarlane's bare case means that one possible explanation for our judgment that BLAZER and EXPLODER are both warranted and that EXPLODER expresses disagreement with BLAZER is that we're responding to the availability of just such a way of filling out the case.

Given that this case leaves open an objective reading, we think this isn't the best example for pressing MacFarlane's case. A better example would be an eavesdropper scenario in which the deontic modal gets a forced, information-sensitive reading, such as Parfit's miners scenario or Jackson's drug case.13 Given space constraints, here we can only sketch what we take to be the strongest version of such a case for relativism, and a few contextualist strategies in response.

Notice first that MacFarlane's Blue Blazer scenario leaves it open whether the original speaker can hear EXPLODER. If we consider an information-sensitive, eavesdropper scenario in which the eavesdropper either communicates the information the original speaker failed to have at the time of her utterance or the latter has some other means of acquiring it before acting, then it is easy for a contextualist to suggest that the eavesdropper's information is included in the domain-determining body of the original speaker's utterance. In such a case, the eavesdropper's denial will be a denial of the very proposition that the original speaker expressed, and so they are disagreeing.14

The hardest case for the contextualist will be one in which the agent is unable to obtain the eavesdropper's information prior to the time of her action. Here it's important to distinguish two types of cases. One type of case would involve additional setup before the original utterance, of the kind provided by WIN in the above supplementation of MacFarlane's bare case. For example, we might imagine an original speaker, Patient, who is deliberating about whether to have an operation, explicitly reasoning in terms of expected outcomes, and surrounded by medical experts. Suppose, on the basis of information she found on a prima facie reliable source on the Internet, she announces to the experts, "I ought to have the operation." Imagine our eavesdropper is himself a medical expert who knows that Patient's information is misleading. In fact, the expected outcomes in Patient's case of having the operation are much bleaker than Patient believes. Here we clearly hear it as fine for the eavesdropper to say out of earshot, "That's false. Patient shouldn't have the operation." But from the setup of such a case, it's clear that Patient intends to be speaking to the question of what can be expected to have the **(p. 101)** best

medical outcome, having the operation or not, given the information of medical experts. The eavesdropper's information is expert information and so in the domain-determining body she plausibly intends. This can be so even if none of the experts in fact provide correction. So, the contextualist may plausibly hold that the eavesdropper is denying the very proposition that Patient expressed.

The second type of case is, like those found in much of the literature on information-sensitive deontic modals, a bare case in which we are given few clues about a speaker's intentions. In such cases, it can be unclear which proposition, from those compatible with the clues provided, is the one a speaker intended to express. There are a number of contextualist-friendly explanations that can in principle be given for these cases.15 In order to know whether these cases are at the end of the day more relativist- than contextualistfriendly, though, we would need to know much more than we currently do about patterns in speakers' reactions to them.

MacFarlane sees a second puzzle for flexible contextualist proposals.

[T]he contextualist could take the contextually relevant body of information to be the information the speaker now possesses plus any information she will acquire before having to act [ . . . ] Suppose that you are trying to decide whether to offer your advice or just let me waste my money on Blue Blazer. According to this account, my claim "I ought to bet on Blue Blazer" will be true if you don't offer your advice, and false if you do offer your advice. This is, to say the least, a bizarre prediction. (MacFarlane 2014: 285)

Here, MacFarlane is floating one clear option for a contextualist. Another option would be a more flexible proposal which would allow that some contexts select the information of the agent at the time of action; others, the best available to her by some designated time; and still others, the information she should have by some designated time. But MacFarlane could make a similar point about this revised proposal. Suppose the only way for an agent to acquire a potential advisor's information by the designated time is for Potential Advisor to give it to her. The question is: is it really so bizarre to allow that Potential Advisor has the ability to make what Agent says either true or false? Consider a case just like MacFarlane's Blue Blazer case, but one in which, instead of BLAZER, Agent says,

(BLAZER′) Given the information I'll have by the time I place my bet, I ought to bet on Blue Blazer.

Here, in this case very like MacFarlane's own, it is utterly unsurprising that Potential Advisor can make what Agent says true or false by choosing to share or withhold his information.

**(p. 102)** What about MacFarlane's positive case for the claim that his flexible relativism fits with speakers' reactions in the full range of cases? Consider first his discussion of an additional case.

Suppose that Fatma is investigating a murder case. She has gathered a considerable amount of evidence pointing to the butler [ . . . ] and the gardener [ . . . ] has a credible alibi. We, however, have some evidence that Fatma does not, and this evidence establishes conclusively that the gardener committed the murder and tried to frame the butler. Question: ought Fatma to believe that the gardener committed the murder? (MacFarlane 2014: 297)

Here he offers two answers. First, he says, "in normal contexts of deliberation and advice, the relevant information state will be the information possessed by the assessor" (p. 298). If the above is such a case, then we should conclude that Fatma ought to believe, against her evidence, that the gardener committed the murder. This seems counterintuitive; however, the flexibility of MacFarlane's relativism makes room for a second response. He also says that when an assessor's concern is whether an agent acted reasonably, the information relevant at her context of assessment "may shift to the agent's information. That is what happens when we say things like, 'Don't beat yourself up over it. You believed then just what you ought to have believed, even though it turned out to be false' " (p. 298).

MacFarlane's discussion here raises a question about a type of case he does not consider. As background, first consider an extension of another of his cases:

If you ought to administer the medicine and [ . . . ] you don't administer the medicine, because you have been told that it is poison and want to help the patient, then you have an excuse for not doing what you ought to have done. (p. 297)

Imagine that we know that the medicine is not poison and that it will cure the patient. But imagine also that we know that Agent has no way of learning this prior to the time at which she must administer the medicine for it to be effective. We've seen that MacFarlane's view predicts that in contexts in which we're wondering whether someone has acted reasonably, it can be fine to say to them something like, "Too bad you didn't know the medicine wasn't poison. But you did as you ought; you shouldn't have given Patient the medicine."

Imagine an elaboration of this case. Professor is lecturing a group of medical students about cases in which the patient presents symptoms just like Patient's and, indeed, is using Patient as her case study. Here, it seems fine for her to say about the doctor in that case,

(OUGHT) Doctor ought to have given Patient the medicine.

Imagine also that, a short time later that same day, Professor, who is on the hospital's review board, attends their meeting reviewing hospital procedures in cases like **(p. 103)** Doctor's. When Doctor's case comes up for discussion, it seems fine for Professor to say,

(OUGHT NOT) Doctor acted reasonably; she ought not have given Patient the medicine.

We can easily imagine here that Professor has not changed her mind. She still believes as she did when giving her lecture. Is Professor disagreeing with or contradicting herself here, on MacFarlane's view? Notice that the case would seem to have both of the hallmarks of so-called "faultless disagreement," the type of disagreement eavesdropper cases were crafted to illustrate and which was intended to motivate the transition from contextualism to relativism.16 First, faultlessness requires that each utterance conform to the "constitutive norms governing assertion," which are "keyed to accuracy relative to the asserter's [ . . . ] context of assessment" (p. 134). That condition is met here. OUGHT NOT is true, evaluated in a context of assessment in which it was uttered. In that context, the reasonability of Doctor's action was in question, making Doctor's information relevant. In contrast, in the classroom, the reasonability of Doctor's action is not in question, its advisability is. So, the context of assessment in which OUGHT is uttered is one in which Professor's information is relevant, making it true at that context. Second, OUGHT NOT and OUGHT meet the condition for disagreement, in MacFarlane's sense. In that sense, disagreement is preclusion of joint accuracy; both cannot be accurate at any single context of assessment. At a context that makes the assessor's information relevant, OUGHT is true, but OUGHT NOT is false, while at a context that makes the agent's information relevant, OUGHT is false and OUGHT NOT is true. Indeed, since MacFarlane is an invariantist about the propositions expressed by "A ought to φ" and "A ought not to φ," there will be no context of assessment at which OUGHT and OUGHT NOT, or any other pairs of sentences with these forms, will both be true. This means that, given his own account of faultless disagreement, he is committed to holding that this case and others like it are cases of intrapersonal "disagreement." But that doesn't seem like the right thing to say. A person who asserts both OUGHT and OUGHT NOT need feel no conflict at all. In contrast, a suitably flexible contextualist theory can easily explain this. Since the contents expressed by OUGHT and OUGHT NOT are perfectly consistent, there is no intrapersonal disagreement.

## **4.5 Schroeder's Ambiguity Theory**

A central claim of Kratzer-style contextualism is that "ought" always takes a proposition as one of its arguments, in addition to a modal base and a ranking. So in the sentence "It **(p. 104)** ought to be that it is raining," "ought" would take the proposition *it is raining* as an argument. The sentence "Mary ought to walk" would have a similar structure, with "ought" taking the proposition *Mary walks* as an argument.

But "Mary ought to walk" also suggests an alternative structure. Perhaps "ought" need not always take a proposition as an argument; perhaps it sometimes expresses a relation between an agent and an action. On this alternative view, the form of "Mary ought to walk" could be *ought(A, φ*), rather than *ought(p)*.

Mark Schroeder (2011) defends this alternative view.17 On his version of the view, there is a crucial deliberative sense of "ought" that relates an agent and an action. Schroeder grants that there are other senses of "ought" (epistemic and evaluative, for example) that do function as propositional operators. But "ought" has its deliberative sense if and only if it expresses a relation between an agent and an action. Thus on Schroeder's view, the sentence "Mary ought to walk" is ambiguous between an evaluative reading, which would have the form *ought (Mary walks)*, and a deliberative reading, which would have the form *ought (Mary, to walk)*. *eval delib*

We consider four of Schroeder's arguments for the claim that the deliberative "ought" expresses a relation between an agent and an action. As above, our focus is on whether these arguments pose challenges to Kratzer-style contextualism. We first explain Schroeder's distinction between the deliberative and evaluative senses of "ought."

Schroeder characterizes the evaluative sense of "ought" as the one that says, "roughly, that were things ideal, some proposition would be the case" (2011: 1). His motivating example involves Larry, a deserving man who has suffered numerous recent misfortunes. One might say "Larry ought to win the lottery" to express the idea that, ideally, Larry would come into some money to help him cope. This, however, is not meant as a deliberative claim about what Larry ought to do. It does not imply that Larry should act in such a way that he will win, or try to win, the lottery. For example, it does not imply that Larry should purchase lottery tickets.

Schroeder offers five "hallmarks" to characterize the deliberative sense of "ought," holding that each occurs in all and only those cases where "ought" has its deliberative sense (2011: 17). First, the deliberative sense "matters directly for advice." In offering advice, one may take into account the evaluative question of how things ideally ought to be, but this is distinct from what advice it is right to offer, as illustrated by the case of Larry. Second, the deliberative sense "is the right kind of thing to close deliberation." As Schroeder says, "knowing what one ought to do, in the deliberative sense, settles the question of what to do." Third, one is "accountable" for doing what one ought to do in the deliberative sense; that one does not do what one deliberatively ought to do is a "legitimate criticism." Fourth, it must be in one's "power to do" what one deliberatively ought to do. Fifth, the deliberative sense is "more closely connected" to the notion of **(p. 105)** obligation—though not perfectly so, since, for example, it may be that one deliberatively ought to do something, even though one is not obligated to do it (pp. 9–10). The details of these hallmarks are controversial, but we take them to draw a reasonably clear distinction between deliberative and evaluative "ought"s.

The first of Schroeder's arguments we consider is an argument against one version of the view that "ought" always expresses a propositional operator. This version of the view denies that distinct readings, senses, or flavors of "ought" are needed to explain the distinction between deliberative and evaluative "ought" statements. Instead, the very same reading, sense, or flavor of "ought" figures in all deliberative and evaluative "ought" statements. On this view, as long as we are within the deliberative/evaluative domain, "Mary ought to walk" is equivalent to "It ought to be that Mary walks."18

Schroeder objects to this view on the basis of the following example, due to Broome:

It is Father Murphy's job to baptize everyone in the parish who needs to be baptized, Colleen is in the parish and needs to be baptized, but it is in Colleen's interests to be baptized by the holiest priest she can find—who is Father O'Grady, not Father Murphy. (Schroeder 2011: 20)

The objection proceeds as follows. Both of the following claims seem plausible: (i) Father Murphy ought to baptize Colleen, and (ii) Colleen ought to see to it that she is not baptized by Father Murphy (but rather by Father O'Grady). Translating these into their supposed equivalents, we get: (i) It ought to be that Father Murphy baptizes Colleen, and (ii) It ought to be that Colleen sees to it that she is not baptized by Father Murphy. But now we are committed to saying that inconsistent things evaluatively ought to be the case. This, Schroeder says, is implausible: we should not expect there to be conflicts in the evaluative "ought."

A contextualist view, though, can avoid this consequence while maintaining that "ought" always expresses a propositional operator.19 The deliberative "ought" statement "Father Murphy ought to baptize Colleen" will have the structure *ought (Father Murphy baptizes Colleen)*, where the ranking *g* associated with *ought* ranks worlds on the basis of the deliberative appropriateness of Father Murphy's actions. This might amount to ranking worlds by the extent to which Father Murphy's actions are consistent with the proper exercise of his agency, or by how well Father Murphy complies with the reasons and obligations that apply to him. Similarly, the deliberative "ought" statement "Colleen ought to see to it that she is not baptized by Father Murphy" will involve a different value **(p. 106)** for the parameter *g*, one that ranks worlds on the basis of the appropriateness of *Colleen's* actions. Statements about what evaluatively ought to be the case will involve yet another value for the parameter *g*, one that ranks worlds by how well they approach some impartial ideal. By distinguishing the different rankings involved in different uses of "ought," a contextualist view can accept that agents may be deliberatively at odds with each other, while maintaining a single evaluative harmony. *f,g*

A second argument of Schroeder's picks up on the fact that views on which "ought" is a propositional operator will tend to validate Principles of Inheritance. In particular, Schroeder is concerned with a version of Inheritance according to which "if B is a necessary consequence of A, and it ought to be that A, then it ought to be that B," where the necessity invoked may be merely causal (2011: 20). He argues that the deliberative "ought" does not obey this kind of principle in cases where one foresees, but does not intend, a consequence of one's actions. Consider the case of Strategic Bomber, who can drop a bomb that would decimate an ammunition factory, although this would unavoidably also decimate a nearby elementary school. Suppose circumstances are such that Strategic Bomber ought, in the deliberative sense, to decimate the factory. Even so, Schroeder finds it implausible that Strategic Bomber ought, in the deliberative sense, to decimate the school.

One reason Schroeder offers appeals to the first hallmark of the deliberative "ought," which is that the deliberative "ought" "matters directly for advice" (p. 9). He says, since

"you should not *advise* Strategic Bomber to decimate the elementary school," it cannot be that Strategic Bomber deliberatively ought to decimate the elementary school (p. 21). It is true that one generally should not advise Strategic Bomber to decimate the school. But this may be merely because this advice would be misleading if an unforeseen opportunity to decimate the factory without decimating the school were to arise. If it is clear that this possibility is being put aside, the advice seems to be good:

Strategic Bomber: I am having doubts about my mission tomorrow. If I decimate the factory, I will thereby decimate the school. Ought I really decimate the school?

Advisor: Yes. Under these unusual circumstances, you ought to decimate the school.

Schroeder might object that the advice here cannot be deliberative, since Strategic Bomber "shouldn't reason toward an intention" to decimate the school in his deliberations (p. 21). While it is true that Strategic Bomber shouldn't reason toward this intention, that does not preclude the advice from being deliberative. One who accepts the advice appears to be committed to ruling out any course of action, of those actually available, that does not involve decimating the school. In this way, accepting the advice can settle the question of what to do.20 In any case, it is plausible that there is a general disconnect between deliberative "ought"s and what intentions one should reason toward. One ought, in the deliberative sense, not steal one's colleague's lunch, but most **(p. 107)** of us will comply with this without forming an intention to comply with it, and so plausibly we shouldn't bother reasoning toward such an intention.21

Schroeder's third argument makes a positive case for the claim that the deliberative "ought" has an argument-place for an agent. Schroeder argues that certain "ought" sentences cannot express deliberative readings at all, or can only do so for certain agents. If the evaluative and deliberative "ought"s were both propositional operators, with no argument-place for an agent, this would be puzzling. But if, unlike the evaluative "ought," the deliberative "ought" requires an argument-place for an agent, this pattern would be wellexplained. The "ought" sentences that cannot express deliberative readings, or that can only do so for certain agents, would be precisely those that do not make the relevant agent available to fill the argument-place required by the deliberative "ought."

Schroeder considers four types of "ought" sentences in support of this: (i) passive sentences, like "Lucy ought to be kissed by Bill," (ii) sentences with expletive (non-referring) subjects, like "It ought to be assumed that he is capable," (iii) sentences with idiomatic subjects, like "The cat ought to get his tongue," and (iv) sentences with non-agential subjects, like "The meeting ought to start at noon." All four types of sentences, Schroeder holds, can be understood evaluatively, as making claims about how things ideally would be. But types (ii)–(iv) cannot be read deliberatively. And if type (i) can be read deliberatively at all, it cannot be read as deliberative for the agent in the "by"-clause. These patterns would be well-explained if the deliberative reading, unlike the evaluative reading, has an argument-place for an agent.22

We do not share Schroeder's intuition that these types of sentences cannot carry deliberative readings.23 Consider passive sentences, as in (i). Suppose there are three children in a family: Lucy, Bill, and Mary. Lucy is the youngest, and each night, either Bill or Mary is obligated to kiss her goodnight. Bill and Mary are arguing about which one of them has this responsibility tonight. Finally, the two of them approach their father for an answer:

> **(i)** Mary: Which one of us ought to kiss Lucy? Father: Lucy ought to be kissed by Bill.

Father's answer is most naturally read as a deliberative use of "ought." It seems directly responsive to the deliberative question that Bill and Mary face. Schroeder might **(p. 108)** interpret Father's answer as an evaluative "ought," indirectly relevant to the deliberative question. But we do not hear Father as being committed to anything beyond the deliberative claim about who ought to kiss Lucy. For example, Father could consistently have answered, "In an ideal world, Mary would kiss Lucy, but as things are, Lucy ought to be kissed by Bill."

Other cases suggest deliberative readings are possible for sentence types (ii)–(iv):

**(ii)** Driving Instructor: If a car is moving erratically, it ought to be assumed that the driver is drunk.

**(iii)** New Hire: What should I say at the meeting?

**Mentor:** The cat ought to get your tongue.

**(iv)** Daughter: You may lie when it's in your interest to do so.

**Mother:** That's wrong! You ought not lie unless it's necessary for the good of all concerned.

**Grandmother:** Call me old-fashioned, but in my opinion, lies ought *never* be told.

The utterances of Instructor, Mentor, and Grandmother appear to have all the hallmarks of the deliberative "ought." They appear to matter directly to advice. If accepted, they appear to settle the question of what to do. They have some connection to obligation, and we would expect criticism for non-compliance. We may also imagine that the speakers are disposed to withdraw or qualify their "ought" claims if they ever come to think that compliance is impossible.

Sentence types that de-emphasize agents, as all of Schroeder's types tend to do, also tend not to receive deliberative readings. On a Kratzer-style contextualism, this would not be surprising, since emphasis on an agent can bring to salience a ranking of worlds in terms of how well that agent acts.24 But the main issue here turns on the *possibility* of the deliberative readings of sentence types (i)–(iv), that is, whether a competent speaker could hear such readings. If these readings are possible, as we believe they are, then these sentences do not support positing a distinctive argument structure for the deliberative "ought."

Schroeder offers a fourth argument, intended to show that the deliberative "ought" has an argument-place for an action, rather than for a proposition. This argument is directed, at least in the first instance, against views that already accept Schroeder's contention that the deliberative "ought" has an argument-place for an agent.25

The Basic Problem with the propositional view is that it is too powerful [ . . . ] if OUGHT is just a relation that you can stand in to some proposition—for example, **(p. 109)** the proposition that you exercise daily—then it is a relation of which it makes sense to ask whether you stand in it to arbitrary other propositions—for example, to the proposition that *I* exercise daily. But I don't think that it makes sense to ask whether you stand in the OUGHT relation to the proposition that I exercise daily. (Schroeder 2011: 24)

Insofar as Kratzer-style contextualism holds that the deliberative "ought" is a propositional operator, it may appear to be susceptible to a version of this objection. But we believe it is not. Schroeder emphasizes that there is little sense to be made of sentences like "You ought that I exercise daily" (p. 33). But similar sentences with other propositional operators are also anomalous. For example, "seems" is typically taken to be a propositional operator, and "You seem that I exercise daily" is anomalous. A view on which "ought" is a propositional operator is not committed to making any more sense of "You ought that I exercise daily" than "You seem that I exercise daily."

But there is another way in which Schroeder's objection could apply. We suggested above that Kratzer-style contextualism could account for the deliberative "ought" by tying the ranking *g* to a salient agent. Such a view would be expected to allow this deliberative "ought" to take propositions *not* involving the salient agent. Thus if *f′* and *g′* are the relevant parameter values for a given deliberative use of "ought," with Mary as the salient agent, the proposition *ought (Bill exercises daily)* would be predicted to make sense. This proposition, though, simply says that in all the worlds in the modal background given by *f′* that rank highest according to, say, how well Mary fulfills her responsibilities as an agent, Bill exercises daily. This proposition does make sense. What would be implausible would be to go on to claim that this proposition is expressed by "Mary ought that Bill exercise daily." *f′*,*g′*

## **4.6 Normative Reasons**

We have focused thus far on determining the proper semantics for deontic modal expressions. We have argued that Kratzer-style contextualism can meet the various challenges that have been raised against it, and that rival views face challenges of their own. We now turn to the implications of Kratzer-style contextualism for the relationship between true deontic "ought" statements and normative reasons. It turns out that this approach imposes no general relationship between them. Instead, particular true deontic "ought" statements may relate, and fail to relate, in various ways to normative reasons. We give four possibilities below.

First, a true deontic "ought" statement may issue a recommendation that an agent has no normative reason to comply with. Consider Foot's (1972) example of the club secretary who informs a member of the club rules by instructing him: "You ought not bring ladies into the smoking room" (p. 308). With the right choices for *f* and *g*, this sentence comes out true. It may be that (i) the modal background given by *f* consists of worlds **(p. 110)** available to the agent through his actions, including some in which he complies with the club rules and some in which he does not, and (ii) the ranking given by *g* ranks worlds by whether the agent complies with the club rules, with all those where he complies being tied for best, and all those where he does not comply being tied for worst. These choices make the sentence true, since it is true that in all the *g*-best worlds available from *f*, the agent does not bring ladies into the smoking room. Even so, nothing about the situation requires that the agent have any normative reason not to bring ladies into the smoking room. The "ought" statement ranks worlds on the basis of club rules that need not have any normative force.

Second, true deontic "ought" statements may systematically, but contingently, line up with the agent's reasons. Suppose now that the club follows legitimate procedures that *do* give the agent some reason to comply with its rules: the fact that an action complies with the club rules counts, to some extent, in favor of it. Using the above choices for *f* and *g*, if one *ought* to φ, then φ-ing complies with the club rules, and so the agent has some reason to φ. Thus there is a systematic connection between these "ought" statements and the agent's reasons. The connection, however, is contingent. In a circumstance where the club's procedures were not legitimate, these "ought" statements, with the very same values of *f* and *g*, could be true without the agent having any reason to comply. *f,g*

Third, there may be a necessary connection between the truth of a particular deontic "ought" statement and a claim about reasons. Suppose it is a necessary truth that agents never have sufficient reason to contravene the requirements of morality. Consider an "ought" statement with *f* and *g* chosen so that (i) the modal background given by *f* consists of worlds available to the agent through his actions, including some in which he complies with morality and some in which he does not, and (ii) the ranking given by *g* ranks worlds by whether the agent complies with morality, with all those where he complies being tied for best, and all those where he does not comply being tied for worst. With these choices for *f* and *g*, a statement "S ought not to φ" is true only if S would contravene morality in φ-ing. If the above supposition is correct, then necessarily, if the statement is true, the agent does not have sufficient reason to φ.

Fourth, a particular deontic "ought" statement may, in virtue of meaning alone, entail a claim about reasons. Suppose that it is not only necessarily true, but also true in virtue of meaning alone, that agents never have sufficient reason to contravene the requirements of morality. This could be so if the correct conceptual analysis of moral requirements identifies them as a type of requirement that one never has sufficient reason to contravene. Then "ought" statements with the above choices for *f* and *g* would not only necessitate but also analytically entail claims about reasons. The same would hold for "ought"

statements that take a value for *g* that simply ranks worlds on the basis of whether an agent's action is something that she has sufficient reason to do.

Given the scope of this volume, it is worth considering how true *epistemic* "ought" statements might relate to normative reasons. Once again, Kratzer-style contextualism allows many possibilities. Paralleling our discussion above, we consider four.

First, a true epistemic "ought" statement may issue a recommendation that an agent has no normative reason to comply with. For example, associations can have the **(p. 111)** equivalent of "club rules" for belief. Along with requirements to attend meetings, the secretary of the Astrology Club might instruct a member: "You ought to believe that alignment of the planets indicates good fortune." If this is merely informative as to what the epistemic rules or norms of the Astrology Club are, then it takes parameter values that rank worlds on the basis of whether the agent complies with such rules, and so it can come out true. Nevertheless, the agent may have no normative reason to comply with those rules.

Second, true epistemic "ought" statements may systematically, but contingently, line up with an agent's reasons. Suppose it turns out that members of the Astrology Club do have reason to comply with the epistemic norms of astrology, perhaps because they do happen to have strong evidence that these norms are truth conducive. Then there is a systematic connection between the club's "ought" statements and the members' reasons. Nevertheless, this connection is contingent, since it is not necessary that members have the evidence they do.

Third, there may be a necessary connection between the truth of a particular epistemic "ought" statement and a claim about reasons. For example, certain norms of responding to evidence may be necessarily backed by reasons. Suppose an "ought" statement of the form "S ought to believe p" invokes parameter values that rank worlds on the basis of whether S's beliefs comply with these norms. Then, necessarily, if the statement is true, S has reason to believe p.

Fourth, a particular epistemic "ought" statement may, in virtue of meaning alone, entail a claim about reasons. This would be so for an "ought" statement "S ought to believe p" that invokes parameter values that rank worlds simply on the basis of whether S's beliefs are ones she has sufficient reason to have.

A final observation: as noted in section 4.2, Kratzer-style contextualism allows for the truth of both subjective "ought" statements, which depend on an agent's information state, and objective "ought" statements, which depend on the actual facts. Endorsing the truth of certain "ought" statements of both these types, however, does not carry a commitment to endorsing the existence of multiple types of normative reasons. Given the ways just outlined in which the truth of an "ought" statement can come apart from the existence of normative reasons to comply with it, the view is compatible with positions on which (i) both subjective and objective normative reasons exist, (ii) only one type exists,

or (iii) neither does. It is also compatible with positions on which both types exist, but one type pertains to actions and the other to beliefs.

## **References**

Broome, J. (1999). "Normative Requirements." *Ratio* 12(4): 398–419.

Broome, J. (2006). "Reasoning with Preferences." In S. Olsaretti (ed.), *Preferences and Well-Being*, 183–208. Cambridge: Cambridge University Press.

Cariani, F. (2013). " 'Ought' and Resolution Semantics." *Noûs* 47(3): 534–58.

Chisholm, R. (1964). "The Ethics of Requirement." *American Philosophical Quarterly* 1(2): 147–53.

Chrisman, M. (2012). " 'Ought' and Control." *Australasian Journal of Philosophy* 90(3): 433–51.

**(p. 112)** Dowell, J. L. (2011). "A Flexible Contextualist Account of Epistemic Modals." *Philosophers' Imprint* 11(14): 1–25.

Dowell, J. L. (2013). "Flexible Contextualism about Deontic Modals." *Inquiry* 56(2–3): 149– 78.

Dowell, J. L. (2017). "Truth-assessment Methodology and the Case Against the Relativist Case Against Contextualism." *Res Philosophica* 94(3): 325–57.

Finlay, S., and J. Snedegar (2014). "One Ought Too Many." *Philosophy and Phenomenological Research* 89(1): 102–24.

von Fintel, K. (MS). "The Best We Can (Expect to) Get?" <**http://web.mit.edu/fintel/fintel-2012-apa-ought.pdf**>.

von Fintel, K., and Iatridou, S. (MS). "What to Do If You Want to Go to Harlem." <**http:// web.mit.edu/fintel/fintel-iatridou-2005-harlem.pdf**>.

Foot, P. (1972). "Morality as a System of Hypothetical Imperatives." *Philosophical Review* 81(3): 305–16.

Geach, P. (1982). "Whatever Happened to Deontic Logic?" *Philosophia* 11(1–2): 1–12.

Grice, P. (1989). "Logic and Conversation." In *Studies in the Way of Words*, 22–40. Cambridge, Mass.: Harvard University Press.

Harman, G. (1973). "Review of Roger Wertheimer, *The Significance of Sense*." *Philosophical Review* 82(2): 235–9.

Jackson, F. (1985). "On the Semantics and Logic of Obligation." *Mind* 94(374): 177–95.

Jackson, F. (1991). "Decision-Theoretic Consequentialism and the Nearest and Dearest Objection." *Ethics* 101(3): 461–82.

Jackson, F., and R. Pargetter (1986). "Oughts, Options, and Actualism." *Philosophical Review* 95(2): 233–55.

Kolodny, N., and J. MacFarlane (2010). "Ifs and Oughts." *Journal of Philosophy* 107(3): 115–43.

Kolodny, N., and J. MacFarlane (MS). "Ought: Between Objective and Subjective."

Kratzer, A. (1977). "What 'Must' and 'Can' Must and Can Mean." *Linguistics and Philosophy* 1(3): 337–55.

Kratzer, A. (1981). "The Notional Category of Modality." In H. Eikmeyer and H. Rieser (eds), *Words, Worlds, and Contexts*, 38–74. Berlin: de Gruyter.

Kratzer, A. (1991a). "Modality." In A. von Stechow and D. Wunderlich (eds), *Semantics: An International Handbook of Contemporary Research*, 639–50. Berlin: de Gruyter.

Kratzer, A. (1991b). "Conditionals." In A. von Stechow and D. Wunderlich (eds), *Semantics: An International Handbook of Contemporary Research*, 651–6. Berlin: de Gruyter.

Kratzer, A. (2012). *Modals and Conditionals*. Oxford: Oxford University Press.

MacFarlane, J. (2014). *Assessment Sensitivity*. Oxford: Oxford University Press.

Radford, A. (2009). *Analysing English Sentences*. Cambridge: Cambridge University Press.

Schroeder, M. (2011). "*Ought*, Agents, and Actions." *Philosophical Review* 120(1): 1–41.

Sloman, A. (1970). " 'Ought' and 'Better.' " *Mind* 79(315): 385–94.

Wedgwood, R. (2006). "The Meaning of 'Ought.' " *Oxford Studies in Metaethics* 1: 127–60.

Wedgwood, R. (2007). *The Nature of Normativity*. Oxford: Oxford University Press.

von Wright, G. H. (1951). "Deontic Logic." *Mind* 60(237): 1–15.

## **Notes:**

[^1]: For the canonical statement of such views, see Kratzer (1977, 1981, 1991a, 2012).

[^2]: Kratzer (1991a).

[^3]: Kratzer (1991b).

[^4]: This assumption is controversial. For reasons to think that the covert modal remains and takes scope over the overt one, see von Fintel and Iatridou (MS). Of course, if von

Fintel and Iatridou are right, it is much less clear that Kratzer's semantics for modals and indicative conditionals validates "if p, ought p."

[^5]: Finlay and Snedegar (2014) provide an example of a contrastivist view fully representable in a Kratzer-style framework. For an example of a contrastivist view not representable in such a framework, see Jackson (1985) and Jackson and Pargetter (1986).

[^6]: For example, in the case of Professor Procrastinate, he allows that the ranking of the options is "accept and write > do not accept > benchmark > accept without writing" (Cariani 2013: 541). Here "do not accept" is a suboptimal option above the benchmark. (In his footnote 23, however, he discusses a variant of his view that does not have this feature. We discuss that variant below.)

[^7]: Although Cariani himself does not offer an independent motivation for a diversity condition, one motivation might be, following Sloman (1970), the idea that "ought"s are comparative and so require at least two different actions or states of affairs to be compared.

[^8]: For some reasons to doubt the force of Cariani's arguments against a pragmatic strategy, see von Fintel (MS).

[^9]: See MacFarlane (2014: ch. 11) and Kolodny and MacFarlane (2010, MS).

[^10]: This characterization of MacFarlane's view is rough. For expository purposes, we overlook aspects of his more complex view not at issue in the discussion here.

[^11]: Dowell (2017: 342–50) argues that empirical data undermine MacFarlane's eavesdropping argument against contextualism.

[^12]: As mentioned in section 4.2, we treat objective "ought"s in the Kratzerian framework as those which have information-insensitive ordering sources.

[^13]: Jackson (1991).

[^14]: For details on one way to make that case, see Dowell (2013).

[^15]: For a few such strategies applied to parallel cases involving epistemic modals, see Dowell (2011).

[^16]: MacFarlane (2014: ch. 6).

[^17]: Earlier defenders include von Wright (1951), Harman (1973), and Geach (1982).

[^18]: See Chisholm (1964) for this view. Chisholm would deal with the case of Larry by distinguishing between "Larry ought to win the lottery," which would be true, and "Larry ought to bring it about that Larry wins the lottery," which would be false.

[^19]: Schroeder holds that the "most straightforward" reading of Kratzer (1977) and (1981) rules this out, by limiting us to a single parameter value for *g* to account for all deliberative and evaluative "ought" sentences (Schroeder 2011: 2). Those articles do not specifically address the question, but given that they emphasize the wide variation in parameter values, we find this reading unmotivated.

[^20]: The advice most directly settles the question of whether to decimate the school. Given the context, it also settles the question of whether to decimate the factory.

[^21]: A more precise view of the rational link between deliberative "ought"s and intentions is given by the requirement of *Krasia* in Broome (2006), which holds, "Rationality requires of *N* that, if *N* believes she ought to *F*, and if *N* believes she will *F* only if she intends to *F*, then *N* intends to *F*" (p. 183). See also Heuer, Ch. 37 this volume.

[^22]: See Radford (2009) for more on these syntactic patterns and what they would show about the argument structure of a verb.

[^23]: Chrisman (2012) and Finlay and Snedegar (2014) also do not share Schroeder's intuition on this point.

[^24]: Finlay and Snedegar (2014) offer a more detailed pragmatic explanation of why certain sentence types tend to receive evaluative readings. Their explanation proceeds in a contrastivist framework, but parallel strategies are available to other contextualist views.

[^25]: Schroeder cites Broome (1999) and Wedgwood (2006, 2007).

---

# 5. Reflections on the Ideology of Reasons 

*John Hawthorne and Ofra Magidor*

### **Abstract and Keywords**

In this chapter we offer a series of reflections on the ideology of reasons. Among the normative reasons for an agent X to phi, it is common to distinguish between those reasons that the agent possesses and those which she does not. After some background (5.1), we argue (5.2) that possession of a reason requires knowledge. In 5.3, we argue, first, that the normative reason construction is factive, and second, that possession ascriptions can be factored into a normative reason construction and a possession claim. In 5.4, we compare two prominent views concerning the nature of normative reasons: those of Kearns and Star and of John Broome. While both views have significant merit, we argue that they also face some non-trivial challenges, and discuss a range of considerations that can help to adjudicate between these two conceptions.

Keywords: reason, normative reason, possessed reasons, reasons as evidence, reasons as explanations

## **5.1 Setup**

*In this chapter we offer a series of reflections on the rather complex ideology of reasons. We will start in this section by spelling out some background assumptions we make. As we shall see, among the normative reasons for an agent X to phi, it is common to distinguish between those reasons that the agent possesses and those which she does not. In section 5.2, we argue that possession requires knowledge (if p is a reason for X to phi then X possesses p as a reason only if X knows that p). In 5.3, we argue, first, that the normative reason construction is factive (if the proposition that p is a reason for X to phi, then it is true that p), and second that possession ascriptions can be factored into a normative reason construction and a possession claim (the fact that p is a reason which X possesses to phi iff the fact that p is a reason for X to phi and X possesses this fact as a reason).

One important theme that runs through both sections is the following: there is a typical range of cases where, since an agent does not know a pertinent worldly fact that might otherwise serve as a motivating reason, one might be tempted to fall back on describing

the agent's reasons using a psychological ascription (e.g. in the case where an agent is hallucinating a tiger and runs, we might revert to "His reason for running was that he thought there was a tiger in the room"). We maintain that in many such cases the psychological fact cited is not after all a motivating reason (though the ascription sentence might still have a true reading and the psychological fact might still count as a possessed normative reason). Indeed, we argue that in cases of this sort the agent often acts for *no* motivating reason.

**(p. 114)** In 5.4, we turn to compare two prominent views concerning the nature of normative reasons: Kearns and Star's view of reasons as evidence that one ought to phi, and John Broome's view of reasons as explanations for why one ought to phi. While both views have significant merit, we argue that they also face some non-trivial challenges, and discuss a range of considerations that can help to adjudicate between these two conceptions of reasons.

Let us begin, however, by noting some things we shall be taking for granted in the discussion that follows. First, we take it that according to the primary use of "reason," reasons are propositions. This is not to deny that there are uses of "reason" which cite things other than propositions as reasons (e.g. "That idiot was the reason for my leaving the party" or "The stock crash was the reason for his getting depressed"). But it is overwhelmingly plausible that such constructions are derivative (from truths like "The fact that that idiot was there was the reason for my leaving the party" and "That the stock crash occurred was the reason for his getting depressed").1

Second, we assume that the normative construction "reason to phi" is context-sensitive across various parameters. (Note that it is unsurprising that this infinitival construction is normative: infinitivals are often normative. Consider, for example, "The thing to do is phi.") Such constructions can encode either an "ought" or a "may" modality. And just as "ought"/"may" can take on a variety of meanings, so can the associated infinitival "reason to phi" construction.2 There are a variety of candidate meanings for "ought" and "may," some more subjective than others. We will work for the most part with the (radically oversimplified) picture according to which there are two "oughts": a subjective and an objective one. We hope the oversimplification won't matter much for what we have to say. Roughly, our envisaged objective "ought" ranks actions according to the best outcome, while the subjective "ought" ranks according to the best expected outcome by the lights of the agent's evidence.3 (We think of evidence as what the subject knows, though much of what we say could be adapted to other frameworks for thinking about evidence.) This basic structure covers both reasons to act and reasons to believe.4

Third, we assume the following taxonomy for classifying the various uses of the ideology of reasons. (While there is nothing like a universally accepted taxonomy in this area, **(p. 115)** what follows is not particularly idiosyncratic.) Quite apart from (i) normative reasons just discussed (i.e. reasons there are for an agent to act, believe, or feel a certain way) there are also (ii) explanatory reasons—reasons why the agent acted, believed, or felt a certain way, and (iii) motivating reasons, the reasons for which the agent acted on a

particular occasion. (Motivating reasons are called "personal reasons" by Grice because we standardly describe them using possessive constructions of the form "X's reason(s) for phi-ing was (were) that …"). Within the category of normative reasons, there is a special subcategory of possessed normative reasons—reasons to act that the agent possesses. The contrast between possessed and unpossessed reasons we have in mind is fairly intuitive. When a glass contains poison but an agent is unaware of this, there is a reason for the agent to avoid drinking from the glass, but that reason for avoidance is something that the agent is not in a position to use as a consideration when acting.

The literature sometimes seems to suggest that we can distinguish whether possessed normative reasons are in play using superficial linguistic tests. We should be cautious here. First, possessive constructions are notoriously context-sensitive. We think that they don't always indicate possessed normative reasons in the intended sense of "possessed." For example, there is a natural use of the possessive which allows us to say, "The agent has a reason to leave the building" when there is a bomb in the building, but the agent is completely unaware of this fact. But this use of "has a reason" doesn't mark the kind of possession that theorists in the area are typically interested in.5 With Mark Schroeder, we agree that a good indicator of whether a normative reason is possessed (in the relevant sense) is whether that reason is available as a motivating reason. Thus, even when our central concern in this chapter is with possessed and unpossessed normative reasons, we will often consider whether a certain proposition can function as a motivating reason, since this is a good heuristic for testing the kind of possession of interest.6

Finally, we should note that as we are thinking about it, one needs to keep apart several distinctions that are often conflated in the literature. First, a particular normative reason might be possessed or unpossessed whether or not it is reported as being possessed. Thus, suppose for example that the following report is true: "There is a reason for X to flee the building, namely that the building is burning." The report in itself does not commit us to the claim that the reason is possessed (X might be completely unaware that the building is burning), but neither does it rule out the possibility that this is a possessed reason (the report can be true even if X is fully aware that the building is burning). Second, the question whether the normative force of the infinitival construction is **(p. 116)** objective or subjective is orthogonal to the question of whether the reason in question is reported as being possessed. Thus, for example, "There is a reason for X to phi, namely that p," which does not report possession, can be read as utilizing either a subjective or objective normative ordering source (and the same is true of ascriptions which do report possession).

## **5.2 Possession Requires Knowledge**

### **5.2.1 The Initial Case in Favor of Possession Requires Knowledge**

What does it take for an agent to possess a reason? We claim that if the proposition that p is a reason for S to phi, then S possesses it as a reason to phi only if S knows that p. 7

Given that in order for the proposition that p to be a reason, it must be true that p (see 5.3), it is clear that there will be no cases where p is a reason for you to phi but where you falsely believe that p. But why not think that possession of a reason merely requires truly believing it?

Suppose there is a dog in the room, which is standing behind a dog-shaped stone. Looking at the stone, a person X, who is afraid of dogs and mistakenly believes that the stone is a dog, runs out of the room. Upon which he claims: "My reason for leaving the room was that there was a dog there." To our ears, it is clear that X's statement cannot be true. But if true belief was sufficient for possession, then (since X does have true belief in this case), it is unclear why this proposition isn't available as X's motivating reason. On the other hand, if possession requires knowledge, then X does not possess the fact that there is a dog in the room as a reason, and hence this fact is not available as a motivating reason for X. Since availability as motivating reason is our key diagnostic for possession, we conclude that true belief is insufficient for possession. Exactly the same case shows that even justified true belief is not sufficient for possession (after all, if the stone is a convincing facsimile, the belief that there is a dog in the room will be justified as well as being true). 8

As a way of blocking the dog-shaped stone argument, someone might appeal to the idea that a necessary condition on P's being X's reason for phi-ing is that p be one of the reasons *why* X phi-ed (i.e. motivating reasons have to be explanatory reasons).9 In the case described, it is false that one of the reasons why the subject runs is that there **(p. 117)** is a dog in the room. It may be urged that it is this fact and not the absence of knowledge that makes for the falsity of the motivating reason ascription. But it is easy to describe somewhat similar cases where the purported motivating reason is an explanatory reason but where, owing to the lack of knowledge, it is odd to describe it as a motivating reason. Suppose, for example, that the dog had dragged the dog-shaped stone into the room, or that one suffers from a rare neurological condition which induces one to hallucinate dogs in the presence of dog pheromones.

This concludes the initial case in favor of the claim that possession requires knowledge. In 5.2.2 and 5.2.3 we address two objections to this claim.10

### **5.2.2 Motivating Reasons in "Fake-Barn" Cases**

The first objection we anticipate rests on the claim that the knowledge requirement is too demanding for a range of fake-barn-style cases. Suppose you are looking at a tiger in fake-tiger country. You are, understandably enough, afraid of tigers, and run. The report "My reason for running was that there was a tiger in front me" sounds acceptable enough. But the majority of philosophers will judge that in such a case one does not know that there is a tiger there (since this is a situation where there are numerous fake tigers in the vicinity).

This style of argument can be generalized to counterclaims of knowledge entailment for a large range of verbs. For even in such a "fake-tiger country" setting, "I saw that there was a tiger there," "I realized that there was a tiger there," "I discovered that there was tiger there," "I was dismayed that there was a tiger there" all sound reasonably acceptable.

**(p. 118)** There are three reactions one might have to such cases. First one might think that, after all, one does know that there is a tiger in such a scenario (despite the faketigers in the vicinity). Second, one might think that the initial judgment of acceptability of the reason (seeing, discovering, etc.) ascriptions is, while prima facie attractive, nevertheless incorrect. Third, one might think that these kinds of cases show that "realize that," "discover that," "see that," and "dismayed that" all fail to entail knowledge. We have some sympathy for the first option, though we shall not press that view here. But at any rate it seems that the third reaction is the least plausible. It is very hard to accept that statements such as the following can be true: "John discovered that there was a tiger there but never knew that there was a tiger there" or "John realized that there was a tiger there but never knew that there was a tiger there." It seems much more likely that the passability of "I discovered that there was a tiger there" is traceable to the fact that the verb "discover" draws attention to novelty and does not focus on the knowledge question. (Notice that "I knew that the tiger wasn't going to poison me" sounds much more passable than "I knew that it was a tiger." This is again because of facts concerning the focus of the statement.) The second response thus seems like a much more plausible way of explaining such judgments, and the objection fails to draw a wedge between possession and knowledge.

### **5.2.3 Reasons Ascriptions in Cases of False Belief and Second-Order Attitudes**

Let us turn to a second objection to the thesis that possession requires knowledge. In cases where someone falsely believes that p and where this belief is causally relevant to some further action, belief, or emotion, we tend to fall back on reason constructions involving psychological ascriptions as the complement of "his/her reason that." For example, if Jane falsely believes that there is a tiger in front of her and runs away, we will naturally resort to such explanations as "Her reason for running away was that it looked as if there was a tiger in front of her" or "Her reason for running away was that she thought that there was a tiger in front of her."11 (Such explanations satisfy the factivity demand of the "reason that" construction since the psychological claims following "reason that" are true.) The worry is that the truth of such ascriptions does not seem to depend in any way on whether the agent has a second-order attitude to the relevant psychological states, and in particular does not depend on whether the agent knows how things look or what she believes. The objection thus consists of two claims: first, that in such cases the agent's motivating reason is a psychological fact (Jane's reason was that **(p. 119)** she believed there was a tiger there), and second, that one can have such psychological motivating reasons without knowing that one is in the relevant psychological state.

Our main response to this objection consists of rejecting the first claim. We maintain that for a wide range of cases where we are tempted to use ascriptions of the form, "Her reason for phi-ing is that p" with true psychological complements, the "that"-clause does not ultimately succeed in picking out a motivating reason (and thus need not pick a possessed reason either). This means that even if such psychological facts are not known, this would not threaten the thesis that possession requires knowledge.

To begin, notice that when constructions of the form "Her reason for believing P was that Q" pick out motivating reasons, they typically cite a proposition that is treated as evidence by the agent. But it doesn't seem (except in special cases) that the proposition that the agent believes that there is a tiger is treated as evidence by the agent.12 This again suggests that such reasons ascriptions do not after all correctly ascribe motivating reasons.

One might think that "It looked as if P" or "It appears that P" are more promising psychological fallbacks in these cases, since they at least are better suited for an evidential role. Now certainly there are some cases where "It looks as if P" is unproblematic as a motivating reason description. Suppose someone is unsure whether they are undergoing veridical perception of a tiger, and thinking to herself, "Well, at any rate, it looks as if there is a tiger there. So I'd better run just to be on the safe side." Here we can all agree that it is correct to cite the proposition that it looks as if there is a tiger there as a motivating reason. But things are far less clear in a case where the person takes the appearances at face value. To get a rough idea of how one might be skeptical here, consider an admittedly crude model of motivating reasons: people have an Aristotelian syllogism box in which various propositions appear as premises, instantiating practical syllogisms that yield action. A necessary condition for a proposition's being a motivating reason is that it figures as premise of practical reasoning in this way. In a case where the person takes the appearances at face value, the proposition that there is a tiger plausibly figures as a premise, but cannot express a reason because there is no tiger (at best that proposition is treated as if it were a reason). On the other hand, on this model, the proposition that it looks as if there is a tiger cannot figure as a motivating reason if it doesn't figure as a premise of syllogistic reasoning. And arguably, when appearances are taken at face value, the "looks" proposition does not so figure in the agent's reasoning.

It is important to recognize, though, that even in those cases where such psychological facts do not constitute true motivating reasons, the ascription sentences (e.g. "X's reason for running was that it looked as if P") might well have a true reading—it's just that on the true reading, the claim will not express a motivating reason ascription. Note that we routinely say such things as "His reason for moving toward the fire was that he wanted to be warm" or "Her reason for leaving was that she was bored" even **(p. 120)** in a case where the fact that the agent wanted to get warm/was bored did not figure as a premise in any kind of reasoning. Very roughly, the point of the possessive is to mark a psychological fact pertaining to the individual that is explanatory (i.e. a psychological reason why).13 If there is indeed a mundane psychological-explanatory use of the possessive, then there will be two very different jobs that might be performed by a claim like "Her reason for

phi-ing was that it looked as if P," one being to mark a motivating reason (which requires that the "looks"-fact is used as a premise in the agent's reasoning), another being merely to mark a psychological-explanatory fact (and hence where there is no requirement that the fact be known). To get a sense that such reasons-ascriptions indeed have two readings, contrast the following two cases in which Jill witnesses a convincing hologram of a tiger in the room. In the first case, she reasons to herself by saying: "There is a tiger in the room, so I should run." In the second case, she reasons to herself by saying: "I'm not entirely sure if there is or isn't a tiger in the room. But it looks like there is a tiger in the room, so I should run." There is one reading of "Jill's reason for running was that it looked as if there was a tiger there" on which the ascription is true of both cases (this is the psychological explanation-why reading), but there is also another reading of the sentence on which it would only be true in the second case (this is the motivating reasons reading).14

The upshot is that in a wide range of cases, even when we are tempted to use "thinks that" and "looks as if" as fallbacks for motivating reason constructions (and even if these constructions have *some* true reading), it may not be correct to think that the complements of the "that"-clause are motivating reasons: where such psychological facts do not in fact figure in the agent's practical reasoning process, they cannot be motivating reasons.

Suppose we are in one of those cases where it is wrong to think that the proposition that it looked as if there was a tiger was a motivating reason in some hallucination case. What about a possessed normative reason? It does not follow that the looks proposition was not a possessed normative reason to run. For suppose that the proposition was known but not in fact motivating. Still, the agent *could* have used it as a motivating reason—for example in a situation where they were being cautious about whether there **(p. 121)** was in fact a tiger. In short, in a situation where a tiger is hallucinated (and the agent knows the "looks" fact), we have little doubt that the agent possesses a reason to run. Nevertheless, since in typical cases the "looks" fact is not a motivating reason for the agent's action, there is little pressure to count this fact as a possessed reason when the agent does not know this fact. This kind of case thus poses no threat to the claim that possession requires knowledge.

The objector might try to press the point, and maintain that even in those cases where such psychological reasons ascriptions do legitimately report motivating reasons, they do not require the agent to know the psychological complement. Thus, for example, the objector might insist that even in cases where Jill's reasoning does involve premises such as "It looks as if there is a tiger there" or "I believe there is a tiger there," we need not require that Jill *knows* that these psychological premises hold in order for these claims to count as Jill's motivating reasons.

Put this way, the objector's worry seems far less compelling. Indeed, the same considerations that justified the claim that possession requires knowledge in the case of worldly facts generalizes to the case where the purported reasons are psychological facts. Con

sider for example the following case: Jill is an art dealer who is interested in buying work containing patches which look to be a particular fine-grained shade of red—red (she has read of recent research showing that buyers are more likely to buy artwork that looks to have that particular shade, perhaps because they are causally sensitive in a certain way to its appearance). She comes across an artwork that in fact has a patch which looks the relevant shade, but despite seeing the patch, she does not know that it looks red (suppose she cannot discriminate between cases where things look to be red and cases where they look to be of a very similar shade such as red or red ). Still, Jill might form a true belief—if you want, a justified true belief—that the artwork contains a patch that looks red (suppose that under the picture is a label claiming the patch on the left looks red , but unbeknownst to Jill this label was accidently left by the curator from a previous exhibition). Jill might use her belief that the patch looks red in her practical reasoning, and end up buying the picture. But still it would be false in this case to say that her reason for buying the picture was that the patch looked red . 15 Finally, note that the objector's line here (which maintains that it is only when psychological facts are ascribed as reasons that knowledge is not required for possession) risks making the possession relation highly disjunctive. After all, as we have argued, in order for an external fact (or even an internal physiological fact) to count as a possessed reason, one has to stand in the knowing relation to it (cf. the dog-shaped stone case above). Yet the objector's position seems to be that for a belief-fact or "looks"-fact one needn't stand in the knowledge relation to that fact in order for the fact to count as a **(p. 122)** possessed reason. But this would seem to require that possession is a gerrymandered relation, which would certainly be a cost of that view.16 27 27 27 28 26 27 27 27 27

We have argued that in typical cases where an agent hallucinates a tiger, reasons "There is a tiger there so I had better run," and then runs away, the agent did not have the "looks as if" or "believes that" as motivating reasons. Moreover, given our commitment to the factivity of reasons (see 5.3), it does not seem that in such cases there are any *other* suitable candidates for being the agent's motivating reasons. Thus one upshot of our argument is that typically, in such cases the agent acts for *no motivating reasons*. An obvious worry about this proposal is that in many such cases we might be tempted to say that the agent is acting rationally, and we might worry that one cannot act rationally if one acts for no reason. We will return to this objection at the end of 5.3, so will not discuss it any further here.17

In summary, we maintain that reasons ascriptions with psychological complements such as "His reason for running was that he believed/it looked like there was a tiger there" pose no threat to the thesis that possession requires knowledge: either (as is the more typical case) they do not pick out a motivating reason of the agent and thus the thesis does not predict that they require knowledge, or they do correctly describe a motivating reason (as might be the case in situations where the agent is being cautious and uses the psychological fact in their practical reasoning)—but then the agent really is required to know the relevant psychological fact.

## **5.3 Factivity and Factoring**

The case for the factivity of "A reason to phi is that P," "His reason for phi-ing is/was that P," and "A reason he has to phi is that P" seems just as compelling as for paradigmatically factive attitudes such as "knows that" and "regrets that." Sentences like "His reason for leaving was that the house was on fire but the house wasn't on fire" sound terrible in the same way that "He regrets that the house was on fire but it wasn't" sound terrible. Meanwhile, the inference from "A reason he has to phi is that P" to "P" strikes **(p. 123)** us as deductively valid in the same way that the inference from "He regrets that P" to "P" strikes us as deductively valid.18 Of course there are true generic readings of sentences such as "A reason to take a teaching job is that it offers flexible hours," and one can truly utter such a sentence even on an occasion where one is contemplating a particular teaching job that does not offer flexible hours. But that does not make trouble for factivity any more than the fact that one can truly utter the true generic "People remember that they went to school" despite the fact that there are certain people who never go to school.

It is worth noting that there is an acceptable use of "His proof that P," "His memory was that P," and "His explanation was that P" which does not imply that P is true or provable. (Think of "His proof that God doesn't exist was terrible" and "His memory is that he never made that promise.") The use of the possessive in these cases is to signal, roughly, that something *seemed* like a genuine proof or a genuine remembering from the subject's point of view.19 Of course this is not the only use for the possessive in connection with "proof ." There is a standard reading on which "Andrew Wiles now has a proof of Fermat's last Theorem even though he hasn't proven that it is true" or "Her proof of the Pythagorean Theorem is shorter than his, but neither have proven the theorem" sound entirely defective. Perhaps the minority of philosophers who think that the possessive reason construction is non-factive are hearing a use of "Her reason" that works along the perspectival lines indicated above. Note, though, that as with "proof," even if there is such a use of the possessive, this is certainly not the only use—indeed the factive use seems to be more characteristic and the one of greater theoretical interest. Also, even if there is such a non-factive use, this would not mark an ambiguity distinctive of "reason." As we have seen, we can, for a wide variety of nouns N, use "Her/His N" to characterize something that seems to be N from the subject's perspective. This does not point to a theoretically interesting ambiguity in "reason" any more than it does for "proof" and "explanation."20 , 21

**(p. 124)** Granted that various "reason" constructions have at least an air of factivity, one might try to explain this away by maintaining that while "reason that P" does not semantically entail that P, such reason ascriptions somehow pragmatically communicate that P. It seems highly dubious that this so-called implication is a mere conversational implicature. (It is not clear what general conversational maxims would be flouted, and moreover the supposed implicatures do not appear to be cancellable.) Perhaps one might claim that the sentence lexically triggers a presupposition of factivity. But note first that, typically, the presuppositions of a lexical item tend to also be semantic entailments in simple non-embedded declarative environments.22 So, for example, while it is widely accepted that "X

knows that P" and "X regrets P" presuppose that P, it is also clear that they also semantically entail that P. Admittedly there is one kind of lexically triggered non-semantic implication that is not accompanied by entailment even in unembedded environments, namely conventional implicatures. (Thus, for example, "He is poor but happy" is usually taken to conventionally implicate but not semantically entail that there is some tension between being poor and happy.) But the move which maintains that reasons constructions carry a conventional implicature of factivity seems entirely ad hoc unless someone produces some data that would encourage the view that while "X knows that P" entails P, "X's reason was that P" conventionally implicates but does not entail P.23

A related question discussed by Schroeder is whether possessive reason constructions can be factored into a conjunction of a reason claim and a possession claim.24 For example, does "She has a reason for leaving, namely that there was a tiger in the room" factor into "There was a reason for her to leave the room, namely that there was a tiger, and she was in possession of that reason"? Putting aside the alleged perspectival reading noted above, we maintain, *pace* Schroeder, that possessive reasons do factor in this way.25 Certainly the superficial linguistic data strongly supports this view. It sounds very strange to say "He had a reason to leave though there was no reason for him to leave." This strongly suggests that "He had a reason to leave" entails "There was a reason for **(p. 125)** him to leave." Indeed, the factorization structure does not seem in any way peculiar to reasons talk. In general, "X had an F" entails there is an F and X had it. (For example, "He had a valuable ring" entails "There was a valuable ring and he had it.")

It is important not to conflate the factorization question with another question, namely whether the status of P as a reason is independent of P being possessed. Consider, by analogy, the property of being valuable. Some objects may count as valuable independently of who they are possessed by. But suppose, for example, that any object possessed by Paul McCartney is ipso facto valuable. Consider a biro whose value consists entirely in its being possessed by McCartney. Its status as valuable is not independent of its possession. Had Paul McCartney not possessed it, it would not have been valuable. None of this conflicts with the factorization of "McCartney has a valuable biro," and no ambiguity needs to be postulated for "valuable" to account for the relevant facts.

Similarly, we think that the status of some propositions as reasons depends on their being possessed. Suppose we are in a context where the guiding normative ordering source is subjective in the sense explained in section 5.1. In that context, a fact will be a reason only if it bears on what is most likely to achieve the relevant ends given the subject's evidence. Suppose that in such a context, a subject knows that there is a tiger in the room and runs. In that context, "The fact that there was a tiger in the room was a reason to run" is true, but it would not have been true if the agent had been oblivious to the presence of a tiger. For holding the subjective ordering source fixed, the sentence "That there is a tiger in the room is a reason to run" is false at such worlds. (Of course such a sentence might be true relative to a more objective ordering source.)26 In this case, then, the

status of the proposition that there is a tiger in the room as a reason for the agent to run is dependent on that proposition's being known and hence possessed.

In attempting to make trouble for factorization, Schroeder suggests an analogy between possessive reason talk and certain other possessive noun-phrase constructions such as "His father" and "Her golf partner." One's status as a father or as a golf partner does depend on there being someone that one is a father or golf partner of. Note that this does not, strictly speaking, conflict with factorization per se. After all, it is true enough that if X is Y's father, then X is *a* father. Moreover we think "reasons" talk is more akin to "valuable" than to "father." No father can be a father without being the father of someone. But many reasons can be reasons without being possessed by someone. This is obvious when the ordering source is a more objective one. (That something is poisonous is a reason for someone not to drink it even if that reason is not possessed.) Even for a subjective ordering source, not all reasons need to be possessed. Consider "That P is unlikely on his evidence is a reason for him not to be very confident about it." This can be true relative to a subjective ordering-source even when the agent in question does not know that P is unlikely on his evidence.

**(p. 126)** Schroeder's chief argument against the factorization view concerns a famous case (originally due to Williams) where someone is given a glass which in fact contains gasoline, but which the agent mistakenly believes contains gin and tonic and because of this drinks the liquid. Schroeder's argument seems to proceed as follows. First, given that the agent was not being irrational in this case, she must have acted for a reason (i.e. there was a motivating reason for the agent's action), and moreover the reason for which she acted must be a (possessed) normative reason. But then if we assume factivity (which Schroeder presents as driven by factorization) for possessed normative reasons, this reason must be a true proposition and, Schroeder argues, no such proposition is a good candidate for being the agent's reason for drinking in this case. (The main candidate he considers is the proposition that the agent believes that the glass contains gin and tonic.)

Our main objection to Schroeder's line here is that we think that, despite the temptation to say that the agent was not acting irrationally, there need not be a motivating reason for their action (let alone a motivating reason which is also a normative reason). We will return to this point below, but before that it is worth asking whether—rationality considerations aside—the agent indeed has any motivating or possessed normative reasons for drinking in this case.

With respect to motivating reasons, while we agree that there is a strong prima facie temptation to think that something was the agent's motivating reason for acting, this may be due to the fact that we are invariably content with such fallbacks as "The agent's reason was that she believed that/it seems that the glass contained gin and tonic." But as we noted above, such fallbacks may not survive critical reflection. And if we are willing (as Schroeder himself does) to jettison these fallbacks and maintain that the "believed that" or "it seems that" claims weren't after all the agent's motivating reasons, we ought to take seriously the hypothesis that there was no reasons for which the agent acted (though of course there were reasons why she acted the way she did, and though there may be propositions the agent treated or thought of as reasons).

What about possessed normative reasons? While we are inclined to accept that the agent did not act for such reasons as that the agent believed the glass contained gin and tonic or that it seemed to contain gin and tonic (i.e. these were not the agent's motivating reasons in this case, and arguably, there were simply no reasons for which the agent acted), we do think that certain of these propositions were reasons the agent had for acting. (By analogy, in the case discussed above where one hallucinates a tiger, that there looks to be a tiger is a reason for the agent to run even if it did not in fact serve as the agent's reason for running.) Moreover we find unpersuasive Schroeder's objections to counting such psychological propositions as possessed normative reasons.

Focusing on the suggestion that the possessed reason is the fact that the agent believed the glass contained gin and tonic, Schroeder considers an enlightened bystander who is asked to tally the reasons for and against drinking the liquid. Given factorization, if the fact that the agent believed there was gin and tonic was a reason he had to drink it, then that fact was a reason for the agent to drink it. But it would be very strange, Schroeder notes, for the enlightened bystander to cite the fact that the liquid was gasoline as a reason for the agent not to drink the liquid, while at the same time citing the fact that **(p. 127)** the agent believed the liquid to be gin and tonic as a reason for the agent to drink it. This strangeness persists for such suggestions as that the fact that the liquid appeared to be gin and tonic, or that the agent had good evidence that the liquid was gin and tonic, were reasons for the agent to drink it. Thus if Schroeder's argument works, it refutes all these other suggestions as well. The problem with the argument, however, is that it abstracts away from fact that in addition to the question whether a reason is possessed or unpossessed, there is also the question whether the relevant normative ordering-source is subjective or objective. Assume first that we are reading "reasons to phi" using a subjective ordering-source. In that setting, the fact that the liquid is gasoline has little bearing on whether the agent "ought" (read "subjectively") to drink, and thus would not figure at all in the bystander's table of reasons for and against the agent's drinking (even though the bystander knows that the glass contains gasoline). Suppose instead that the bystander uses an objective ordering-source. Then, arguably, the fact that the agent believes the glass contains gin and tonic is no reason at all for them to drink.27 Thus, even with factorization and factivity, we can explain the relevant strangeness by suitable appeal to the candidate ordering-sources.

Here is a further worry about the idea that in the bad case where, for example, a tiger is hallucinated, the proposition that it looks as if there is a tiger in front of a certain agent is a reason that agent has to run. The concern is that we are left with no happy view of what to say in the good case where the person knows there is a tiger. First, it seems strange to say that the "looks" proposition is a reason the person has to run in the bad case but not in the good case. But second, it seems strange to say that in the good case the person has two reasons to run—(i) that there is a tiger there and (ii) that it looks as if there is a tiger there. In response, we agree that the proposition that it looks like there is a tiger is avail

able in both the good case and the bad case. Indeed, as we noted, the cautious person may well use the "looks" proposition as their motivating reason even in the case where they know. (After all, they may be unsure whether they know . . .) So we do wish to claim that in the good case, both propositions are reasons the person has to run. Any sense of strangeness in this claim arises from a failure to notice one of two things. First, while each of the two propositions are available to the agent as suitable motivating reasons to run, we agree that it may be atypical that the person uses both propositions **(p. 128)** as motivating reasons.28 Second, there are many cases where a person has two reasons for acting a certain way or for believing something but where one is so much more decisive than the other that it is pragmatically strange to cite both. That the liquid tastes very bitter and that it contains arsenic are both reasons not to drink it. But it would be somewhat odd to say "The agent has two reasons to refrain from drinking that liquid—that it contains arsenic and that it tastes very bitter." We conclude, then, that the most plausible thing to say about the gin and tonic case is that the agent did possess a normative reason to drink, but that reason did not serve as the agent's motivating reason.

We close this section by discussing what is arguably the most pressing challenge for the view we have been proposing: namely the purported connection between motivating reasons and rationality. Our suggestion was that that in the gasoline case (*mutatis mutandis*, in the typical case where one hallucinates a tiger and runs), the agent acts for no motivating reasons. But the natural worry here is that the agent in such cases does not seem to be irrational, and there is a strong temptation to accept that anyone who acts for no motivating reasons is irrational. Indeed, Schroeder pushes this line even further by arguing that the only way of rescuing the agent from a charge of irrationality is to allow false propositions to function as both motivating and possessed reasons.

Even setting aside the fact that there is overwhelming evidence that our reasons talk is factive (see 5.3), it is not clear that allowing false propositions to function as motivating reasons provides a good theory for the connection between reasons and rationality. Indeed, such a view risks erring in the opposite direction—it will count people as rational when they are anything but. Think of people who have all sorts of belief pop into preservative memory out of nowhere on a regular basis and, because of this, act in a very haphazard way. Or think of someone who has utterly perverse moral views which shape his pattern of behavior. It is not particularly attractive to say "Such people are fully rational because they have excellent reasons for doing what they do." But by allowing any false proposition in as a reason, one risks licensing speeches like this.29

**(p. 129)** What is going on here, we think, is that there are at least two modes of evaluating agents which tug in different directions. For any property of an agent that we deem desirable, we will first think it a good thing that an agent manifest that property, but second, we will also deem it desirable that (roughly speaking) an agent acts in ways that would constitute manifesting that property under normal conditions. So, for example, a brain in a vat can get merit points on the second dimension, even if not on the first, with respect to the property of "being generous toward other people."30 This distinction carries over to acting for reasons: we take it to be a good thing for people to act for good reasons. But

we also take it to be a good thing for people to act in ways that under normal circumstances would constitute acting for good reasons. The hallucination cases without motivating reasons that we are inclined to count as rational are ones where, roughly speaking, the agent scores well on the second mode of evaluation even if they score poorly on the first. In general there is a danger of an all-purpose term like "rational" being overworked. One risks lapsing into incoherence if one takes it as a necessary condition for rationality that one has good motivating reasons but sufficient for rationality that one does well by the second mode of evaluation. Perhaps it would be better to drop the term "rationality" and more explicitly distinguish the various layers of evaluation. Allowing in false propositions as reasons is in effect a misguided attempt to collapse kinds of normative propriety that ought not to be conflated. We thus conclude that both factivity and factoring should be accepted.

## **5.4 Reasons: Explanation or Evidence?**

An interesting proposal defended in a series of papers by Stephen Kearns and Daniel Star is that a proposition is a reason for X to phi iff it is evidence that X ought to phi.31 This proposal is developed in a way that respects factivity and factoring, and can be rendered consistent with the distinction between possessed and unpossessed reasons, so long as one accepts a parallel distinction between possessed and unpossessed evidence.32 We think that this proposal has quite a lot going for it—indeed, we are quite unmoved by **(p. 130)** many of the concerns in the literature. Moreover, we think a position along these lines could be made stronger by recognizing context-sensitivity in the normative force of the infinitival "to phi." (For example, there may be some contexts in which normative force focuses on what's best all things considered, while others in which it corresponds to what is morally obligatory. This would take care of the worry that phi-ing can count as a reason for a supererogatory act, even though on one standard reading, it's not evidence that one ought to perform it.)

However, the view also faces some serious challenges. One worry has to do with how the view construes the notion of unpossessed normative reasons. As noted above, this requires us to accept some parallel notion of unpossessed evidence—evidence that is "out there," independently of the epistemic situation of any particular agent. Some such notions are not foreign to the literature in epistemology. Thus, for example, one might adopt Williamson's hypothesis that there is an objective agent- and world-independent evidential probability function *P*, and maintain that a fact *e* is evidence for a hypothesis *h* if *P(h*| *e*)>*P*(*h*).33 But note, first, that adopting Williamsonian evidential probability is far from an uncontroversial commitment (do we really want to accept that there is an objective, world-independent evidential probability that there are, say, pink elephants?). More importantly, it is highly doubtful that this notion of evidence will suffice for Kearns and Star's purposes: suppose, for example, that a glass contains arsenic, but an agent X does not know this. That the glass contains arsenic is an (unpossessed normative) reason for X to refrain from drinking, and thus Kearns and Star maintain that the fact that the glass contains arsenic is evidence that X ought not to drink it. But there is no reason to sup

pose that a Williamsonian probability distribution would deliver this verdict (recall that, for example, in many possible worlds arsenic is extremely good for X's health . . .). Rather, it seems that this fact is evidence only relative to some background body of information (which includes, among other things, the proposition that arsenic is poisonous).34 That is not to say that the view of reasons as evidence cannot be patched up with a theory of objective evidence (perhaps a contextually relevant background body of information might do some work here)35—but there is more to be said in developing this aspect of the view.

The second, more serious challenge for the view concerns a certain kind of potential counterexample. Consider a case where a subject is holding an apple in their hand and wondering whether to eat it. Suppose that, unbeknownst to the subject, a highly reliable book hidden in a cave on the other side of the world says that the apple is poisonous (and also says, using an objective "should," that no one should eat the apple). If the apple is indeed poisonous, we are happy to allow a context where it is true that the fact that **(p. 131)** the apple is poisonous is a reason for the agent not to eat the apple (using an objective "ought"). But whether or not the apple is poisonous, it is hard to recover a context where it seems true to say "That a reliable book said that the apple was poisonous was a reason for the agent not to eat the apple." On the other hand it seems entirely natural to say that the fact that the reliable book says that the apple is poisonous is evidence that the agent ought not to eat it. (Similarly the fact that the reliable books says that the agent ought not to eat it is evidence that the agent ought not to eat it.)

Kearns and Star offer two responses to this kind of example. The first assumes that the force of the example relies on the fact that even a reliable book might be fallible. They then argue that, all things considered, this cannot knock out the candidate reason, since all sorts of reasons for doing things are not in themselves conclusive. We agree that reasons do not have to be conclusive. Indeed, one way to see that focusing on the fallibility of the book is a red herring is to note that we can generate similar examples using factive verbs. To our ears, if a hermit in a cave on the other side of the world knows that the apple is poisonous, it remains hard to recover a context where it seems true to say "That someone knows that the apple is poisonous is a reason for the agent not to eat it" (though of course the fact about knowledge is evidence that the agent ought not to eat it).

In our view, the force of the example does not turn on fallibility but rather on a different feature. Following John Broome and others, we are tempted by the thought that there is a deep connection between reasons and explanation.36 The basic insight is that the fact that the hermit knows that the apple is poisonous is unsuitable as part of the explanation of why (for the objective "ought') the person ought not to eat the apple. By contrast, the fact that the apple is poisonous is just the sort of thing to appropriately figure in the explanation of why the agent ought not to eat the apple.

Kearns and Star offer a second response to the alleged counterexample, one that they think mitigates the force of explanation-based accounts of reasons. Their thought is that if the agent were to read the book in question, then the fact that the book says that the ap

ple is poisonous would give them a reason to refrain from eating it. (What of the suggestion that the book provides the proposition that the apple is poisonous as a reason? Given factivity, that would not work in a setting where the apple is not poisonous. But in that setting there would still seem to be a sense that reading the book would provide the agent with a reason not to eat the apple.) We agree that in the case where the book is read, there is a natural reading of "That the book says that the apple is poisonous is a reason for the agent not to eat the apple" on which it is true. However, in our view, this does not entail that in the case where the book is *not* read, the relevant fact about the book is a reason for the agent not to eat the apple.

Indeed, with a bit of care about the normative force of the infinitival "to-phi" construction, the explanation-based approach can predict all the data concerning this **(p. 132)** example very nicely. First, consider the case where the "ought" is objective: in that case, the fact about the book is not a suitable part of the explanation and so does not count as a reason. Meanwhile, in the case where the "ought" is subjective, it matters whether or not the subject knows that a reliable book says that the apple is poisonous. When this is not known, the fact about the book plays no explanatory role vis-à-vis the subjective "ought," since, roughly speaking, it does not explain relevant features of the expected utilities of the actions available to the agent.37 Meanwhile, when the fact about the book is known, it does seem that the fact can be explanatorily relevant.

One might object that it is not the fact that a reliable book says that the apple is poisonous, but rather the fact that the agent knows this fact, which is explanatorily relevant to the subjective "ought" claim. However, we think in general that when an agent knows that p, the fact that p is explanatory of the knowledge fact. (The causal theory of knowledge is driven by this insight, though we don't ourselves assume that explanations have to be of an efficient causal sort.) Note that there is nothing at all surprising about the fact that subjective "oughts" can be explained by external world facts in the case where they are known. The same is true for completely mundane explanations of psychological attitudes and actions. For example, if an agent knows there is a diamond on the floor and is thereby excited, it is entirely natural to say that they are excited because there is a diamond on the floor or that they are bending down because there is a diamond on the floor. We conclude that the explanation account predicts that there is a natural true reading of "There is a reason for the agent to eat the apple, namely that a reliable book says that it is poisonous" when the agent knows that a reliable book says so but no natural true reading when the agent does not know this.38

The explanation approach is thus a promising alternative to the evidence view, but it does face a serious challenge of its own. We cannot in general accept that p is a reason for X to phi just in case p explains (or partially explains) why X ought to phi, because p can be a reason for X to phi even in cases where it is not true that X ought to phi. Since the "reason why" construction is factive in the sense that "p is a reason why q" can only be true if q is true, the explanation approach—at least in its simplest form—fails. The evidence approach, on the other hand, is naturally suited to accommodate this structure (it is completely standard for p to be evidence for q even if q is not true). Broome is of course

aware of this issue and offers the following response. Assume it is a fact that **(p. 133)** one ought to (/ought not to) phi. There is a particular kind of explanation of this fact: a "weighing explanation." Such explanations work by analogy with the process of placing weights on a balance: we place weights on either side of the balance, and if the weights on the left-hand pan add up to more than the weights on the right-hand pan, the scale tips to the left. By analogy, consider a certain kind of explanation for why one ought to phi: "There are reason for you to phi and reasons for you not to phi. Each reason is associated with a number which represents its weight. The numbers associated with the reasons to phi add up to more than the numbers associated with the reasons not to phi. That is why you ought to phi" (Broome 2004: 36–7). The idea, then, is that something counts as a *pro tanto* reason for X to phi, just in case it plays the "pro phi-ing" role in a weighing explanation, even if the explanation in question is ultimately explanation for X ought *not* to phi.

The development of the explanation account in terms of weighing explanations has the disadvantage that it makes the view far less clean, but we think it faces a deeper worry: placing weights on a scale is simply the wrong model for how to think about reasons forand-against phi-ing.39 Consider some of the central features of the mechanical case: placing weights on a balance is a monotonic process (in the sense that placing more weights on one pan can only increase the total weight on that pan), and it is additive (to determine how much total weight there is on one pan of the balance, one simply adds the weights). Relatedly, the only feature that matters to the process of placing weights is how much each weight weighs (if at some stage of the process one places a golden square weight of 5 kg on the left-hand pan that would have exactly the same effect on the process as placing a silver round weight of 5 kg on that pan).

On the other hand, the process of considering reasons for-and-against phi-ing does not respect these features. Suppose you are trying to decide whether or not to buy a certain item on eBay. If the item is made of jello, this fact might on its own be a reason for you to buy it (you like eating jello). If the item is a car, this fact might on its own be a reason for you to buy it (you need a car to travel around town). But if we already take on board that it's made of jello, the fact that it's a car will no longer count as a reason for buying it (such car will be of little use in travelling around), and moreover this fact will undermine the claim that being made of jello is a reason for you to buy the item (the jello car would presumably be grubby from the road, so you would no longer want to eat it). Similarly, if you like red items, then the fact that an item is bright red might be a reason (of a certain strength) for you to buy it, and the fact that it's red might also be a reason (of a certain strength) for you to buy it. But the strengths of the two reasons **(p. 134)** do not add up (you don't have twice as much reason to buy it because it's both red and bright red). Finally, considered on its own, the fact that an item is made of jello might be a reason of equal strength for you to buy it as the fact that it's manufactured by Raleigh (you have an equal need for jello items for your kitchen and for Raleigh items for your bicycle collection). But adding each of these two facts to my deliberation can have radically different effects on the ultimate process (it will matter a lot to your overall deliberation which one you take on board, if you later also consider the fact that the item is a bicycle . . .). One could object that the talk of a so-called deliberation process is an unhelpful metaphor

here, but the same point can be made more precisely without talk of such a process: if *pro tanto* reasons worked by analogy with weights, one would expect them to obey certain principles. For example, one would expect them to obey the principle that if p is a reason to phi and q is a reason to phi, then p and q is a reason to phi. But the above examples show that this principle fails (that the item is made of jello is a reason to buy it, that the item is a car is a reason to buy it, but that it's a car made of jello is not a reason to buy it). We conclude that the weighing analogy is simply the wrong way to think about *pro tanto* reasons.

The evidence view, by contrast, has exactly the right resources to deal with the above structure: evidence can be non-monotonic, non-additive, and the ultimate import of a certain piece of evidence depends on its specific content, not only on how strongly it supports the proposition in question (these features become clear when evidence is cashed out in probabilistic terms). But given our worry concerning the evidence view (examples such as the one involving the book or hermit above), one wonders if there are more subtle ways to expand the explanation view, so as to cover *pro tanto* reasons, that go beyond the simple weights model. While we shall not undertake that project here, we might mention a few bodies of work from which one might draw inspiration. First, causal forces display a phenomenon akin to *pro tanto* reasons. There can be a force inclining an object to phi, even if it doesn't phi. A simple weights model for causal forces will obviously be too naïve. But a view of causal forces as evidence does not seem particularly palatable either. (For example, it will overgenerate. An effect might be evidence of its cause, but that doesn't mean it exerted causal influence on its cause.) Perhaps some of the ideological structure crafted to describe how causal forces combine might be of help in the current context. (Note, though, that causal forces in physics can be represented by vectors which can be added in the usual way. On the other hand, it's not clear that causal forces at the macro level are amenable to a clear vector representation.) Second, there is a great deal of literature on the phenomenon of *pro tanto* reasons in the epistemological literature that deploys inference graphs that encode directed patterns and strength of support between "prima facie" reasons and various propositions as well as phenomena of defeat (nodes on inference graphs get marked as defeated or undefeated).40 The focus **(p. 135)** in that context is of course on reasons to believe, but insofar as they prove illuminating in the original context of application, there is no obvious reason why structurally similar graphs might not be of use in the current context.41 , 42

One additional aspect of the way we talk about reasons is that we sometimes talk about a reason being strong or weak, one reason being stronger than another, or a certain reason outweighing another. It might seem that one advantage of the evidence view over the (suitably amended) explanation account is that it allows for a ready-made analysis of such talk of the relative strength of reasons (after all, evidence too comes in various strengths, one piece of evidence can outweigh another, and so forth).43 One should note, however, that our talk of the relative strength of reasons for phi-ing is far too context-sensitive and multidimensional to map neatly to the strength of evidence that one ought to phi. To see some of the complexity, consider the following case. X is given a glass of liquid which is both tasty and such that drinking it will save X's life. Let us also suppose that there are

no countervailing considerations against drinking. In this case, the conjunctive fact that the liquid is tasty and there are no countervailing considerations is completely conclusive evidence that X ought to drink. Similarly, the conjunctive fact that the liquid will save X's life and there are no countervailing considerations is also completely conclusive evidence that X ought to drink. Thus both facts provide equally good evidence (namely, conclusive evidence) for the claim that X ought to drink. But intuitively, the fact that the liquid will save X's life and there are no countervailing considerations provides a much better reason for X to drink than the corresponding fact **(p. 136)** about the liquid being tasty. Roughly put, what this suggests is that the relative strength of reasons depends not only on how well the reason fact supports the aim in question, but also on how much we value the aim. To see some further complications, consider the following example: suppose you enjoy fizzy drinks, and you enjoy pink drinks, and you value both properties equally. Suppose also that there is no correlation between a drink being fizzy and its being unhealthy, but that if the drink is pink, it's slightly more likely to be unhealthy (though assume that there is no explanatory connection between the color and the healthiness facts—it just turns out that manufacturers who produce less healthy drinks also tend to like the color pink). In the absence of any other considerations, that a drink is fizzy provides stronger evidence that you ought to drink than that it's pink (because the fact that it's pink also slightly increases the probability that it's unhealthy—which is a consideration against drinking). But intuitively, given that you value both properties equally, that the drink is pink is an equally good reason for you to drink as that it's fizzy. Roughly put, what this suggests is that the relative strength of reasons depends, at least in some cases, more on the explanatory force of each reason than on its evidential force. Of course, these considerations are not in themselves objections to the evidence view per se (the view does not have to commit to analyzing the strength of reasons in terms of the strength of evidence), but it does suggest that the evidence view does not have the advantage of offering a ready-made analysis of such talk.

Another worry that might arise at this point is that the two views are sufficiently vague that it is hard to see what's at stake here (this worry is especially pertinent barring a worked-out theory of unpossessed reasons in the case of the evidence view, and of *pro tanto* reasons in the case of the explanation view). A helpful way to defuse this worry and get some traction in the debate is to note that there are a range of structural features that plausibly separate the explanation view of reasons from an evidence-based one. Here are some such features:

**(1)** *Conjunctions with irrelevant facts*. Suppose that P is evidence that one ought to phi, and consider the conjunction of P with some completely irrelevant fact R (in probabilistic terms: assume that the conditional probability of the ought claim given P is the same as the condition probability of the "ought" claim given the conjunction). In this case, the conjunctive fact P AND R will also be evidence that one ought to phi. For example, if the fact that the apple is poisonous is evidence that one ought not to eat it, then the fact that the apple is poisonous and Paris is the capital of France is also evidence that one ought not to eat it.

Explanations, by contrast, do not tolerate the addition of irrelevant conjuncts: suppose that the fact that the apple is poisonous is part of the explanation of why one ought not to eat it, it is very odd to say that the fact that the apple is poisonous and Paris is the capital of France is part of the explanation of why one ought not to eat the apple. The two views thus have conflicting verdicts on the question of whether the fact that the apple is poisonous and Paris is the capital of France is a reason for the agent to refrain from eating the apple.

**(p. 137) (2)** *Reflexivity of reasons*. On many natural conceptions of evidence, any proposition (at least any non-trivial proposition) is evidence for itself. (In a probabilistic framework, the key consideration here is that, for any proposition with a defined probability above zero, its conditional probability on itself is 1.) The evidencebased approach thus predicts that the fact that the agent ought not to eat the apple is a reason for the agent not to eat the apple.

By contrast, explanations are plausibly irreflexive in nearly all cases. Thus the explanation account predicts that in typical cases the fact that the agent ought not to eat the apple is not a reason for the agent not to eat the apple.

**(3)** *A reason for both ought-phi and ought-not-phi*. On most conceptions of evidence, no proposition can be both evidence for p and evidence for not-p. This in itself does not rule out that the proposition can be evidence both for for the claim that one ought to phi and for the claim that one ought not to phi (if one had non-zero prior in the claim that one neither ought to phi nor ought not to phi, then learning the disjunction that one either ought to phi or ought not to phi can increase one's probability in both "ought" claims). However, assume we are in a setting where it is certain on one's evidence that either one ought to phi or one ought not to phi (and certain that it is not the case that both "ought" claims are true). In this setting, nothing can be evidence both for the claim that one ought to phi and for the claim that one ought not to phi; hence, on the evidence view of reasons, nothing can serve in this situation as both a reason to phi and a reason not to phi.44

But this is not so on the explanation view. The argument depends, of course, on how we fill out the details of the account of *pro tanto* reasons, but plausibly any such way would allow that the same fact can, in the same context, have explanatory pull both toward the claim that one ought to phi and toward the claim that one ought not to phi. For example, suppose that in front of you is a glass containing some blood. Drinking blood is disgusting but on this occasion it will save your life. The fact that the glass contains blood has explanatory pull both toward the claim that you ought not to drink (if there weren't countervailing considerations here, it would have explained why you ought not to drink) and toward the claim that you ought to drink (after all, it partially explains why you ought to drink). The explanation view thus predicts that the fact is both a reason for you to drink and a reason for you not to drink. The evidence view, by contrast, predicts (fixing the assumptions above) that in this case it is only a reason for you to drink.

For what it's worth, we think these differing predictions provide some encouragement for the explanation-based approach over the evidence-based one, but we admit that the data

in these cases are not entirely clear. The main purpose of these distinctions, **(p. 138)** however, is not so much to defend one side of the debate as to show that, vague as they are, there are substantive differences between the two approaches, and to point to the kinds of considerations that can be useful in advancing the debate.

In this section we have contrasted two main approaches to what it is for the fact that p to be a reason for X to phi: the evidence approach and the explanation approach. One might of course offer another account. Alternatively, one might argue that the concept of a reason for X to phi is a primitive concept that cannot be reduced to other, more basic ones.45 While we are perfectly happy with the use of primitive concepts in philosophy, the highly gerrymandered nature of our reasons-talk should cause us to doubt that reasons are indeed such a basic concept.46 At any rate, we hope our remarks in this chapter have gone some way toward bringing some clarity to this disorderly area.

## **References**

Abbott, B. (2006). "Where Have Some of the Presuppositions Gone?' In B. Birner and G. Ward (eds), *Drawing the Boundaries of Meaning: Neo-Gricean Studies in Pragmatics and Semantics in Honor of Laurence R. Horn*, 1–20. Philadelphia: John Benjamins.

Broome, J. (2004). "Reasons." In J. Wallace, M. Smith, S. Scheffler, and P. Pettit (eds), *Reason and Value: Themes from the Moral Philosophy of Joseph Raz*, 28–55. Oxford: Oxford University Press.

Broome, J. (2013). *Rationality Through Reasoning,* Oxford: Blackwell.

Finlay, S. (2014). *Confusion of Tongues: A Theory of Normative Language*. New York: Oxford University Press.

Hornsby, J. (2008). "A Disjunctive Conception of Acting for Reasons." In A. Haddock and F. MacPherson (eds), *Disjunctivism: Perception, Action, Knowledge*, 244–61. Oxford: Oxford University Press.

Hyman, J. (1999). "How Knowledge Works." *Philosophical Quarterly* 49: 433–51.

Kearns, S., and D. Star (2008). "Reasons: Explanations or Evidence?' *Ethics* 119: 31–66.

Kearns, S., and D. Star (2009). "Reasons as Evidence." *Oxford Studies in Metaethics* 4: 215–42.

Kearns, S., and D. Star (2013). "Weighing Reasons." *Journal of Moral Philosophy* 10: 70– 86.

Kratzer, A. (1981). "The Notional Category of Modality." In H. J. Eikmeyer and H. Rieser (eds), *Words, Worlds, and Contexts*, 38–74. Berlin: de Gruyter.

Lasonen-Aarnio, M. (2010). "Is There a Viable Account of Well-Founded Belief?" *Erkenntnis* 72: 205–31.

Parfit, D. (2011). *On What Matters*. Oxford: Oxford University Press.

**(p. 139)** Pollock, J. (1995). *Cognitive Carpentry: A Blueprint for How to Build a Person*. Cambridge, Mass.: MIT Press.

Potts, C. (2007). "Conventional Implicatures: A Distinguished Class of Meanings." In G. Ramchand and C. Reiss (eds), *The Oxford Handbook of Linguistic Interfaces*, 475–501. Oxford: Oxford University Press.

Schroeder, M. (2008). "Having Reasons." *Philosophical Studies* 139: 57–71.

Schroeter, L., and F. Schroeter (2009). "Reasons as Right Makers." *Philosophical Explorations* 12: 279–96.

Unger, P. (1975). *Ignorance: A Case for Skepticism*. Oxford: Clarendon Press.

Williamson, T. (2000): *Knowledge and its Limits*. Oxford: Oxford University Press. **(p. 140)**

## **Notes:**

[^000]: Thanks to audiences in LSE, Oxford, and in the central APA (especially to Mark Schroeder) for helpful discussion. Thanks also to Michael Brady, John Broome, Christina Dietz, Julien Dutant, David Enoch, Maria Lasonen-Aarnio, Daniel Star, and Tim Williamson for their comments and suggestions.

[^1]: We shall not undertake to argue here against the main rival, namely that states and events are reasons (in the primary sense). We also note in passing one interesting construction that we shall not focus on, namely, "Her/His reason for v-ing was to phi." It is plausible that this is a propositional use—perhaps it is elliptical for "His/Her reason for ving was that his/her goal was to phi."

[^2]: One natural way of thinking about this is Kratzer's (see e.g. Kratzer 1981), where the various uses of "ought" have a common skeletal logical structure but are distinguished by being associated with different ways of ranking states of affairs (she calls these modes of ranking "ordering sources") and/or differing domains of states of affairs ("modal bases").

[^3]: Obviously there are also sorts of further distinctions (e.g. what is best relative to the agent's goals or instead relative to some ethical or legal way of ranking states of affairs).

[^4]: If one wants to focus on a particular subset of reasons to believe—*epistemic* reasons to believe—one can do so by appealing to an epistemic kind of ordering-source for resolving the context-sensitivity of "X ought to believe p." (For example, we can rank beliefs as better or worse according to their instrumental goodness vis-à-vis the agent's happiness, or instead as closeness to some epistemic ideal.)

[^5]: Another illustration of the flexibility of "my reason": suppose various people each have a reason for a certain bridge to be built pinned to their chest. Someone can in this context say "My reason for the bridge being built is better than yours." (Thanks to Tim Williamson here.)

[^6]: It is also worth keeping in mind that the possessive construction "his reason for phiing was that p" is typically used to mark motivating rather than possessed normative reasons.

[^7]: We are attracted to a stronger claim still: (S knows P and P is a reason for S to phi) iff P is a reason to phi which S possesses. But we won't undertake to defend that here.

[^8]: This line of argument follows that of Unger (1975), Hyman (1999), and Hornsby (2008).

[^9]: A putative counterexample: A sexist employer promotes a man over a female competitor. Let us suppose in this case that the employer would cite as their own motivating reason the fact that the male employee gave an excellent speech at the annual general meeting. But suppose that the employer would, due to their sexist biases, have chosen the employee at all nearby worlds. It might reasonably be claimed that it is their bias and not the speech that was the reason why the male was chosen for promotion. There are various ways to resist this attempt to block the entailment from motivating reasons to reasons why. Depending on how the details are fleshed out, this might be (i) a case where both the sexist bias and the speech are reasons why or (ii) a case where the employer is under an illusion, mistakenly thinking the fact about the speech was a motivating reason when in fact it was not.

[^10]: One objection that we will not consider at length is that possession merely requires being in a position to know (as opposed to actually knowing). One way of motivating this thought is by appeal to examples using the possessive construction as applied to normative reasons where it is obvious that the person does not know. (For example, if there is a post-it note bearing bad news that is there to be read but not yet read, it doesn't sound too bad to say "The agent has reason to be depressed.") Such examples trade on the flexibility of the possessive construction noted earlier—we think it unpromising to look for a single epistemic relation that will accommodate both these examples and paradigmatic examples of possessed reasons, especially as the possessive-normative construction extends in certain contexts to cases where there is no interesting epistemic relation, potential or actual, to the relevant fact. Another way to try and resist the claim that possession requires knowledge is to maintain that certain stative factives—such as seeing that—suffice to enable p to be possessed as a reason but don't require knowledge, because they don't require belief. Our view is that at best, the relevant considerations indicate that knowledge does not require belief. But pursuing this would take us too far afield.

[^11]: Notice that in some cases the "looks" or "appears" fallbacks are not a distinct option from the belief fallback. Consider a case where someone has a belief in preservative memory that fails to be knowledge and which is not accompanied by any phenomenology. Here there is no belief-sustaining seeming fact distinct from the belief itself (i.e. no seem

ing fact other than facts such as "it appeared to her that p") which can be appealed to as the person's reason for acting.

[^12]: As Hyman (1999) notes, one such special case is where X's reason for visiting a psychiatrist is that X believes she is being constantly followed.

[^13]: Matters are actually a bit more delicate. We tend to use such "his reason for phi-ing" constructions only to explain actions are normatively evaluable. Thus there is an interesting contrast between e.g. physical pain and emotional grief: "Her reason for being in pain is that someone stepped on her foot" is, in most cases infelicitous, while "Her reason for being in pain was that her father died" is entirely felicitous. Precisely what accounts for this contrast is a matter for a separate discussion.

[^14]: Thanks for discussions with Christina Dietz here. Hornsby (2007) argues that we cannot understand such ascriptions as expressing explanatory reasons because when we truly make such ascriptions as "X's reason for running was that she believed there was a tiger there," those ascriptions are true in virtue of some reasoning process that X undergoes (this is contrasted with some other cases of explanation: if the reason the bridge collapsed was that it had a weak link, this is not true in virtue of any reasoning-like process on behalf of the bridge). But even if the psychological reasons ascription is true in virtue of some reasoning-like process on behalf of X, this does nothing to rule out that the reason is explanatory (explanations of different facts can be highly diverse, and in this case the particular explanation might appeal to X's reasoning).

[^15]: Of course, if in addition to her Gettiered-belief about the patch's color, Jill is also causally sensitive to the patch's color, the sentence would have a true reading as a psychological-reason-why ascription. (But note that even in that case, there will also be a second reading—the motivating reasons one—on which the ascription would be false.)

[^16]: A similar worry is expressed by Schroeder (2008). (Schroeder does not himself endorse the thesis that possession requires knowledge, but he does maintain that in the case of worldly-facts, to have p as a reason one should stand in some epistemic relation to the reason, e.g. believing p; and he maintains that if a psychological fact is to act as a possessed reason, the agent would be required to stand in the same epistemic relation to the relevant psychological fact.)

[^17]: The claim that there can be cases where an agent falsely believes that they are acting for a motivating reason might lead the reader to suspect that we are defending here the view that all motivating reasons are normative reasons. This, however, would be a misunderstanding of our argument: what we have argued for is merely the claim that motivating reasons have to be both known and in practice play the right kind of motivating role in the agent's action. This still leaves open the view that a known fact can be a motivating reason to phi even if it does not count in favor of phi-ing, and hence is not a normative reason. For example, if the reason for which a sexist employer chooses not to promote a

female employee is that the employee is a woman, that might be a motivating reason that is not a normative reason.

[^18]: It goes without saying that in a case where an agent mistakenly takes themselves to know that P even though not-P, they will happily report themselves by such constructions as "My reason for phi-ing was that P." This is no more evidence for the non-factivity of this reason construction than the fact that such an agent might say "I know that P" is evidence that knowledge isn't factive. (We mention this partially because Schroeder seems to be misled into thinking that such perspectival reports provide some encouragement for the claim that possessed reason ascriptions are non-factive: see Schroeder 2008: 10.)

[^19]: Cf. Hyman (1999: 445).

[^20]: Also relevant are the following uses of definites and demonstratives: "The/That diamond is fake," "The/That proof is terrible." A systematic treatment of the nature of proofs should not give such uses central stage any more than a systematic treatment of the nature of diamonds ought to.

[^21]: One of our main opponents is Mark Schroeder (Schroeder 2008), who argues that propositions don't have to be true in order to be what he calls "subjective" reasons and where there is a fundamental ambiguity in "reason" between the factive "objective" use and the non-factive "subjective" use of "reason." Even if one granted a non-factive use of "His reason" of the sort suggested above, that would not do much to advance Schroeder's vision. First, that use does not point to an interesting ambiguity of "reason." Second, *pace* Schroder's discussion, it does not suggest that possessive reason constructions are in general non-factive. And third, Schroeder seems to suggest that the use of "His reason" he is interested in does at least carry an *implication* of factivity (even if it does not strictly entail factivity). On the other hand, the perspectival use of "His reason" discussed above carries no such implication.

[^22]: See Abbott (2006) for the claim that this is true of all presuppositions.

[^23]: Moreover, the factivity implication for reasons ascriptions fails the standard tests for being a conventional implicature (see Potts 2007). Here is one such test: conventional implicatures (but not entailments or presuppositions) seem to survive under propositional attitude reports. Thus, for example, with implicatures generated by apposatives we get: "John believes that Lance Armstrong, that cheater, deserves his medals" commits the speaker to the claim that Lance is a cheater. Note that the factivity of reason-constructions fails this test: "John thought that Mary's reason for leaving was that she was bored" does not seem to commit the speaker to the claim that Mary was bored.

[^24]: See Schroeder (2008), who argues that they cannot be so factored.

[^25]: On any use of "There was a reason, namely P" that is factive, the perspectival "His reason was that P" will not factorize, since the latter but not the former can be acceptable even where not-P. (Note that this feature is shared with the perspectival readings of other constructions—on the perspectival reading, "His proof of p was long" doesn't entail "There was a proof of p," so cannot be factorized into a conjunction with this as one of the conjuncts.)

[^26]: Note that we don't wish to claim that for a subjective ordering source, the only way that some P can function as a reason is by being known. We return to this point below and in 5.4.

[^27]: This at least seems to be plausible if we adopt the view of reasons as explanations (cf. 5.4)—that the agent believes the glass contains gin and tonic arguably has no explanatory force in support of the claim that they ought (objectively) to drink. (The argument is somewhat complicated because it involves the controversial case of a *pro tanto* reason. But here is a similar case that illustrates the point without appealing to *pro tanto* reasons: the glass in fact contains gasoline. Unbeknownst to the agent, drinking gasoline would make them feel very unwell but ultimately save their life from a rare disease. The agent falsely believes the glass contains gin and tonic, and thereby drinks. Here the agent ought (objectively) to drink, but the fact that they believe that the glass contains gin and tonic is in no way part of the explanation of why they ought to drink.) At any rate, even if one wishes to count the belief-fact as a reason to drink, it at most would act as a very weak and trivially overridden reason. Either way, one would predict some discomfort in counting the belief fact as having any substantive force to the "pro drinking" side.

[^28]: Unless of course one thought (i) that the knowledge that there is a tiger is inferred from knowledge that it looks as if there is a tiger and (ii) that this inferential structure is sufficient for both to count as motivating reasons.

[^29]: A common reaction we receive to this line is that the problem can be avoided if we allow false propositions to count as motivating reasons only when the agent *justifiably* believes them (or at least, count only justifiedly believed propositions as the motivating reasons of *rational* agents). Discussing this suggestion in full would require more space that we have here, but here are a couple of considerations that tell against it. First, suppose that an agent knows P, P provides reasonable support for a false proposition Q which the agent then justifiably believes, and Q logically entails R. If we then allow Q to act as a motivating reason for the agent in question, then since Q logically entails R, Q is a completely decisive reason for the agent to believe R. But it is clear that, even if the agent is not being entirely unreasonable to believe R, she does not have a decisive reason to believe R either.

Second, our opponent faces a dilemma here. Either the notion of justification in play is very minimal, in which case it would leave the revised suggestion with exactly the same problem as the original one. (For example, if all that is required is internal coherence of one's beliefs, then we can imagine an agent that has complete sets of internally coherent beliefs pop up out of nowhere and haphazardly into their preservative memory. Such an agent would hardly be acting rationally.) Alternatively, if the notion of justification in play is quite demanding, then even an agent that is intuitively (in one sense, at least) rational can often form unjustified beliefs. Thus, for example, if P is taken to justify Q just in case P provides a level of (objective) evidential support for Q that is above a given threshold,

then in cases where P provides evidential support for Q that is just barely below the threshold, a reasonable agent with good intentions could easily think that P justifies Q and come to believe Q. But then there will be many cases of intuitively rational agents that act on propositions that they are unjustified in believing, so we are back to a position that allows for "reason illusions": sometimes agents who we would intuitively take to be rational nevertheless act for no motivating reason. This is a claim we ourselves accept, but it was precisely this consequence that the denial of the factivity of reasons was intended to avoid.

[^30]: Cf. Williamson on primary vs. secondary norms (Williamson 2000: ch. 11).

[^31]: See especially Kearns and Star (2008, 2009, 2013).

[^32]: Though see our concern about the latter below.

[^33]: See Williamson (2000: chs 9 and 10), though note that Williamson himself does not make use of the idea of unpossessed evidence. (Unpossessed evidence does not satisfy the functional roles that Williamson takes to be key to a proposition's being evidence, e.g. the role of justifying belief.)

[^34]: And obviously, it would not do to just look at X's knowledge as the background body of evidence (after all, X has a reason to refrain from drinking, even if X doesn't know that arsenic is poisonous).

[^35]: Cf. Kratzer's notion of circumstantial modality.

[^36]: See Broome (2004) and (2013), as well as so-called "right-maker" accounts such as that of Schroeter and Schroeter (2009).

[^37]: Though, as we have noted, it is not in general true that unknown facts cannot be explanatory in this way. For example, the fact that such and such is likely on the subject's evidence can, on our view, be explanatory even if the relevant probabilitistic fact is not known to the agent. And the fact that an object is round might explain why it looks round even when it is not known to be round, where this "looks" fact may in turn be important to the expected utility profile.

[^38]: One complication: perhaps there is a use of "ought" that is intermediate between subjective and objective by being grounded, not on the evidence the subject has, but (roughly) on evidence that is easily available to the subject. (Think of a case where a note is on the fridge but not attended to that says "The apple is poisonous.") In this setting it might be natural to invoke the note in explaining what the agent ought to do.

[^39]: Broome acknowledges the limitations of the metaphor and hedges his view by saying: "Such a strictly analogous explanation rarely seems appropriate. For one thing, it often seems inappropriate to associate a reason with anything so precise as a number to represent its weight. Secondly, although we can aggregate together the weights of several reasons, to aggregate them simply by adding up also often seems inappropriate. So-called

'organic' interactions between reasons often mean that their aggregate effect differs from the total of their weights" (2004: 37). Simiar reservations are stated in Broome (2013: 52). What is not clear, though, is what survives of the weighing analogy after we seriously take these points on board.

[^40]: This kind of project is associated above all with John Pollock (e.g. 1995). For critical discussion, see Lasonen-Aarnio (2010).

[^41]: Perhaps one or other of these models might also be helpful in making out a distinction that we have not done much with, namely that between a proposition's being an overridden reason and its being no reason at all. Suppose that a house has an air-conditioning unit. But suppose further that use of air-conditioners of that model has been made illegal. In that setting, it is natural to say that the fact that the house has an air-conditioning unit is no reason at all to buy it (as opposed to its being some reason to buy it, albeit one that is overridden by other factors.) Thanks to Julien Dutant here.

[^42]: Another version of the reasons as explanation view that does not rely on the weighing model appears in Finlay (2014: ch. 4). Finlay's proposal is that a *pro tanto* reason for s to phi is not an explanation for why s ought to phi, but rather an explanation of why it is good for x to phi.

It is not clear, however, that this solves the problem: after all, if the medicine saves your life but is disgusting you have a *pro tanto* reason to refrain from drinking it, but it is far from clear that it is good for you to refrain from drinking. Finlay's response to this worry is that something can be said to be "good" in many degrees and relative to different ends —it is sufficient for a *pro tanto* reason to be good "in some way and to some degree" (Finlay 2014: 90). The problem, however, is that this risks making *pro tanto* reasons ascriptions far too weak (it is not clear that on this liberal interpretation we will get true readings of "He has no reason to do this"). Relatedly, on this account it is not clear why considering one's various *pro tanto* reasons should play any role in determining what one ought to do. After all, what one "ought" to do depends on the specific ends determined by the contextual resolution of "ought," and the fact that an action is good relative to *other* ends is irrelevant.

[^43]: Kearns and Star (2009: §2.4) make this argument. Of course, Broome's "weights model" seems particularly well-suited for the task of accounting for the strength of reasons, but as we explained above we think that this model fails for other reasons. It is also worth noting in this context that the fact that we sometimes talk of a reason being "out*weighed*" by another should not be taken to lend too much support to the weights model. After all, we also talk of a piece of evidence outweighing another, but it's fairly clear that we should not opt for a weights model for evidence.

[^44]: This feature of the evidence view is also highlighted in John Brunero's Ch. 14 in this volume.

[^45]: See e.g. Parfit (2011).

[^46]: Another reason to be initially suspicious about the thought that reasons-talk is fundamental is that it does not translate very neatly into various other languages. In Hebrew, for example, there is no very natural translation for sentences such as "Her reason for running was that there was a tiger." The closest translation would use instead of "reason" a word which (at least on the face of it) literally means "cause," and moreover drops the possessive altogether. No doubt, a lot more needs to be explored to flesh this into a fullfledged argument against reasons fundamentality, but we have some reason to worry about views that hold that English happens to carve reality at its fundamental joints, while other natural languages do not.

---

