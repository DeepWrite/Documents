# PART II. REASONS, MOTIVATION, AND ACTION EXPLANATION

# 6. Internalism and Externalism about Reasons 

*Hille Paakkunainen*

### **Abstract and Keywords**

Internalism about normative reasons for action, in its broadest characterization, holds that each agent A's reasons to act are constrained by some motivational fact, M, about A. Different versions of internalism differ on what M is. This chapter examines Bernard Williams's (1981) influential version of, and argument for, internalism, in a broadly sympathetic vein. I isolate the key assumptions driving Williams's argument, tracing their influence on Williams's views and on the literature he sparked; and arguing that each assumption, when properly understood, is more plausible than some recent critics think. The upshot is that Williams's internalism, and the assumptions that generate it, remain serious contenders on the contemporary scene.

Keywords: internalism, externalism, reasons for action, Williams, reasons and motivation, deliberative constraint

## **6.1 Reasons and Motives**

"You have every reason to go see him right now." "There are so many more reasons against it than for it. Still, I'm going to do it. Caution to the wind!" Such statements should look familiar. They employ the concept of a *normative reason* for (or against) action. Normative reasons for an agent A to do something, Φ, are considerations that justify, recommend or call for A's Φ-ing, at least *pro tanto*. Normative reasons are often contrasted with *motivating* reasons: the reasons for which an agent acts, and that thereby explain the agent's doing what she does. The reasons for which A Φs needn't also be normative reasons for A to Φ. Axl's motivating reason to visit Bea might be that his visit would aggravate Bea. Perhaps this is Axl's motivating reason because Axl enjoys aggravating Bea, and tends to seek out every opportunity to do so.1 But this motivating reason might do nothing to justify the visit. (On the general contrast between motivating and normative reasons, see McNaughton and Rawling, Chapter 7 this volume. On the **(p. 144)** metaphysics of motivating reasons, and on different ways of using the term, see Wiland, Chapter 8 this volume.)2

Normative and motivating reasons thus seem to come apart, both extensionally and intensionally. Nonetheless, a highly influential line of thought sees them as necessarily connected. Bernard Williams, whose 1979 article "Internal and External Reasons" (reprinted 1981) launched a vast contemporary literature on "internalism" and "externalism" about normative reasons for action, states the alleged necessary connection as follows:

It must be a mistake simply to separate explanatory and normative reasons. If it is true that A has a [normative] reason to Φ, then it must be possible that he should Φ for that reason; and if he does act for that reason, then that reason will be the explanation of his acting. [ . . . ] This is a basic connection. (1995a: 38–9)

Williams's "explanatory" reasons are motivating reasons: reasons for which A Φs.3 Williams claims that whenever a consideration, *p*, is a normative reason for A to Φ, it must be "possible" for *p* to also be A's motivating reason to Φ. Let's use "A Φs because *p*" to indicate that A Φs for the motivating reason that *p*. We can formulate Williams's "basic connection" as the following Explanatory Constraint, EC:

EC: The fact that *p* is a normative reason for A to Φ only if A can Φ because *p*.

EC calls for clarification. What is the modality of "can"? And what does it take for it to be the case that A can Φ because *p,* in the relevant sense of "can"? In order for A to Φ because *p*, A must at least believe that *p*; but what more is required? I clarify these issues in section 6.3. But abstract away from them for now. Williams sees EC as a "fundamental motivation" for what he calls "internalism" about normative reasons for action (1995a: 38–9). The following seems to be Williams's considered formulation of internalism, and of its negation, externalism:

The internalist view of [normative] reasons for action is that [ . . . ] A has a reason to Φ only if he could reach the conclusion to Φ by a sound deliberative route from the motivations he already has [that is, from his actual present subjective motivational set, S]. The externalist view is that this is not a necessary condition, and that it can be true of A that he has a [normative] reason to Φ even though A has no motivation in his [S] that could, either directly or by some extension through sound deliberation, lead him to Φ. (1995a: 35)4

**(p. 145)** Williams claims that internalism, thus understood, would explain or accommodate EC, whereas it's not clear how externalism could (1995: 39–40, 1981: 106–9). There is controversy over exactly how Williams's argument from EC to internalism goes, over whether it's Williams's only or best argument, as well as over how to interpret Williams's internalism itself.5 Further, the literature since Williams's "Internal and External Reasons" has spawned a variety of different versions of internalism and externalism. Some externalists reject EC, thus also rejecting the explanatory task that Williams claims both internalists and externalists face (e.g. McDowell 1995, Parfit 2011). Relatedly, some view EC, or something very close to it, as itself the heart of internalism (Setiya 2012: 4). On the other hand, even some contemporary views billed as "internalist" reject EC, while holding that an agent's normative reasons nonetheless depend on her existing motiva

tions in some way (Markovits 2011a, 2011b, 2014; cf. Smith 1995). The territory is further complicated by the fact that some philosophers view (their favored version of) internalism as a conceptual truth, implicit in the very concept of a normative reason for action (Williams 1981, 1995a; cf. Finlay 2009 on Williams); some as a metaphysical truth about the nature of the property of being a reason for action, a truth not entailed by the concept of a reason (Markovits 2014); and yet others as a first-order normative claim about what reasons there are or could be (Street 2017).6

Amidst this complexity of views, two things are now widely agreed upon. First, that EC itself is badly in need of defense, and can hardly stand as the "basic connection" that Williams thought it was. And second, that uniting all views about reasons that anyone has termed "internalist" is the thought that a necessary condition of *p*'s being a normative reason for A to Φ is that *some motivational fact about A* obtains (Finlay and Schroeder 2008/2012: §1.1).7 Only some such views are committed to EC—although of course, EC itself counts as a version of internalism on this broad classification. The broad uniting thesis that A's reasons depend on some motivational fact about A also leaves open stronger views, on which the relevant motivational fact is necessary *and sufficient* for there being a reason for A to Φ, or is what there being a reason for A to Φ *consists* in or is *grounded* in. Views of these stronger types are sometimes called "subjectivism" (see e.g. Sobel 2011, 2001; Parfit 2011: i, ch. 3).8 As is most common, I'll take the claim of necessary connection to be the heart of internalism.

**(p. 146)** Of course, the uniting thesis that A's reasons depend on some motivational fact about A is highly schematic, and very permissive as it stands. Limiting versions of it are trivially true. For example: *p* is a normative reason for A to Φ only if, were A to Φ because *p*, A would thereby act on a normative reason. Still, the uniting thesis captures, in the most general form, a view that admits of multiple different versions, some trivial and uninteresting, some obviously false, and—so internalists claim—some that are both non-trivial and true.9

Much of the literature on internalism can be read as an attempt to find the right connection between agents' reasons and their motivational profiles, with different versions of internalism construing the connection in different ways, and corresponding versions of externalism denying the claimed connections. In the space available here, I cannot hope to do justice to all the different views on which reasons depend on agents' motivations, let alone to all the different views on which they don't. This would be to attempt to address all the views about reasons that there are. Instead, I'll mostly focus on assessing the merits of views that accept EC—including the merits of EC itself—in light of the literature that Williams's article sparked. While this is my focus, examining the merits of views that accept EC should of course also inform assessment of views that reject EC.

Section 6.2 starts by explaining what's at stake with debates over internalism. Section 6.3 clarifies EC and Williams's internalism, and examines arguments from the former to the latter. The discussion identifies a broad premise in the background of both Williams's view and the views of many (though not all) of his opponents. This premise is the *Deliber*

*ative Constraint* that, roughly, normative reasons for action are premises in good practical deliberation, where such deliberation concludes in acting on one's (weightiest) reasons, in the way that those reasons support.10 Although one can accept this Constraint without accepting EC, I'll argue that the most plausible versions of internalism that accept EC must also accept the Deliberative Constraint—though with perhaps surprising consequences. Section 6.4 then investigates the merits of EC and the Deliberative Constraint. Each has seemed obvious to some and been attacked by others. I tentatively defend both against objections by Julia Markovits (2011a, 2014), David Sobel (2001), and Michael Smith (1995, 2009). I suggest that a deep source of the attraction of each thesis is the peculiar normativity of normative reasons: the fact that, when A has decisive reasons to Φ, A ought to Φ, in a sense that places a genuine and authoritative demand on A. While my discussion here is tentative, I suspect it reveals something importantly right about internalism.

## **(p. 147) 6.2 The Stakes**

Why worry about whether internalism is true? One set of concerns is extensional. On some versions of internalism, an agent's reasons for action depend on contingent features of her actual or possible motivational profile.11 For example, on Williams's internalism, the fact that a neighbor needs my help lifting a tree that fell on her is a reason for me to lift the tree only if lifting the tree is something I could be moved to do by some element already in my "subjective motivational set" S, either directly or indirectly through some extension via "sound deliberation." And according to Williams, this condition might fail to obtain if the contents of my S are sufficiently nasty (1981: 105). (More about this in 6.3.) Given my nastiness, the fact that my neighbor needs my help might be no reason for me to help. This consequence seems counterintuitive. Why think that my nasty motivational profile makes it so that there's no reason for me to help, rather than that my nastiness makes me unresponsive to reasons that there really are?12 Examples can be multiplied. For instance, deeply imprudent persons might lack reasons to avoid future agony (Parfit 2011: i: 73–82; cf. Sobel 2011). The worry is that any version of internalism on which an agent's reasons depend on her contingent motivations risks extensional inadequacy.

More ambitious forms of internalism try to resist such counterintuitive extensional consequences by arguing that deeply immoral or amoral, or deeply imprudent, motivational profiles are impossible (Korsgaard 1986, 1996, 2009; cf. Smith 2010, 2015); or that no matter how immoral or imprudent one's motivational starting points, they somehow entail pro-moral or prudent motivations when corrected for in the light of full or relevant information and relatively modest and uncontroversial standards of "procedural rationality," standards requiring "internal consistency and coherence" among one's attitudes (Markovits 2014, 2011b; cf. Smith 1995).13 Such strategies attempt to locate some motivational fact that holds necessarily for all agents and secures even moral or prudential reasons' connection to each agent's motivational profile. However, such claims about necessary motivations are notoriously hard to defend. Some have accordingly suggested that internalists might do better to explain away the seeming counterintuitiveness of denying

that certain reasons exist. Even if there are incorrigibly nasty agents who, because of their nastiness, lack certain reasons we wish they had, perhaps we can **(p. 148)** adequately criticize them and their actions in terms other than by appeal to alleged normative reasons (Manne 2014; cf. Williams 2001: 95–6). I return to this possibility briefly in the conclusion, in a skeptical vein.

These issues are very much live, and every attempt to index reasons to agents' motivations faces them in some form. It's worth noting that the potential counterintuitive extensional consequences of indexing reasons to agents' motivations don't depend on EC. Agents with deeply immoral or amoral motivational profiles might lack reasons to act morally well regardless of whether EC is true, if the motivational facts on which reasons supposedly depend are contingent—or, even if necessary, not necessarily pro-moral.14 Nonetheless, as I said, I'll mostly focus on versions of internalism, such as that of Williams, that accept EC.

Beyond concerns about extensional adequacy, another factor motivating interest in internalism is potential implications for broader debates about the nature of reasons. If A's reasons bear a necessary connection to some motivational fact about A, then any account of reasons must accommodate this fact. Moreover, unless the necessary connection is brute, there's some explanation for it; and a leading candidate explanation would be that the necessary connection obtains because of the nature of the property of being a reason for action. If what it is for *p* to be a reason for A to Φ just is for *p* to be a consideration that bears a suitable relation to A's motivational profile, then this would explain why A's reasons for action are necessarily connected to A's motivational profile. This could in turn provide an abductive argument for the relevant (reductive) view of what it is to be a reason—provided of course that alternative explanations are ruled out.15 For instance, suppose the necessary connection to be explained is EC. And suppose that agency is a capacity to act on any old consideration, normative reason or not. Then the nature of agency would explain why EC holds; no need to appeal to the nature of reasons. Such an explanation of EC by appeal to the nature of agency wouldn't constrain further theorizing about the nature of reasons.16

With the stakes thus clarified, why hold that an agent's reasons depend on her motivational profile? And what are the contours of the relevant necessary connection?

## **(p. 149) 6.3 EC, Williams's Internalism, and the Deliberative Constraint**

Suppose Williams is right that EC constrains any further theorizing about reasons. How best to understand the constraint that EC places? And how might it support more fleshedout internalist theses such as that of Williams? Recall both EC and Williams's statement of his internalist view from section 6.1:

EC: The fact that *p* is a normative reason for A to Φ only if A can Φ because *p*.

And Williams's statement of his internalism:

The internalist view of [normative] reasons for action is that [ . . . ] A has a reason to Φ only if he could reach the conclusion to Φ by a sound deliberative route from the motivations he already has [that is, from his actual present subjective motivational set, S]. The externalist view is that this is not a necessary condition, and that it can be true of A that he has a reason to Φ even though A has no motivation in his [S] that could, either directly or by some extension through sound deliberation, lead him to Φ. (1995a: 35)

Like EC, Williams's internalism speaks to the necessary, not sufficient, conditions of an agent's having a reason to Φ (1995a: 35–6, 2001: 91–2).17 And while Williams speaks generally of A's having a reason to Φ, rather than of a specific consideration *p*'s status as a reason, it's clear that the more specific question is Williams's ultimate concern (1981: 107). It's only because a specific consideration *p* is a reason for A to Φ that A "has a reason to Φ."18 Connectedly, recall Williams's claim that his internalism can explain EC, while externalism can't (1995a: 39–40, 1981: 106–9). Like EC, Williams's internalism had thus better be concerned not with A's being led to Φ for *any* old motivating reason, or for no reason at all, but in particular with A's being led to Φ on the basis of the consideration, *p*, that is also the normative reason in question.19 Finally, by "sound deliberation" starting from the agent's S, Williams seems to mean broadly instrumental deliberation that successfully seeks either causal or constitutive means to the co-satisfaction of the agent's contingent ends—including, for example, ways to carry out personal projects or to express commitments. Williams makes it clear, however, that he takes there to be "essential indeterminacy" in what counts as a "rational deliberative process"; and that his central claim **(p. 150)** about deliberation is just that its course is "controlled" by existing contingent elements in the agent's S (1981: 104–5, 110; 1995a: 36–8). We can formulate Williams's Internalism, W-INT, as follows:

W-INT: The fact that *p* is a normative reason for A to Φ only if A has some contingent motivation in her present actual subjective motivational set, S, that could lead A to Φ because *p via* broadly instrumental sound deliberation.

Three clarifications are in order at this stage. First, to successfully seek means to one's ends, one had better not rely on false beliefs in the course of one's deliberation. In Williams's example, an otherwise instrumentally rational agent deliberates unsoundly if his desire for a gin and tonic leads him to drink petrol because of a false belief about what's in the glass (1981: 102). (Such deliberation might be "valid," as we might put it; but because at least one of its factual premises is false, it's unsound.) Still, Williams is adamant that soundness in deliberation doesn't require correction of one's moral, prudential, or other normative or evaluative commitments (1995a: 36–7). Williamsian deliberation is sound if and only if its ordinary descriptive premises are true and it is (broadly) instrumentally cogent. It's because no more than these materials go into making deliberation sound on Williams's view that sufficiently nasty starting motivational sets can imply that agents lack reasons to be moral.

Second, while the "internalist view," as Williams states it in the quote above, formulates the necessary condition on A's reasons as "[A] could reach the conclusion to Φ by a sound deliberative route from the motivations he already has," the contrasting "externalist view" as stated denies what seems to be a more expansive disjunctive condition: that A has a motivation in his S that "could, either directly or by some extension through sound deliberation, lead him to Φ." Should we incorporate this more expansive condition into W-INT? Much of the literature on Williams's internalism omits mention of the disjunction, focusing only on what sound deliberation might lead one to do.20 We can justify this tendency by thinking of being led "directly" to Φ by some motivation in one's S as a limiting case of "deliberation" from S. When one "directly" carries out an element in one's S—for instance, one Φs as a result of a desire to Φ (1981: 104)—this is a limiting case of finding a "constitutive" solution: of finding that *this* would constitute Φ-ing. I doubt that this unduly distorts Williams's view; at any rate, Williams himself makes no hay about the disjunction. We can stick to the above formulation of W-INT.

The third clarification concerns the idea that sound deliberation concludes in A's Φ-ing on her normative reasons—in A's actually doing what *p* is a reason for her to do. Normative reasons are often *pro tanto*: they can be overweighed by other, contrary reasons for other, different actions. Surely sound deliberation wouldn't lead one to act on *all* of one's conflicting reasons in a situation, in the (conflicting) ways that they support. Partly because of this, Williams's view is often stated in terms of sound **(p. 151)** deliberation from one's S engendering a *motivation* to Φ, instead of leading one to Φ outright (see e.g. Manne 2014: 90, Markovits 2014: 27–30, Setiya 2012: 4). Indeed, Williams himself sometimes speaks in these terms (1981: 108–10). However, it also seems strange to expect sound deliberation to issue in multiple conflicting motivations whenever one has reasons for conflicting actions. It may be better to think of sound deliberation as registering one's reasons for conflicting actions in some other way, and as leading one to act on the reasons that are *decisive*. We needn't settle the details here. For the purposes of figuring out why we should think that anything like Williams's view is correct, we can adopt the simplifying assumption, which Williams himself sometimes adopts, that what's at issue in W-INT and EC are decisive reasons (Williams 2001: 90).21 So again, let's stick to the formulations above.

How, then, might we argue from EC to W-INT? Whether and how EC might support more fleshed-out versions of internalism such as Williams's depends in part on how we read the "can" in EC. We can distinguish between readings on which the "can" signals bare possibility (whether metaphysical or conceptual), and readings on which it attributes a present actual capacity to A. I start with the first, and go on to explain what I mean by the second as we go along.

Understood as making a bare possibility claim, the consequent of EC says that there's a possible world in which A Φs because *p*. As David Sobel (2001: 222–3) points out, this consequent can be made true by, say, the possibility of a far-fetched brain surgery that instills in A a (perhaps temporary) disposition to Φ because *p*, regardless of what A's actual S is like. If such brain surgery worlds must be possible regardless of how we vary "A,"

"*p*," and "Φ"—at least within the constraints of intelligibility—then this would suffice to make EC true, if the "can" in EC signals bare possibility.

However, it's difficult to see how EC read this way might support Williams's internalism. Clearly EC can't on its own furnish a good deductive argument for W-INT. Single-premise deductive arguments are always either invalid or, even if sound, objectionably questionbegging.22 We could try adding further premises—and not just further premises that together amount to an independent argument for W-INT, but premises that still allow EC to do substantive work in the argument. The most common interpretation of Williams reads him as giving something like the following argument—call it the "Classic Argument":

**(1)** The fact that *p* is a normative reason for A to Φ only if A can Φ because *p*. (EC) **(2)** A can Φ because *p* only if A has some contingent motivation in her present actual S that could lead A to Φ because *p* via broadly instrumental sound deliberation. (roughly Humean Theory of Motivation)

**(p. 152) (3)** So, the fact that *p* is a normative reason for A to Φ only if A has some contingent motivation in her present actual S that could lead A to Φ because *p* via broadly instrumental sound deliberation. (W-INT)

The theory of motivation stated in (2) is roughly Humean in the sense that it indexes the possibility of A's being moved to Φ to contingent motivations that A already has. In order for *p* to become A's motivating reason to Φ, *p* had better show Φ-ing to somehow engage a contingent motivational tendency that A already has. The theory is only "roughly" Humean, however, partly because of Williams's noted liberality concerning deliberation. Williams is likewise notably permissive about what A's "motivational set" S might include. In addition to pro-attitudes such as desires, it can include such things as "dispositions of evaluation, patterns of emotional reaction, personal loyalties, and various projects" (1981: 105). Williams even admits that *beliefs* to the effect that *p* is a reason for one to Φ might motivate one to Φ; it's just that, in order for such beliefs to motivate, one must already have a disposition to be moved by them (1981: 107).23 Read in these broad terms, there's some basis for attributing something like (2) to Williams, and for finding something like (2) plausible.

However, if the "can" in (1) is the "can" of bare possibility—so that the consequent of (1) says just that there's a possible world in which A Φs for the reason that *p*—then we must read the "can" in the antecedent of (2) in the same way, on pain of equivocating.24 And on this reading, (2) is simply false. For as we just noted, *regardless* of what's in A's actual S, there are possible brain surgery worlds in which A Φs for the reason that *p*. The bare possibility of A's Φ-ing for the reason that *p* after such far-fetched surgery is precisely *not* constrained by what's in A's actual S—unlike the contours of Williamsian "sound deliberation." Since (2) is false on the bare possibility reading of its antecedent, a charitable reading has to construe (2) in some other way. But (2) couldn't then help to mount a deductive argument to W-INT from EC, when EC is read in terms of the "can" of bare possibility. Indeed, it's hard to see what other premise could.

I return to the Classic Argument below, in considering other ways to interpret its premises. But recalling Williams's claim that internalism can *explain* EC while externalism can't (1995: 39–40; 1981: 106–9), we might read Williams as giving an *abductive* argument from EC to W-INT. Even if we read the "can" in EC as the "can" of bare possibility, W-INT is surely enough to at least entail EC. The trouble is, of course, that other views of reasons besides W-INT entail EC read this way too. For instance, the following view does:

VIRTUE AND REASONS: The fact that *p* is a reason for A to Φ (if and) only if, if A were fully virtuous, A would be moved to Φ because *p*. 25

**(p. 153)** Provided that A's being or becoming fully virtuous isn't outside the realm of bare possibility—and it's hard to see why it would be—then VIRTUE AND REASONS entails the EC of bare possibility too. Williams is clear that he wants to rule out views such as VIRTUE AND REASONS, in favor of W-INT. I return to this in 6.4. The present point is just that, since both VIRTUE AND REASONS and W-INT entail the EC of bare possibility, an abductive argument from EC read this way to W-INT won't work. If there's something to speak in favor of W-INT over other views such as VIRTUE AND REASONS, it must be something else.26

What alternative readings of EC are there, and do they fare better in supporting W-INT? An obvious possibility, noted by, for example, Sobel (2001: 223) and Finlay and Schroeder (2008/2012: §2.1.1), is to read the consequent of EC in stronger terms. Specifically, perhaps "can" in EC restricts the worlds in which A Φs because *p* to those worlds in which A is led to Φ because *p* through sound deliberation starting from an S just like her actual present S. But of course, as Finlay and Schroeder as well as Sobel point out, EC read this way would merely presuppose W-INT, or something close to it.

However, there's a further—and once we see it, a more plausible and natural—interpretation of EC as attributing to agents an actual present *capacity* to act on their normative reasons.27 As I'll explain, EC read this way doesn't presuppose W-INT, yet contributes to a fairly clear and promising, if still controversial, rationale for W-INT. And arguably this is how much of the literature immediately following Williams's "Internal and External Reasons" interprets EC, though usually without commenting on the contrast between this reading and the bare possibility reading above.

To see the difference between capacity claims and bare possibility claims, consider attributions of actual present capacity to swim, in the sense of a standing ability to swim. Such standing abilities are usually at issue when we say "I can swim" or "I can't swim." To have a capacity to swim in this sense, it's not enough that there's some faraway possible world in which I swim. Of course, neither do I need to be actually swimming. Even if I know how to swim and I'm in a swimmable body of water, I might fail to exercise my capacity to swim—perhaps willingly, or because of a cramp. (If a cramp prevents me from swimming, there's a sense in which I'm incapacitated, and "can't" swim, although I still have the general standing ability to swim.) What does seem true is this: if I have the actual present capacity to swim, there's a whole *range* of possible worlds, relatively close to the actual world, such that if I'm in swimmable bodies of water, and I sincerely try to

swim, then I swim. This leaves open that there's a difference in the rafts of subjunctives entailed by the capacity of someone who only barely knows how to swim and by the capacity of a highly skilled swimmer. It's also left open how to analyze capacities— **(p. 154)** whether, for instance, capacities are analyzable in terms of the rafts of subjunctives they entail, or whether there's some further fact about one that explains why the relevant subjunctives hold when one has a given capacity.28 Either way, if I have an actual present capacity, then *I'm now such that* the relevant raft of subjunctives is true of me; it's a further question what exactly my being like this consists in.29

These observations about capacities seem general. If they're correct, then likewise if A has the actual present capacity to Φ because *p*, then there's a range of relatively nearby worlds in which A Φs because *p*. Capacity claims entail a significant degree of subjunctive robustness. This again leaves open exactly how to analyze A's capacity to Φ because *p*; and exactly how to fill in the conditions in which A exercises or is likely to exercise that capacity. It's a motivational capacity, and its analysis is a task for theories of motivation. This suggests a way to read the Classic Argument in terms of motivational capacities and their analysis:

**(1C)** The fact that *p* is a normative reason for A to Φ only if A has the actual present capacity to Φ because *p*. (EC, capacity version)

**(2C)** A has the actual present capacity to Φ because *p* only if A has some contingent motivation in her present actual S that could lead A to Φ because *p* via broadly instrumental sound deliberation. (roughly Humean Theory of Motivation, capacity version)

**(3C)** So, the fact that *p* is a normative reason for A to Φ only if A has some contingent motivation in her present actual S that could lead A to Φ because *p* via broadly instrumental sound deliberation. (W-INT)

The consequent of (1C) presupposes no particular view about what having the relevant motivational capacity consists in or requires. (2C) states a theory of what A has to be like in order for the capacity attribution to be true of her. There's no equivocation here, and no question-begging—though of course there's room to resist either premise.

I discuss the plausibility of (1C) in section 6.4. For now, note that (2C) at least makes much more sense than the bare possibility version of the premise did. Theories of motivation are precisely theories of what it takes to have a motivational capacity to Φ—not merely (implausible) claims about what must be actually true of A now in order for there to be some faraway possible world in which A Φs. Moreover, recalling the liberality of Williams's views about deliberation and the contents of A's S, (2C) might start to look almost indisputable. Who would deny that what one has the present actual capacity to do depends on one's present actual dispositions and tendencies, broadly construed?30

**(p. 155)** Something like this capacity reading of the Classic Argument is arguably how much of the critical literature immediately following Williams's "Internal and External Reasons" reads him—though usually without explicitly mentioning the contrast between this reading and the bare possibility reading above.31 Christine Korsgaard (1986) accepts (1C) but rejects (2C), disagreeing with Williams about agents' motivational capacities.32 She doubts that practical reasoning is limited to broadly means/ends reasoning; and perhaps more importantly, given Williams's liberality about "deliberation," urges that some dispositions in agents' S might be non-contingent, necessary for agents as such, contrary to what (2C) assumes. In contrast, John McDowell (1995) accepts Williams's broad view of motivational capacities but rejects (1C). McDowell accepts that there's a weaker sense in which agents "can" come to be motivated by their normative reasons, through a non-deliberative process such as "conversion" to seeing things aright. (Cf. Sobel's brain surgery example.) What he doubts is that any transition to being moved by one's reasons must be an exercise of one's present actual motivational capacities, whatever their precise shape. It can instead be a transition to having virtue—and this is a "transition *to* deliberating correctly," not a transition effected *by* deliberating correctly (1995: §5). McDowell's view is, roughly, VIRTUE AND REASONS; and because he doubts that everyone already has the motivational capacities to act on the reasons that a virtuous person deliberating correctly would act on, he doubts (1C).

These disputes revolve largely around the issue of what "correctness" or "soundness" in deliberation amounts to; and how it's related to agents' capacities for deliberation, or acting for reasons, just as such. McDowell's virtuous agent's "correct" deliberation evidently isn't just Williamsian sound instrumental deliberation, as it involves correction for motivational starting points in the direction of virtue.33 Similar remarks apply, *mutatis mutandis*, for how Korsgaard's views about deliberation contrast with those of Williams.34 But notice that these issues about correct or sound deliberation only have a point, in the context of debates about reasons, if we assume that agents' reasons are constrained by the contours of sound deliberation, whatever exactly these contours **(p. 156)** look like. This points to a hidden premise that McDowell, Williams, and Korsgaard all agree on:

Deliberative Constraint: The fact that *p* is a normative reason for A to Φ (in circumstance C) only if there's a sound deliberative route (in C) such that, if A underwent it, she would thereby be led to Φ because *p*. 35

What Williams, Korsgaard, and McDowell disagree on is *what sound deliberation of the sort that constrains A's reasons looks like*, and so how to interpret the Deliberative Constraint; and *whether A must be capable of going through the sound deliberative routes to which her reasons correspond*. McDowellian sound deliberation is something that non-virtuous agents don't have the present actual capacity to go through—they can at most transition in some non-deliberative way *to* deliberating soundly—but this doesn't deter Mc-Dowell from indexing reasons to such sound deliberation, since he rejects (1C). In contrast, since Williams and Korsgaard accept both (1C) and the Constraint, they're committed to holding that A must be actually capable of going through the sound deliberation to which her reasons correspond. Notice, relatedly, that in order for W-INT to *explain* EC in its capacity version, W-INT had better itself be read as attributing to A the actual present capacity to go through the sound deliberative routes to which A's reasons correspond.36 The upshot is a perhaps surprising form of optimism about agents' capacities to deliberate soundly, given that they have a range of reasons for action. Of course, Korsgaard's op

timism goes deeper than Williams', since Korsgaard is also optimistic that sound deliberation never issues in immoral actions. Williams's optimism about agents' capacities for sound deliberation, and so for being moved by their reasons, is tempered by his pessimism about what the contours of sound deliberation and one's set of reasons can be like. Still, it's a good question what justifies the underlying optimism about agents' deliberative capacities.37

One might try to avoid the optimism by holding onto (1C) but rejecting the Constraint. But plausible versions of internalism that buy into (1C) must also buy into something like the Constraint. For surely agents often have reasons to do things that go beyond what they are already "directly" motivated to do. For instance, surely agents can have reason to Ψ as a means to Φ-ing, if they desire to Φ but don't already desire to Ψ. If we hold onto (1C), then we must think that agents' capacities to be moved by their **(p. 157)** reasons extend to a capacity to engage in some kind of deliberation that is more complex than the limiting case of being moved to Φ as a constitutive solution to satisfying the desire to Φ. And since it's implausible that agents' normative reasons are indexed to what they would do after deliberating *badly*, 38 or to the outcomes of deliberation just as such, it seems that anyone who holds (1C) should also hold a version of the Deliberative Constraint.

This makes urgent the evaluation of both EC and the Constraint. If there's good reason to reject the Constraint, this also puts pressure on us to reject EC. There might also be direct reasons to reject EC even if we accept some version of the Constraint, as McDowell does. Section 6.4 examines these issues. Before we proceed, three final remarks on Williams's argument and on nearby views.

First, the above observations yield a final revision to the Classic Argument for W-INT. One might have wondered at premise (2C)'s invocation of *sound* deliberation as part of a theory of agents' motivational capacities. The antecedent of (2C) and the consequent of (1C) concern A's motivating reasons. And it seems false that A has the capacity to act on a motivating reason, *p*, only if A could come to act on it through sound deliberation. Surely we often act on considerations after *unsound* deliberation—as when, in Williams's example, I'm led to drink a glass of petrol thanks to a false belief that the glass contains gin and tonic. Although my action is prompted in part by belief in a consideration, *p*, that is false, the action is still an exercise of my motivational capacity to act because *p*. If something in the vicinity of (2C) is true, it seems rather to be the following:

**(2C*)** A has the actual present capacity to Φ because *p* only if A has some contingent motivation in her S that could lead A to Φ because *p* via broadly instrumental deliberation, whether sound or unsound. (roughly Humean Theory of Motivation, revised capacity version)

And of course, (2C*) and (1C) alone won't supply a good deductive argument for (3C). However, if the Deliberative Constraint holds, we can supply the further premise needed. While an agent's capacity to act on motivating reasons doesn't on its own entail that, in exercising that capacity, the agent deliberates soundly rather than unsoundly, *normative* reasons are indexed to sound, not unsound, deliberation, as per the Constraint. Accord

ingly, if agents must be capable of acting on their normative reasons (as per EC), they must be capable not just of unsound but also of sound deliberation. Our conclusion is the strong version of W-INT mentioned above:

**(1C)** The fact that *p* is a normative reason for A to Φ only if A has the actual present capacity to Φ because *p*. (EC, capacity version)

**(2C*)** A has the actual present capacity to Φ because *p* only if A has some contingent motivation in her present actual S that could lead A to Φ because *p* via broadly **(p. 158)** instrumental deliberation, whether sound or unsound. (roughly Humean Theory of Motivation, revised capacity version)

**(2C**)** If *p* is not just A's motivating reason for Φ-ing but also a normative reason for A to Φ, then A's actual present capacity to Φ because *p* must be a capacity not just to deliberate from her S to Φ-ing because *p*, but to deliberate *soundly* from her S to Φing because *p*. This is because the Deliberative Constraint is true.

**(3C*)** So, the fact that *p* is a normative reason for A to Φ only if A has some contingent motivation in her present actual S that could lead A to Φ because *p* via broadly instrumental sound deliberation *that A has the capacity to go through*. (W-INT, revised)

The second of our final remarks is that if we abstract away from Williams's views about sound deliberation and motivational capacities, we can formulate a parallel argument for a more general "Rational Capacity/Reasons Internalism," RC-INT, that Williams shares with Korsgaard as against McDowell:

RC-INT: The fact that *p* is a normative reason for A to Φ only if A has the present actual capacity to deliberate soundly to the conclusion to Φ because *p*. 39

Third, there's a slightly different interpretation of Williams—one that sticks closer to the text of Williams's original (1979/1981) piece. On this interpretation, Williams's foremost concern is with the *meaning* of statements such as "*p* is a normative reason for A to Φ"; and W-INT is a view about their meaning. Williams is mystified as to what an alternative "external" interpretation of such statements could be, such that they might be true and explain EC. He considers the proposal that the content of external reason statements is that "if the agent rationally deliberated, then, *whatever motivations he originally had*, he would come to be motivated to Φ" (1981: 109, my emphasis). But as before, Williams can't see how rational deliberation—and so an exercise of an agent's motivational capacities—could lead an agent to Φ *except* by drawing in some way on the agent's existing motivations, broadly understood (p. 109). Thus external reasons statements understood in the proposed way are simply false, and couldn't explain EC (read as a capacity claim). And Williams can't see what *other* content external reason statements might have, if not the proposed content above. He asks, rhetorically: "*What* is it that one comes to believe when he comes to believe that there is reason for him to Φ, if it is not the proposition, or something that entails the proposition, that if he deliberated rationally, he would be motivated to act appropriately?" (1981: 109).

In the background here is, I think, a conviction that something like the Deliberative Constraint is a conceptual constraint on reasons. If EC (in the capacity version) is *also* a conceptual constraint on reasons, as Williams seems to think it is, then it's indeed hard **(p. 159)** to see what "external reason statements" could mean such that they could be true. For if we read "deliberation" and "A's S" as broadly as possible, then it's hard to deny that A's present capacity to Φ because *p* must draw on the dispositions and motives in her S, whether contingent or necessary.40 However, as, for example, Parfit (2011), Scanlon (2014), and Street (2017) point out, the meaning of statements such as "*p* is a normative reason for A to Φ," or the concept of a normative reason for action, might be primitive and unanalyzable. Indeed, this is nowadays a fairly common view. If it's right, then what A comes to believe when she comes to believe that *p* is a reason for her to Φ is just this: that *p* is a reason for her to Φ. The content of this belief might entail neither that A would Φ because *p* if she deliberated soundly, nor that A has the capacity to Φ because *p*. But this is fine *if* neither the Deliberative Constraint nor EC are conceptual truths; or, even if they are, they needn't be derived from the concept of a reason. The present interpretation of Williams thus can't escape the need to assess EC and the Deliberative Constraint. We can't simply assume that they constrain the very concept of a reason for action, any more than we can assume that they hold as metaphysical truths about reasons.

## **6.4 Why EC and the Deliberative Constraint?**

Start with the Deliberative Constraint. As we've seen, the Constraint can be interpreted compatibly with rejecting EC, and with accepting, say, VIRTUE AND REASONS, as Mc-Dowell does. For McDowell, sound deliberation is fully virtuous deliberation, the deliberation of the Aristotelian *phronimos* whose motivational profile is ethically good. Williams (1995b) objects, however, that less-than-virtuous people often have reasons to do things that are quite different from what fully virtuous people have reasons to do, and would do as a result of their fully virtuous deliberation. Our reasons can depend on our ethical imperfections. For Williams, this pushes us toward W-INT. But as we'll see, versions of Williams's complaint against McDowell can be raised against W-INT itself, and indeed against the very idea of the Deliberative Constraint.

Here is Williams against McDowell:

[I]n considering what he has reason to do, one thing that A should take into account, if he is grown up and has some sense, are the ways in which he relevantly fails to be a *phronimos*. Aristotle's *phronimos* (to stay with that model) was, for instance, supposed to display temperance, a moderate equilibrium of the passions which did not even require the emergency semi-virtue of self-control. But, if I know that I fall short of temperance and am unreliable with respect even to some kinds of **(p. 160)** self-control, I shall have good reason not to do some things that a temperate person could properly and safely do. The homiletic tradition, not only within Christianity, is full of sensible warnings against moral weight-lifting. (Williams 1995b, quoted from the 2012 reprint, p. 92)

The intemperate and un-self-controlled A may have good reason to avoid putting herself in the way of temptation; and this is a reason that a virtuous person wouldn't have, and wouldn't be moved by via virtuous deliberation, as her virtue would preclude her being too tempted. The Constraint as interpreted through the lens of VIRTUE AND REASONS appears extensionally inadequate because our reasons can depend on our ethical imperfections. And Williams points out that it won't help to try to build A's ethical imperfections into a statement of her circumstances, so that *p* is a reason for A to Φ in circumstance C *where C includes A's lack of virtue*—only if, if A were deliberating fully virtuously in C, she would Φ because *p*. For this move would commit the "conditional fallacy": the proposed necessary condition on reasons would put the fully virtuous person into circumstances that she couldn't be in—the circumstances of lacking virtue—compatibly with her supposed virtue.41 Williams concludes that we had better interpret the Constraint, not through the lens of VIRTUE AND REASONS, but instead in a way more closely aligned with the actual motivational set, warts and all, of the A whose reasons we're interested in. And this pushes us toward W-INT (or RC-INT).

However, as, for example, Sobel (2001) and Johnson (1999) note, a similar "conditional fallacy" complaint arises against Williams, and indeed seemingly against any interpretation of the Deliberative Constraint. After all, both index A's reasons to what A would do through an idealized deliberative procedure. For Williams, the idealization involves not full ethical virtue, but rather broadly instrumental rationality and the removal of false beliefs regarding ordinary matters of fact—at least, matters of fact relevant to what one should do in the situation. The worry is that A can have reasons to try to remove such false beliefs, and reasons to try to become more instrumentally rational; yet if A satisfied the right-hand side of W-INT, and so deliberated instrumentally soundly, she *wouldn't* be motivated to become more instrumentally rational or to remove relevant false beliefs. For she would *already* be perfectly instrumentally rational, and wouldn't have false beliefs infecting her deliberations. *Mutatis mutandis* for the Deliberative Constraint, whatever we mean by "sound deliberation." Whatever the idealization involved in satisfying the strictures of "soundness," it seems that actual A might have reasons to try to become such as to satisfy those strictures; and these are reasons that A wouldn't have, and wouldn't be moved by, *if she already satisfied those strictures*.

Such concerns have moved some authors to embrace an "Advice Model" of reasons, on which A's reasons to Φ are considerations that would move a hypothetical ideally rational counterpart of A, A+, who knows about actual A's imperfections and irrationalities, to **(p. 161)** *advise* A to Φ (Smith 1995, Sobel 2001). This contrasts with the "Example Model," on which the imperfect A's reasons to Φ are considerations that would move A+, A's ideally rational counterpart, to *do* Φ. The Advice Model is designed to avoid the conditional fallacy worry, and to make sure that A's reasons are appropriately tailored to her actual circumstance, including her imperfections. The ideal advisor A+ knows, for example, whether the actual A lacks virtue, and can tailor her advice to A so as to appropriately take account of this lack. And notice that the Advice Model gives up the Deliberative Constraint. For the Advice Model is compatible with holding that, although *p* is a reason for A to Φ, there may be *no* possible version of A who would be moved to *do* Φ because *p* via sound deliberation. By the same token, the Advice Model also gives up on EC: the imperfect A whose reasons are at issue may lack the capacity to be moved to Φ on the basis of her reasons to Φ.

However, I doubt the conditional fallacy worry forces us to reject the Deliberative Constraint and to adopt the Advice Model. We can interpret the Constraint so that it takes account of A's imperfections after all. For we can construe the Constraint as indexing A's reasons to *individual courses* of *the best sort of deliberation that A could go through compatibly with holding fixed all the facts of the circumstance, including A's imperfections, that are relevant to A's reasons*; not to what A would be moved to do if she were generally a perfect and well-informed deliberator (Setiya 2012: 15, 2014). Then A can still have reasons to become a better deliberator generally than she is in fact, compatibly with the Constraint. Likewise, A can have reasons to become better informed than she is. Of course, what A *couldn't* have reasons to do is to take steps to remove false beliefs, *B, where the only possible sound deliberative routes that could move A to take these steps would have to rely on A's already lacking B.* Likewise, A couldn't have reasons to try to acquire new beliefs, *B, if the only sound deliberative routes that could move A to try to acquire B would have to rely on her already having B*. But these strictures seem mostly easy to satisfy. If I have reason to learn more about the history of Syracuse, I can deliberate my way into taking steps to learning without having already acquired the new information that I'm seeking. Likewise, if I learn that my beliefs about the history of Syracuse are riddled with errors (perhaps I fail a test), then I can deliberate my way to taking steps to remove those errors, without having already removed them: I can study certain books, ask experts, and so on.

Similar remarks apply to explicitly EC-friendly interpretations of the Constraint. A's reasons to become a generally better deliberator can be indexed to individual courses of sound deliberation *that the actual A has the capacity to go through*, without implying that A is a highly skilled deliberator across the board. Indeed, having the capacity to go through a given sound deliberative route doesn't imply being highly skilled at going through even this very route, just as having the capacity to swim doesn't imply being a highly skilled swimmer. Likewise, A's reasons to rid herself of false beliefs can be indexed to individual courses of sound deliberation that the actual A has the capacity to go through—again assuming that these very courses of deliberation needn't rely on A's already lacking these false beliefs. *Mutatis mutandis* for A's reasons to try to acquire new information, as above.

**(p. 162)** These remarks may suffice to answer the conditional fallacy worry. But of course, they leave room for further objections to the Constraint and to EC. For instance, consider EC-friendly interpretations of the Constraint. The remarks above don't completely remove the prima facie surprising optimism of holding that A's having reasons to Φ implies that A has the capacity to soundly deliberate to the conclusion to Φ on the basis of these reasons. Certainly such optimism may seem particularly ill-founded if we suppose that part of the capacity to undergo the relevant sound deliberative routes is a capacity *to know, or to reliably come to believe*, the relevant reason-giving facts that sound delibera

tion takes into account. For instance, it may seem implausible that past people who weren't capable of knowing about the adverse health implications of tobacco had no reason to avoid smoking it.42 However, we should distinguish between (a) A's capacity, *given* belief in relevant reason-giving facts, to take them into account in deliberation and to be moved by them to do what they support, and (b) A's capacity to come to believe the relevant reason-giving facts. Correspondingly, we can read EC as attributing to A either a capacity to act on her reasons, *p, provided* she believes that *p*, or, more strongly, a capacity to come to believe *p*, as well. Those attracted to EC, and to EC-friendly versions of the Constraint, should carefully consider which of these capacities they regard as constraining reasons and why.43 I assume, in the remainder, that defenders of EC-friendly versions of the Constraint are mainly interested in capacity (a).

There are also further objections to the Constraint, whether it's interpreted in EC-friendly ways or not. Consider the following cases, which look to be counterexamples to the Constraint:

*James Bond:* The fact, *p*, that I have the deluded belief that I'm James Bond, is a reason for me to seek psychiatric help. But *p* is a fact, and so a reason, only if I don't believe it, and so only if I don't take it into account in deliberation. For were I to believe that I have the deluded belief that I'm James Bond—that is, were I to think of my belief that I'm James Bond *as* deluded—this would do away with my delusion. (paraphrased from Markovits 2014: 41, discussing a case from Johnson 2003: 575)

*Soldier in a Just War*: The fact, *p*, that the inhabitants of an enemy state share a common humanity, is a reason for a soldier to fight in a just war. But the soldier shouldn't think about this fact or be moved by it in the midst of fighting, lest she lose her nerve and fight (perhaps dangerously) ineffectively. So it seems that it wouldn't be part of sound deliberation to act on the basis of one's reasons in this case. (paraphrased from Markovits 2014: 47)

**(p. 163)** In *James Bond*, the fact, *p*, that is the supposed reason for me to seek help isn't a fact that I could believe consistently with its remaining a reason for me to seek help. For as soon as I come to believe that I have the deluded belief, I no longer have it; so I no longer have the supposed reason to seek help. If so, *p* is a reason for me to Φ only if I don't come to Φ for the reason that *p*, whether via sound or unsound deliberation; for whatever else Φ-ing for the reason that *p* involves, it at least involves believing that *p.* This case challenges both the Constraint and EC.44 *Soldier*, on the other hand, seems compatible with EC: perhaps the soldier has the capacity to act on her reasons in this case. But the thought is that it wouldn't be part of sound deliberation for her to do so; for it would be better for her to ignore the reason-giving fact, *p*, lest she become dangerously unnerved by considering it. *Soldier* challenges the Constraint, even if not EC. (Though recall that versions of internalism that are committed to EC must also, to be plausible, adopt the Constraint. So *Soldier* does challenge EC-friendly versions of internalism, even if not EC itself.)

However, I think we can respond to these cases compatibly with the Constraint; and moreover, there's some good positive reason for the Constraint. I'll also suggest, tentatively, that there may be some related good reason for EC, too. The remainder of this section fleshes out these thoughts, aiming thereby to pinpoint what I think is a deep source of internalism's attraction.

Consider *Soldier* first. What this case suggests, I think, is at best that the common humanity of the inhabitants should only be the soldier's motivating reason *to enter the war,* not her motivating reason *to perform this combat maneuver as opposed to that.* But that is to be expected, to the extent that facts about common humanity aren't relevant to deciding between combat maneuvers (at least within certain constraints), but are only relevant to deciding whether to fight in the war at all. On the other hand, there surely are cases in which the common humanity of the inhabitants *is* relevant to deciding what to do even in the heat of combat. In such cases, intuitively, this consideration *should* guide the soldier's decisions in some way even in the heat of combat, lest she risk brutalizing those inhabitants. More to the point, it seems that it *would* be an instance of sound deliberation for the soldier to take the common humanity into account where it's relevant to what she should do, and to be moved by considering this common humanity to do what it supports. The fact that the soldier might become unnerved—and so fail to undergo the relevant sound deliberative route—doesn't show that it wouldn't, after all, be an instance of sound deliberation for the soldier to be moved by considering the reason-giving facts to do what they support.45

What about *James Bond*? Suppose I can't both believe that I'm James Bond and believe that this belief is deluded, as the case claims.46 Then the fact that I have the deluded **(p. 164)** belief that I'm James Bond can't be a fact that I take into account in sound deliberation and thereby come to act on. Is this fact nonetheless a reason for me to seek psychiatric help? No doubt the fact that I have the deluded belief makes it in *some* sense a good idea for me to seek help. But it's unclear that we should interpret this intuitive reaction as an indication that the specific fact that I have this deluded belief is a reason for me to seek help. Perhaps my normative reason to seek help is the nearby more general fact that I have *a* deluded belief—where this general fact is one that I *can* take into account and act on. Or perhaps my deluded belief is *a reason why it would be a good thing*, or *good for me*, if I happened to find myself at a psychiatrist's office and somehow made the nature of my delusions evident. (Of course, the fact that my seeking help would be good for me might itself be a reason for me to seek help—and again, a reason I can act on.) Or the fact that I have this deluded belief might be a normative reason for *others* to seek help for me, or to urge me to go. I doubt that we can settle on the best interpretation of the case on purely pre-theoretical grounds. "Reason" is used in many ways; and our willingness to say that my deluded belief is a reason for me to seek help can be interpreted compatibly with the Constraint.47

The crucial question is whether there are good positive arguments for the Constraint, and so for interpreting our reactions to cases such as *James Bond* compatibly with it. I think there are. First, the Constraint taps into very intuitive general ideas about reasons. Faced

with an important decision, we usually think there's a point to trying to figure out the facts relevant to what we should do, and to trying to make our decisions in light of those facts. We try to find out what the reasons are pro and con our various options—or at least, pro and con the options most salient or important in the circumstance—and we try to deliberate well in their light. We certainly don't tend to think it better to make important decisions while seriously drunk or incapacitated, so that we have the best chance of deliberating badly or overlooking important facts. In short, we expect deliberating well in light of the reason-giving facts to help us to do what the reasons in the situation actually call for.48

This leaves room for outlier cases: even if reasons are generally to be taken into account in sound deliberation, and to be acted on as a result, there may be some *James Bond* reasons that are not like this. Still, if *James Bond* cases are confined to outlier status, this fact is itself significant. It means that there's a systematic connection between reasons and sound deliberation; it merely remains to find the right formulation of that connection. But more strongly, we should ask what acknowledging the existence of outlier *James Bond* reasons gets us. It's unclear that there's any intuitive cost to thinking, **(p. 165)** for example, that the reason in *James Bond* isn't the specific fact that I have the deluded belief that I'm James Bond, but rather some nearby fact that I *can* take account of and act on, as suggested above. If the intuitive cost of denying a general connection between reasons and good deliberation is quite high, we have some reason to prefer the Constraint, with its straightforward formulation of this connection, over admitting even such outlier cases.

There's a second, more abstract argument for the Constraint. Part of what seems important about reasons for action is their connection to *normative authority*. In particular, if A has decisive reasons to Φ, then A ought to Φ, in a sense of "ought" involving an authoritative demand on A to Φ. It's not just that A ought to Φ, say, *according to the rules of some club or game*, where the club or game rules don't themselves have authority on A: the "ought" connected to decisive reasons is a "robustly normative" or "authoritative" "ought" that somehow goes beyond the idea of "ought"-according-to-a-rule (cf. McPherson 2011). This is a common, if elusive, idea. It structures, for example, familiar debates about the authority of morality, which usually presuppose that morality's authority on us depends on our having reasons to be moral. It's also part of what makes various subjectivist and internalist theses about reasons look potentially troubling: recall the concern to make sure that we have reasons to act morally well. (And contrast the *lack* of concern to make sure that moral requirements are backed up by, say, requirements of local etiquette.) Part of the thought here seems to be that, without reasons to be moral—where such reasons could at least sometimes be decisive—we are free to take or leave morality as a guide to action. And it seems important that, were there decisive reasons to act morally well, such reasons could impose authoritative demands to so act. (After all, if they couldn't, then, even given such reasons, we would *still* be free to take or leave morality as a guide to action.)49 The second argument for the Constraint is that it's plausibly a condition of making sense of reasons as imposing authoritative demands.

To see why this is so, notice that there seems to be a link between authoritative demands and *reasonable expectations*. If the facts in a situation demand of A that she Φ, then there must be some possible condition, X, that A might be in in the situation, such that if A encounters the situation while in that condition, then we can reasonably expect of A that she will Φ. The relevant notion of reasonable expectations is partly predictive, partly normative. The predictive part is that, if A is in condition X in a situation, then it's predictable that A will end up doing precisely what the facts in the situation demand of her: condition X *well-equips* A to meet authoritative demands. Without some such possible condition X, the idea that A is under an authoritative demand to Φ seems to lapse. A might of course happen, by sheer accident, to do precisely Φ. And we might apply some positive evaluative predicate to such happy accidents. (Compare Railton 1988: 408–10 on "morally fortunate" actions.) But authoritative demands to Φ require **(p. 166)** that there be some possible condition that A could be in that well-equips A to meet those demands. If there's no such possible condition, then demanding of A that she Φ seems out of place.

Here's the normative aspect of the notion of reasonable expectations: if A is under an authoritative demand to Φ, then it must be reasonable to expect it *of* her that she Φs, and to criticize her if she fails to Φ—at least absent excusing conditions. (For instance, non-culpable ignorance of relevant non-normative facts plausibly excuses.) The condition X that well-equips A to meet authoritative demands must be of a type that makes sense of the appropriateness of such criticism. And roughly, it seems that A is criticizable only for what she does or fails to do under her own steam, via the exercise of her capacities for rational agency, in the sense of capacities for considering relevant information and acting in its light. We no more criticize A for involuntary non-rational twitches than we criticize rocks for their behavior—even though there are conditions of rocks that well-equip them for certain behaviors in certain circumstances. It seems, then, that X must be some deliberative condition of A's, in the following sense: a condition in which A acts on considerations, takes in information, and makes choices in its light.

In sum, then, X must be (a) a possible deliberative condition of A's that (b) well-equips A to do precisely what the facts in the circumstance demand of her. Without some such X, the facts in the circumstance can't demand anything of A. What deliberative condition X best satisfies (b)? The obvious answer is: the condition of deliberating soundly, where this involves taking account of the facts that impose the relevant demands, and being moved on their basis to do what they demand—whatever else it might involve. It's certainly harder to see why deliberating *badly* (e.g. drawing bizarre conclusions from relevant reasongiving facts), or taking into account only irrelevant facts that do nothing to support Φ-ing, would generally lead agents to Φ whenever the reasons so demand.

If this is right, then the Constraint is plausibly a condition of making sense of reasons as imposing authoritative demands. Reasons can impose demands on A only if there's a possible deliberative condition of A's that well-equips her to meet those demands; and the best candidate deliberative condition is the condition of deliberating soundly in light of the reason-giving facts.

These arguments aren't conclusive.50 But if there's anything to them, I think they point toward a deep source of the Constraint's attraction: the peculiar normative importance of reasons. It's because reasons can impose authoritative demands that there must be a sound deliberative route from considering the reason-giving facts to doing what the reasons demand. And it's because reasons are relevant to important decisions that we seek to make our decisions in their light. (With unimportant decisions, where little is at stake, we feel less pressure to seek good reasons for one option rather than another.) Do similar considerations recommend EC-friendly interpretations of the Constraint in particular? I close with a tentative suggestion that they might.

**(p. 167)** Return to the idea of reasonable expectations. The predictive aspect of this idea was that there must be some possible condition of A's that well-equips A to meet the authoritative demands that the reasons in her circumstance impose on her. Does it matter, for the presence of the demand, whether this well-equipping condition is one that A is in only in quite faraway possible worlds? Must the condition be within A's actual present motivational capacity? If it needn't be within A's actual present motivational capacity, then A's motivational situation with respect to her reasons may often be rather like the physical situation of someone who lacks the actual present capacity to jump over the Empire State Building, but is under a putative demand to do so (cf. Albritton 1985). Suppose I tell you that you ought to jump over the Empire State Building, because doing so would raise a million dollars for a good cause and you have nothing better to do right now. You would likely scoff. And you likely wouldn't think my claim any more reasonable once I observe that you "can" jump over the Empire State Building, in the sense that there's a faraway physically possible world in which a quantum event occurs that causes you to bound over the building in one huge leap. Nor would it help if I pointed to faraway worlds in which you gain superhuman powers that give you the capacity to perform the jump. Because you utterly lack the actual present capacity to perform the jump, the demand to do so seems wholly unreasonable. Importantly, it doesn't seem that your lack of physical capacity merely *excuses* you from criticism for your failure to abide by a demand that's still in force. It's not that you have decisive reasons to jump, and ought to jump, in the sense involving an authoritative demand on you to jump; rather, the putative demand itself seems to lapse.

Perhaps it's the same with motivational capacities. It's a familiar thought that degrees of maturity and health in our motivational capacities can affect what demands we are under. As we grow from childhood to adolescence and adulthood, our reasons and obligations change, and not just because our physical age or other non-motivational circumstances change. If one's capacities to respond motivationally to reason-giving facts in appropriate ways never mature, then many of the usual changes in reasons and obligations seem not to occur. In *some* way, then, our reasons and related obligations seem to be constrained by our motivational capacities. Whether this connection takes the form, specifically, of EC and EC-friendly versions of the Constraint—so that the existence of reasons for A to Φ depends on A's capacity to Φ for those very reasons—depends, I suggest, on how we settle various questions about the *normative* aspect of reasonable expectations. Which motivational incapacities merely excuse from otherwise reasonable criticism, and which ones

make the criticism, and the associated demand to Φ, lapse entirely? Perhaps some motivational incapacities neither excuse nor make the demand lapse. Being thoroughly vicious may involve such incapacities, leaving in place reasons to act morally well despite one's incapacity to act on them. And perhaps this is so because the relevant motivational incapacities are themselves ones that mature agents can be reasonably expected to have rid themselves of.

Whatever the case may be, I suggest we can best make progress on the merits of EC and EC-friendly versions of the Constraint via such questions about reasonable expectations. There's some plausibility to the idea that, *if* the deliberative condition that would wellequip A to meet the demands imposed by the reason-giving facts in her **(p. 168)** circumstance is *blamelessly* outside of A's current motivational reach—in the way that the physical condition in which I jump over the Empire State Building is blamelessly outside of my current physical capacity—then the supposed demand that I'm not well-equipped to meet lapses. The truth in the vicinity of EC may be more nuanced than the simple capacity version allows: the existence of reasons for A to Φ might be constrained by *some* of A's motivational capacities to act on the relevant reasons—those capacities she would be blameless to lack—and not others. Such versions of internalism await detailed development. Still, I suggest that the connections between reasons, authoritative demands, and reasonable expectations are a deep source of the attraction of the central internalist idea that reasons depend, in some important non-trivial way, on some motivational facts about the agents whose reasons they are. (For related discussion of reasons and abilities, see Streumer, Chapter 10 this volume, and Lord 2015.)

## **6.5 Conclusion**

I've been concerned with the prospects for versions of internalism that accept EC. I considered different interpretations of EC, traced the connections between EC and Williams's Internalism, and noted that each is committed to the Deliberative Constraint (6.3). I tentatively defended the Constraint, whether in EC-friendly versions or not, against recent objections by, for example, Sobel, Smith, and Markovits; and I suggested that a deep source of the attraction of the Constraint, and also perhaps of EC or some thesis close to EC, is the peculiar normative importance of reasons: that when A has decisive reasons to Φ, A ought to Φ, in a sense that places a genuine and authoritative demand on A.

I think it's the normative importance of reasons that also makes it hard to accept the suggestion that, even if morally nasty agents lack reasons to be moral, we might still be able to adequately criticize them in other terms. (For this suggestion, see Manne 2014, Williams 2001: 95–6.) If morally nasty agents have no reason to be moral, then it seems that moral requirements don't impose genuinely authoritative demands on those agents. And this is hard to accept. If the foregoing is right, however, then the very importance of normative reasons is also what makes it appealing to think of reasons in internalist terms —and so in terms that potentially leave the vicious without reasons to be moral after all.

The importance of normative reasons makes it urgent to find reasons to be moral, but is also part of what, in the end, problematizes the idea that we all have such reasons.51

## **References**

Albritton, R. (1985). "Freedom of the Will and Freedom of Action." *Proceedings and Addresses of the American Philosophical Association* 59(2): 239–51.

Bird, A. (1998). "Dispositions and Antidotes." *Philosophical Quarterly* 48(191): 227–34.

Dancy, J. (2004). *Ethics Without Principles*. Oxford: Oxford University Press.

Fara, M. (2005). "Dispositions and Habituals." *Noûs* 39(1): 43–92.

Fara, M. (2008). "Masked Abilities and Compatibilism." *Mind* 117(468): 843–65.

Finlay, S. (2009). "The Obscurity of Internal Reasons." *Philosophers' Imprint* 9(7): 1–22.

Finlay, S., and M. Schroeder (2008/2012). "Reasons for Action: Internal vs. External." In E. N. Zalta (ed.), *The Stanford Encyclopaedia of Philosophy*. <**http://plato.stanford.edu/ archives/win2012/entries/reasons-internal-external/**>.

Frankfurt, H. (1988). "Rationality and the Unthinkable." In *The Importance of What We Care About*, 177–90. Cambridge: Cambridge University Press.

Frankfurt, H. (1999). "Autonomy, Necessity, and Love." In *Necessity, Volition, and Love*, 129–41. Cambridge: Cambridge University Press

Johnson, R. (1999). "Internal Reasons and the Conditional Fallacy." *Philosophical Quarterly* 49: 53–71.

Johnson, R. (2003). "Internal Reasons: Reply to Brady, van Roojen and Gert." *Philosophical Quarterly* 53(213): 573–80.

Korsgaard, C. M. (1986). "Skepticism about Practical Reason." *Journal of Philosophy* 83: 5–25.

Korsgaard, C. M. (1996). *The Sources of Normativity*. Cambridge: Cambridge University Press.

Korsgaard, C. M. (2009). *Self-Constitution: Agency, Identity, and Integrity*. Oxford: Oxford University Press.

Lord, E. (2015). "Acting for the Right Reasons: Abilities, and Obligation." In R. Shafer-Landau (ed.), *Oxford Studies in Metaethics*, vol. 10, 26–52. Oxford: Oxford University Press.

Manne, K. (2014). "Internalism about Reasons: Sad but True?" *Philosophical Studies* 167: 89–117.

Markovits, J. (2011a). "Internal Reasons and the Motivating Intuition." In M. Brady (ed.), *New Waves in Metaethics*, 141–65. London: Palgrave Macmillan.

Markovits, J. (2011b). "Why Be an Internalist About Reasons?" In R. S. Landau (ed.), *Oxford Studies in Metaethics*, vol. 6, 255–79. Oxford: Oxford University Press.

Markovits, J. (2014). *Moral Reason*. Oxford: Oxford University Press.

McDowell, J. (1995). "Might There Be External Reasons?" In J. E. J. Altham and R. Harrison (eds), *World, Mind, and Ethics*, 68–85. Cambridge: Cambridge University Press.

McPherson, T. (2011). "Against Quietist Normative Realism." *Philosophical Studies* 154: 223–40.

Molnar, G. (2003). *Powers: A Study in Metaphysics*. Oxford: Oxford University Press.

Paakkunainen, H. (2017). "Can There Be Government House Reasons for Action?" *Journal of Ethics and Social Philosophy* 12 (1): 56-93.

Parfit, D. (2011). *On What Matters*. Oxford: Oxford University Press.

Pettit, P., and M. Smith (1990). "Backgrounding Desire." *Philosophical Review* 99(4): 565– 92.

Railton, P. (1988). "How Thinking about Character and Utilitarianism Might Lead to Rethinking the Character of Utilitarianism." *Midwest Studies in Philosophy* 13: 398–416.

Scanlon, T. (1998). *What We Owe to Each Other*. Cambridge, Mass.: Harvard University Press.

Scanlon, T. (2014). *Being Realistic about Reasons*. Oxford: Oxford University Press.

Schroeder, M. (2007). *Slaves of the Passions*. Oxford: Oxford University Press.

Schroeder, M. (2009). "Having Reasons." *Philosophical Studies* 139: 57–71.

Setiya, K. (2007). *Reasons without Rationalism*. Princeton, NJ: Princeton University Press.

**(p. 170)** Setiya, K. (2009). "Reply to Bratman and Smith." *Analysis* 69(3): 531–40.

Setiya, K. (2012). "Internal Reasons." In K. Setiya and H. Paakkunainen (eds), *Internal Reasons: Contemporary Readings*, 1–3. Cambridge, Mass.: MIT Press.

Setiya, K. (2014). "What Is a Reason to Act?" *Philosophical Studies* 167: 221–35.

Smith, M. (1987). "The Humean Theory of Motivation." *Mind* 96(381): 36–61.

Smith, M. (1994). *The Moral Problem*. Oxford: Blackwell.

Smith, M. (1995). "Internal Reasons." *Philosophy and Phenomenological Research* 55(1): 109–31.

Smith, M. (2003). "Rational Capacities, or: How to Distinguish Recklessness, Weakness, and Compulsion." In S. Stroud and C. Tappolet (eds), *Weakness of Will and Practical Irrationality*, 17–38. Oxford: Clarendon Press.

Smith, M. (2009). "Reasons With Rationalism After All." *Analysis* 69(3): 521–30.

Smith, M. (2010). "Beyond the Error Theory." In R. Joyce and S. Kirchin (eds), *A World Without Values*, 119–40. Dordrecht: Springer.

Smith, M. (2015). "The Magic of Constitutivism." *American Philosophical Quarterly* 52: 187–200.Sobel, D. (1999). "Do the Desires of Rational Agents Converge?" *Analysis* 59(3): 137–47.

Sobel, D. (2001). "Explanation, Internalism, and Reasons for Action." *Social Philosophy and Policy* 18: 218–35.

Sobel, D. (2009). Review of Mark Schroeder's *Slaves of the Passions*. *Notre Dame Philosophical Reviews*. <**http://ndpr.nd.edu/news/slaves-of-the-passions/**>.

Sobel, D. (2011). "Parfit's Case against Subjectivism." In R. Shafer-Landau (ed.), *Oxford Studies in Metaethics*, vol. 6, 52–78. Oxford: Oxford University Press.

Street, S. (2009). "In Defense of Future Tuesday Indifference: Ideally Coherent Eccentrics and the Contingency of What Matters." *Philosophical Issues* 19(1): 273–98.

Street, S. (2017). "Nothing 'Really' Matters, But That's Not What Matters." In P. Singer (ed.), *Does Anything Really Matter? Parfit on Objectivity*, ch. 6. Oxford: Oxford University Press.

Tenenbaum, S. (ed.) (2010). *Desire, Practical Reason, and the Good*. Oxford: Oxford University Press.

Velleman, D. (2009). *How We Get Along*. Cambridge: Cambridge University Press.

Williams, B. (1979). "Internal and External Reasons." Repr. in *Moral Luck*, 101–13 (Cambridge: Cambridge University Press, 1981).

Williams, B. (1981). *Moral Luck*. Cambridge: Cambridge University Press.

Williams, B. (1995a). "Internal Reasons and the Obscurity of Blame." In *Making Sense of Humanity and Other Philosophical Papers*, 35–45. Cambridge: Cambridge University Press.

Williams, B. (1995b). "Internal and External Reasons (Reply to McDowell)." In J. E. J. Altham and R. Harrison (eds), *World, Mind, and Ethics*. Cambridge: Cambridge University Press. Repr. in K. Setiya and H. Paakkunainen (eds), *Internal Reasons: Contemporary Readings* (Cambridge, Mass.: MIT Press, 2012).

Williams, B. (2001). "Internal and External Reasons, with Postscript." In E. Millgram (ed.), *Varieties of Practical Reasoning*, 77–98. Cambridge, Mass.: MIT Press.

## **Notes:**

[^1]: These tendencies of Axl's are "background" factors that explain why the consideration that his visit would aggravate Bea figures in the "foreground" of Axl's practical thought, as the consideration on which he acts. I'll restrict the term "motivating reasons" for such foreground considerations, the considerations on which, or reasons for which, agents act. The background factors explaining why certain considerations figure in the foreground are also sometimes called "motivating reasons": see e.g. Pettit and Smith (1990).

[^2]: It's a further question whether agents can act on a consideration without *conceiving* of it as justifying their action. The thesis that they can't is one version of the thesis that action must take place "under the guise of the good." For discussion, see Tenenbaum (2010) and Setiya (2007).

[^3]: Though Williams (1981: 102) is also clear that sometimes it's appropriate to explain actions in other ways than by appeal to motivating reasons—e.g. by appeal to neurological facts.

[^4]: I follow Williams in using the unadorned "reasons" to refer to normative reasons. For motivating reasons, I use either "motivating reasons," the "reasons for which," or "considerations on which" an agent acts; or "because *p*."

[^5]: I comment on some of this controversy, and give references, in 6.3.

[^6]: Although Street's own view is that A's reasons are a function of A's *attitudes* more broadly, not that they depend on A's motivations in particular.

[^7]: There are other views called "internalist" that aren't about the conditions of *p*'s being a normative reason. On *normative judgment internalism*, normative judgments about reasons or oughts bear a necessary connection to motivation. On *morality/reasons internalism*, moral requirements necessarily provide reasons for action for every agent. (This is often called "moral rationalism.") Our topic, sometimes called "existence internalism" about reasons, is distinct from each of these.

[^8]: There isn't total terminological agreement here. Schroeder (2007) and Markovits (2014) both defend versions of a view on which what it is for *p* to be a reason for A to Φ is for *p* to bear a certain relation to A's existing motivations; but Schroeder calls his view "hypotheticalism," while Markovits calls her view "internalism." Sobel (2001) reserves the title "internalism" for views that accept EC (cf. Setiya 2012), and "subjectivism" for views that reject EC but nonetheless link an agent's reasons to her motivations (contrary to e.g. Markovits 2014, whose "internalism" rejects EC). In the terminology of Finlay and Schroeder (2008/2012: §1.1.1–2), subjectivism in Sobel's sense is a "State View," not a "Motivation View"; and in its typical developments, subjectivism is a "Counterfactual

State" view, holding that an agent's reasons depend on, or are a function of, the motivational states she would be in in certain idealized conditions.

[^9]: Cf. Finlay and Schroeder's discussion at (2008/2012: §1.1.2).

[^10]: I take the label "Deliberative Constraint" from Schroeder (2007: 26, 33).

[^11]: Among contingent features of individual agents' motivational profiles, I include motivational facts that are necessary for a given individual agent—Frankfurtian "volitional necessities" (Frankfurt 1988, 1999)—though contingent for agents as such.

[^12]: There's also a further worry: that we cannot adequately analyze my nastiness itself except in terms of unresponsiveness to reasons that there are (Scanlon 1998: 367).

[^13]: One nearby position is that agents who lack moral reasons are possible but exceedingly rare (Street 2009); another, that everyone has reasons to be moral because everyone has *some* desires that morally good actions would do *something* to promote, even if the relevant desires aren't themselves intuitively pro-moral (Schroeder 2007).

[^14]: For Velleman (2009), reasons depend on a motive that every agent necessarily has, but this motive needn't lead to pro-moral behavior.

[^15]: By a "reductive" view of what it is to be a reason, I mean a view that explains how *p*'s having the property of being a reason for action is a function of other, metaphysically less mysterious facts and properties. If what it is for *p* to be a reason for A to Φ just is for *p* to bear relation R to A's motivational profile, then facts about reasons are only as mysterious as are facts about R and A's motivational profile. See e.g. Schroeder (2007) and Markovits (2014) for such reductive views; although Markovits is self-consciously not reductive about normativity more broadly, because on her account, the relation R is itself irreducibly normative (2014: 10–11).

[^16]: One complication is whether EC describes a conceptually or a metaphysically necessary connection. If conceptual, could the nature of agency, or of reasons, explain EC? Maybe not: but the concept of reasons, or of agency, might.

[^17]: Williams (1981) speaks both of necessary and sufficient conditions, but even there the arguments are aimed at establishing the necessary condition.

[^18]: Here and throughout, I elide further distinctions between there being a reason for A to Φ and A's having or possessing this reason (see Schroeder 2009)—as Williams generally does (see e.g. 1981: 101). By "A has a reason to Φ," I mean that there is a reason for A to Φ.

[^19]: Cf. Sobel (2001: 221), though on EC, not W-INT.

[^20]: See e.g. Sobel (2001), Setiya (2012), Markovits (2014) and Manne (2014).

[^21]: Manne (2014: 90, n. 2) nicely notes this simplifying assumption by Williams. Though contrast Williams (1981: 104).

[^22]: Sobel (2001: 222–3) seems to read Williams as attempting to mount a one-premise deductive argument from EC to W-INT; and complains that depending on how we read EC, the argument either begs the question or doesn't entail W-INT. I think there are more charitable ways to read Williams.

[^23]: I return to this at the end of 6.3. For a now-classic defense of the "Humean Theory of Motivation," in a somewhat less liberal version than that of Williams, see Smith (1987, 1994: ch. 4). I comment on contrasting "Kantian" views briefly below. A terminological note: Williams sometimes calls all elements in A's S "desires," but makes it clear that he means this term to cover the broad possibilities he describes (1981: 105).

[^24]: Cf. Finlay and Schroeder's discussion at (2008/2012: §2.1.1).

[^25]: McDowell's (1995) response to Williams, which I comment on below, proposes something like this view.

[^26]: This holds regardless of whether we read EC, W-INT, and VIRTUE AND REASONS as making claims about conceptually or just metaphysically necessary conditions on reasons.

[^27]: Or at least a capacity that the agent has at the same time as she has the reason. If the reason is one that the agent will have in the future, then the relevant capacity would likewise be a future actual capacity. For example, it can be that the future adult that will develop from a toddler will have a normative reason to park the car, even if the toddler now lacks the capacity to act on such a reason. For simplicity, I restrict focus to present reasons and capacities in the text.

[^28]: For a subjunctive analysis of rational capacities, see Smith (2003). For problems with subjunctive analyses of capacities generally, see Bird (1998), Fara (2005; cf. 2008), and Molnar (2003: ch. 4). Much of the literature on internalism formulates it, and EC, in subjunctive terms (see e.g. Finlay and Schroeder 2008/2012). Setiya (2012: 8–9) is an exception.

[^29]: Thanks to Kim Frost for helpful discussion of capacities—although of course all mistakes are mine.

[^30]: In the literature on the metaphysics of capacities or powers, they are not generally clearly distinguished from dispositions. See e.g. Molnar (2003) and Fara (2008).

[^31]: It's noteworthy that e.g. Finlay's more recent (2009) article, which contains an otherwise admirable and clear survey of ways to interpret the Classic Argument, makes no mention of the possibility of a "capacity" reading of its premises.

[^32]: The interpretation of Korsgaard (1986) is complicated by the fact that she often formulates the "Internalism Requirement" (her version of EC), which she accepts, as the claim that reasons must be capable of motivating "rational" agents; and "rational" for her sometimes seems to mean *fully* rational, in a sense ruling out all irrationalities. But Korsgaard also thinks that we can infer from facts about what "full" rationality is like to facts about what agents as such are capable of. I return to the underlying optimism about agents' capacities below; it's a major theme in Setiya (2012).

[^33]: The contrast here is sometimes put as being between "procedural" and "substantive" conceptions of rationality, with Williams falling on the "procedural" side and McDowell on the "substantive" side (see e.g. Finlay 2009: 4 and Markovits 2014: 6, 10–11, *et passim*). I bypass this terminology here, as I think it can wrongly suggest an overly neat stock of options.

[^34]: Although Korsgaard's view also differs from McDowell's in potentially important ways. For Korsgaard (2009), deliberation proceeds *in accord with moral principles*; not just from moral "starting points" as inputs into broadly instrumental deliberation.

[^35]: As for Williams, "sound deliberation" precludes reliance on false factual beliefs, whatever else it precludes. Recall that, throughout, I'm implicitly restricting the discussion to *decisive* reasons (cf. the discussion at the beginning of 6.3).

[^36]: In contrast, VIRTUE AND REASONS wouldn't explain EC, at least if McDowell is right that an agent's present actual capacities for deliberation needn't include the capacity to deliberate virtuously.

[^37]: Though recall that having an actual present capacity to X is compatible with (at least contingent) impediments to doing X (the cramp in the swimming case). Presumably having the actual present capacity to go through a sound deliberative route is likewise compatible with contingent impediments to exercising this capacity on an occasion. Cf. Williams' remarks on deliberation and what's "possible" for an agent in his (1995b) reply to McDowell.

[^38]: Cf. Sobel (2001: 223).

[^39]: Cf. Williams' remark (1995b: n. 2) that it "best preserves the point of the internalism/ externalism distinction to see [Korsgaard's view] as a limiting case of internalism."

[^40]: Finlay's (2009) interpretation of Williams is in some ways similar to this one. But for Finlay, Williamsian deliberation seeks first-personal explanations of action: explanations, for oneself, of why one would Φ if one deliberated well.

[^41]: Williams (2012: 92–3). Cf. Johnson (1999).

[^42]: Thanks to David Sobel for this example, and for pressing me to address capacities for knowledge of reason-giving facts.

[^43]: See Lord (2015) for relevant discussion; cf. Sepielli, Ch. 33 this volume, on "objective" (in the sense of fact-relative) reasons and "subjective" (in the sense of relative to the agent's epistemic predicament) reasons.

[^44]: For similar cases, see Smith (2009: 523), Schroeder (2007: 33), and Sobel (2001: 231, 2009).

[^45]: W-INT—even in its capacity version—is likewise compatible with thinking that agents might fail, perhaps through becoming unnerved, to undergo the sound deliberative routes to which their reasons correspond.

[^46]: We might doubt this: compare having deep-set prejudicial beliefs that manifest themselves in actions and reactions even while one explicitly and consciously believes those prejudicial beliefs to be false. But I set aside this concern here.

[^47]: Cf. Setiya (2009: 538) on Smith (2009: 523). Markovits also suggests further cases, some patterned after the ones I've considered, and some that involve "state-given" reasons to have an *intention* (e.g. to retaliate against nuclear attacks in kind): reasons that stem not from what would be the case if one acted on the intention, but rather from the good (e.g. deterrent) *consequences of merely having the intention* (and having the intention be known). I ignore cases of this latter type, since our concern is with reasons for action; and reasons for intention that are also reasons to perform the action intended aren't "state-given" in the above sense.

[^48]: Cf. Schroeder (2007: 132).

[^49]: This leaves it open that *some* reasons, even if not outweighed by contrary reasons, merely "entice" or recommend (Dancy 2004: 21). Still, if even the strongest reasons to abide by moral requirements left it entirely normatively optional whether to do so—as they would, if they merely entice or recommend without demanding—this wouldn't be much of a vindication of morality's authority.

[^50]: I develop the above arguments for the Deliberative Constraint in more detail in Paakkunainen 2017.

[^51]: I'm grateful to Daniel Star, David Sobel, Alex King, Kim Frost, and John Brunero for extremely helpful feedback on earlier drafts.

# 7. Motivating Reasons and Normative Reasons 

*David McNaughton and Piers Rawling*

### **Abstract and Keywords**

Reasons for action are traditionally divided into "motivating reasons," which explain why someone did something, and "normative reasons," which concern why she should (or should not) have done it. We explore various positions concerning both types of reason, and the relations between them. We discuss Davidson's causal account of action, reasons internalism and externalism, constructivism, motivational internalism and externalism, and practical normative realism (PNR)—the view that there are truths concerning what you have reason to do (this is opposed by error theorists and noncognitivists, whose views we also briefly address). In our account of PNR, we distinguish between what you ought to do and what you have most reason to do, by appealing to the idea of reasonable credences. And we include two appendices, one resisting Lewis's argument to the effect that advocates of PNR must reject motivational internalism, the other responding to a concern about future contingents.

Keywords: action, causal, constructivism, credence, externalism, internalism, motivation, normative, ought, reasons

*Reasons for action, or practical reasons, may be seen as falling into two categories, the reasons that explain why someone did something ("motivating reasons"1 ), and the reasons why she should (or should not) have done it ("normative reasons"). In what follows we shall explore the pros and cons of various positions concerning both types of reasons, and the relations between them.

## **7.1 Motivating Reasons**

Perhaps the best-known contemporary view of motivating reasons is that expounded by Donald Davidson (1980a; see also Wiland, Chapter 8 this volume). In explaining an action, Davidson's thought is that we cite the psychological states (or attitudes) that both caused and rationalize it. In simple idealized cases, the states are a desire and a belief—these constitute what Davidson dubs the "primary reason" for an action. In giving a potential explanation of the politician's vote for the bill, we might cite her belief that if she didn't,

she wouldn't get re-elected, and her desire to get re-elected; or we might cite her belief that passage of the bill would help the poor, and her desire to accomplish this. Both belief–desire pairs rationalize her action—it makes sense in light of either pair, and they each portray it in a favorable light from her point of view. And it is possible that she acted for both reasons. But what makes it the case that she acted for one or the other or **(p. 172)** both? Davidson claims that answering this question requires knowing the causal story—the states that moved the politician to vote for the bill are the ones that caused her to do so. (Note that we draw a distinction throughout this chapter between an agent's being moved to act and her being motivated to act: movement implies motivation, but not vice versa.) One of Davidson's challenges to non-causal views, then, is to distinguish, among mental states that rationalize an action, between those that played a role in moving the agent to act and those that didn't. Davidson's account, however, is not without its own challenges. We shall not canvass them all, but here is a sampling.

One objection rests on Hume's (1978 [1739]) claim that there can be no necessary connections between causes and their (purported) effects. The thought is that the rationalization relation between actions and the relevant belief–desire pairs is just such a necessary connection, or close to it, and hence belief–desire pairs cannot cause the actions that they rationalize. Davidson's response to this is to point out that if this connection is necessary, it is a connection between events and states under certain descriptions, and this is entirely innocent (1980c: 14). "The causes of the Great Fire of London caused the Great Fire of London" is certainly true, yet it expresses a connection between cause and effect that is a least as "necessary" as any apparent in "her belief that Fred was thirsty and her desire to relieve his thirst caused her to fetch him a glass of water."

Another objection rests on combining the following:

- **(1)** Causal claims entail laws (see e.g. Hume (1978 [1739])).
- **(2)** There are no laws linking belief–desire pairs and acts performed in their light.

Adopting this pair apparently entails the rejection of Davidson's view that belief–desire pairs can cause acts. However, claims Davidson, (2) only holds at our everyday level of description (as in the final example of the previous paragraph). There are, Davidson argues, relevant laws at the physical level: any particular belief–desire pair, and the action it caused, will have *physical* descriptions under which their causal interaction is covered by a law (see Davidson 1980b; 1980c: 15–17). One difficulty here, however, is that of accounting for the relevance of the propositional contents of the belief–desire pair to the action that, on Davidson's account, they cause (see Wilson and Shpall 2016 for discussion).

A third objection seeks to undercut Davidson's account by claiming that *all* the belief–desire pairs that rationalized an act played a causal role in its performance. As we noted, Davidson challenges those who deny his causal view to give an alternative account that distinguishes between psychological states that merely rationalize an action and those that not only rationalize but for which the agent actually acted. But if the states that ra

tionalize always have a desire-like component, are they not all involved in causing the act in question—isn't it criterial of desire-like states to be "pushy"?

One line of response (see Wiland, Chapter 8 this volume) is to note cases in which an agent has different motivating reasons to perform one and the same act, but that cannot be jointly satisfied. I might have a standing desire to surf in Hawaii, say, as well as attend a conference there, but cannot do both on one trip. So, given that I'm going **(p. 173)** to the conference, I do not go to Hawaii for the surfing on this occasion. My surfing desire does not disappear, however; rather, it just fails to play any part in moving me to go to Hawaii on this conference trip. Another response is to point out that plenty of motivating reasons don't result in action (I have motivating reasons that move me to sit here and type, but I also have motivating reasons to do many other things), so why suppose that all the motivating reasons for an act that is actually performed are part of its cause? The objection rests, it seems, on analogizing motivating reasons to forces, with acts being the product of their resolution. However, perhaps this analogy can be rejected without abandoning a causal account of action.

Another difficulty for the Davidsonian view is posed by "deviant causal chains." Belief–desire pairs can cause behavior in "deviant" ways, and in such cases the pairs in question do not constitute reasons in Davidson's sense—as in the following example of his (1980c: 79). A climber wants to rid himself of his partner, and believes he can do this by loosening his hold on the rope. These thoughts so disconcert him that they cause him to do so. But, since this is unintentional, the belief–desire pair in question is not the reason for the slackening of his grip.

What conditions must we add to the causal criterion, then, in order to guarantee that a belief–desire pair is the reason for which the agent acted? We know of no satisfactory answer (see Wilson and Shpall 2016 for discussion). Perhaps we should rest content with the thought that at least Davidson provides a necessary condition for a belief–desire pair to be the reason for which the agent acted, just not a sufficient one. However, one might see the case of the disconcerted climber as raising the issue of whether Davidson's account accords an appropriate role to the agent, as opposed to merely her beliefs and desires. The case is deviant, one might argue, because the climber was not appropriately engaged. But Davidson seems to lack the resources in his account to address this.

Another issue, discussed in sections 7.4 and 7.6, is that of whether your belief that you have a reason to A, or ought to A, can suffice as motivation for you to A. Can Davidson's view accommodate this possibility? Interestingly, he maintains that "all [desires] may be expressed by evaluative judgements" (1980c: 86), such as your judgment that you ought to A. If these judgments also express beliefs, and if these beliefs can, by themselves, give rise to, or constitute, the relevant desires, then it would appear that Davidson's account is consistent with the view that beliefs can suffice for motivation. It is crucial to note, however, that the belief and desire expressed by the evaluative judgment have different contents—"I ought to improve the taste of the stew" (Davidson 1980c: 86) would, on this

interpretation of matters, express the agent's desire that he improve the taste of the stew, and his belief that he ought to do so.

Finally, Davidson's view is a form of psychologism about motivating reasons—the motivating reasons are psychological states or attitudes. But there are alternative views according to which motivating reasons are not, or are not all, psychological states. Eric Wiland discusses such views in detail in Chapter 8 in this volume, so we shall be brief. If motivating reasons are not psychological states, what are they? One view is that they are facts about the world. If you are thirsty, then what motivates you to walk across the room, it might be said, is the fact that there is a glass of water on the table, rather than **(p. 174)** your desire for a drink coupled with the relevant belief. The standard difficulty faced by views of this sort, however, is the problem of false belief. Suppose the belief–desire pair is present, but the belief is false. There is no glass of water on the table—it's a cunning illusion—yet you still walk across the room in expectation of a drink: what is your motivating reason if not the belief–desire pair?

One response is to "go disjunctive" and claim that in the true belief cases the motivating reasons are facts, but in the false belief cases they are belief–desire pairs. However, thinking of reasons as facts is thought by some to invoke a different usage of "reason," to which we now turn.

## **7.2 Normative Reasons: The Two-Tier View**

To say that Anne is putting on her coat because she believes it's cold might imply an element of doubt—ordinarily we'd give as her reason the fact that it's cold. And assuming that she *should* (at least *pro tanto*) wear her coat for this reason, it is a "normative reason" (we shall typically omit the "normative").

It's important to note that there are two facts lurking here. Anne's reason is the first: It's cold. But there's also a second: The fact that the first fact is a reason for Anne to wear her coat. We have, then, a two-tier view of practical reasons. At tier one are the (normative) reasons for various actions; at tier two are the facts that the tier one facts are (normative) reasons for these actions.2 Tier two facts include facts about what is a reason for what—the fact that the cold is a reason for her to wear her coat—as well as simply the fact that she has a reason to wear it, and, more generally, the fact that agents have practical reasons (reasons to do things). Experience tells us that it's easy to muddle the tier one/tier two distinction, so perhaps it helps to appreciate that the two tiers give rise to different possibilities for error: you might be mistaken about the weather (tier one error); or you might fail to realize that cold weather is a reason to wear a coat (tier two error). A related potential muddle concerns the very use of the term "normative reason": the fact that it's cold is *not* normative, even though, in the usual terminology, it is a normative reason for you to wear your coat. It is tier two facts that are practical *normative* facts.3

**(p. 175)** So far, we have outlined a "simple" two-tier view of normative reasons, according to which practical reasons (tier one facts) are non-normative. But suppose you're contemplating an act that would cause undeserved harm. Isn't this a reason against doing it? If it is, then the simple view is false, since "undeserved harm" is a normative notion. However, any such act has non-normative features that make it a case of causing undeserved harm. So perhaps the simple view might be retained by citing these features as reasons, rather than citing the harm. For example, suppose you're deciding whether to cast the deciding vote on a piece of legislation that would increase sales taxes. This increase would cost the poor more relative to their incomes than it would cost the wealthy, and thereby inflict harm on the former group, let us suppose, and undeservedly so. What reasons do you have for voting against the increase? It seems that you might cite the first fact about relative cost; or you might cite the second, concerning undeserved harm. We see no problem with citing either, provided you don't cite both. The undeserved harm is a reason for you to vote against the increase, but not a *further* reason to vote in this direction, in addition to the higher relative cost to the poor. In any case of a normative tier one fact, there will be, we claim, non-normative facts that are equivalent to it qua practical reasons. So we reject the simple view, with the caveat that care must be taken not to "double-count."

The two-tier view, simple or not, raises a host of well-known questions and challenges. Many of these are usually raised with respect to the existence and nature of moral facts, but they are easily adapted so as to apply to practical normative facts in general.

First, there is the issue of whether there are any practical normative facts. Noncognitivists and error theorists disavow them. We discuss these views in section 7.4. Second, if there are normative facts, there is the issue of whether they are reducible to non-normative facts in some way. Naturalist normative realists maintain that there are normative facts, and (instantiated) normative properties, but that these are either reducible to, or even identical with, "natural" facts and properties—where, among other things, natural claims are empirically investigable, and natural properties play causal roles. We reject naturalism, along with noncognitivism and the error theory; thus we are non-naturalist normative realists.

We do not deny, of course, that empirical investigation can play a role in determining what we have reasons to do. For example, if we have reason to increase happiness, then working out how to achieve this requires empirical work. But the issue of whether the antecedent holds is a normative matter, and empirical research cannot resolve it. Why suppose, however, that a lack of empirical investigability should tell against the status of a claim? Science relies on mathematics and logic, and they are not subject to empirical inquiry. And what about the question of whether, say, scientists should adhere to the hypothetico-deductive method? How could we empirically investigate this issue? We can hardly apply the hypothetico-deductive method.

What of causal roles? One line would be to claim that neither mathematical nor logical properties play causal roles, in the sense that, say, the property of being solid does. So why should we insist that the lack of such a role tells against (non-natural practical) nor

mative properties? Another line might be to claim that normative **(p. 176)** properties can play causal roles. Your child is having a tantrum; this is a reason for you to soothe him; and there are no countervailing reasons. Your circumstances, then, have the normative property of there being among them an overriding reason for you to soothe your child. And, on this line of thinking, it can be in virtue of this property of your circumstances that you come to believe that you have this overriding reason—just as a ball might have the properties of being inelastic and having a certain momentum, and it is in virtue of these properties that it breaks the window. It should be borne in mind, however, that the *justification* of your belief that you have overriding reason to soothe your child would, as in all cases of justifying what is a reason for what (practical or theoretical), involve rational recognition and reflection—that is, doing such things as thinking carefully about your circumstances from various perspectives, and contemplating such matters as the relative importance of, say, fairness, the impersonal good, and personal enjoyment.

In addition to naturalist normative realism, there is a related reductive position—"descriptivism"—according to which ethical properties are identical to descriptive properties, where a descriptive term is (roughly) one that belongs "to the 'is' side of the famous 'is-ought' debate" (Jackson 1998: 113). Jackson contends that the account of properties germane here is one according to which necessarily coextensive properties are "one and the same property" (p. 126). If Jackson's argument for this position is sound, descriptivism can be adapted to conclude that tier two facts are identical to non-normative facts.4 Such a view (call it the "one fact view" or "OFV") is broader than naturalism since, for instance, whereas the naturalist eschews supernatural entities, an advocate of OFV might accept the claim (F1) that God has told you to A, and equate it to the fact (F2) that you have an overriding reason to A.

But adapting Jackson's view of property identity to fact identity results in a very coarsegrained view, on which, for example, the fact (F3) that 2 + 2 = 4 is identical to the fact (F4) that all bachelors are unmarried, or the fact (F5) that Peano Arithmetic is incomplete.5 We reject this view, and opt instead for a fine-grained view of fact identity that distinguishes facts in part on the basis of conceptual distinctions—so, according to us, despite their all obtaining at all possible worlds, (F3), (F4), and (F5) are distinct. The identity conditions for facts are, however, a complicated matter (see e.g. Mulligan and Correia 2013), and we won't pursue the topic here. But if we are correct, then, in order to establish that the OFV is false, it suffices to show that non-normative and normative concepts are distinct.

In the particular case of (F1) and (F2), some divine command theorists might claim that the concept of an action that you have an overriding reason to perform and that of an action that God tells you to perform are the same concept, but there are surely more plausible versions of the theory. For example, it might be claimed that (F1) is a tier one **(p. 177)** fact—it *is* an overriding reason to A—rather than being a tier two fact, identical to the fact that you *have* an overriding reason to do so.

More generally, Jackson himself acknowledges that "ethical language may be needed in practice to capture the similarities among the various descriptive ways that [ . . . ] constitute ethical nature" (1998: 124) because, from the non-normative perspective, the ethical might be infinitely disjunctive and patternless. The same applies to practical reasons overall: even if we (*per impossibile*) could list all the instances of reasonhood—some fact being a reason for some act—the grouping of all these instances would make no sense from the non-normative perspective, much as the grouping together of, say, all the different types of fasteners makes no sense in the absence of the notion of a functional artifact. And without a grasp of the concept of a fastener at the functional level, we could not categorize novel objects as fasteners (or not). Similarly, there is a distinct concept of what it is to be a reason, and without an understanding of this concept we could not, for example, discuss what it is that we have reasons to do in a novel circumstance.

OFV would, if true, however, provide a very simple account of the supervenience of the normative upon the non-normative. If there are normative facts, then all sides agree that they supervene upon non-normative facts: there cannot be a normative change without a non-normative one. OFV accounts for this by simply equating the normative and the nonnormative; but supervenience is often thought to be a special difficulty for positions such as ours. But we too have a simple account. The normative facts in question are facts about what you have reasons to do—tier two facts—and the basic idea is that there cannot be a change in what you have reasons to do without a change in the non-normative facts because your reasons themselves—the tier one facts—are among the non-normative facts.6

There are certainly complications here. For instance, how sharp is the divide between reasons and background non-normative circumstances? Perhaps the answer is "not very." But this does not undermine our position. All we require is that whenever there is a change in what you have reasons to do, there is a change in non-normative circumstances, and that remains the case.

We turn now to the relations between normative reasons and motivation. In the next section we explore views according to which whether you have a reason to perform some act depends upon your (idealized) will or motivations.7 These "constructivist" accounts of normative reasons are not fully fledged forms of normative realism in our sense, but they are, as it were, halfway there—both accounts we shall discuss rely, for **(p. 178)** example, on the notion of rationality, and this is a normative concept (one mark of the normative is the possibility of error, and irrationality is an error).

## **7.3 Constructivism and the Two-Tier View**

The two positions we're about to discuss—due to Bernard Williams and certain Kantians respectively—may not be inconsistent with the two-tier view per se, but they certainly differ from ours concerning the status of tier two facts. We see these facts as metaphysically basic; Williams and these Kantians deny this, making them constructivists about reasons. Their idea is that you have a reason to perform an act of some sort because of some fur

ther fact(s), where this "because" marks a metaphysical dependence. And then the fact that you have a reason can be seen, in a sense, as being "constructed" from the resources adverted to in the further fact(s)—although Williams and the Kantian constructivists differ on what the further facts are and how the "construction" proceeds.

### **7.3.1 Reasons Internalism**

On Williams' (1981 and 1995a) view—"reasons internalism" (RI)—you have a reason to do something only if, and because, you would be motivated to do it under the assumption that you are fully informed (about non-normative matters) and "procedurally rational" (which merely requires that you do such things as adhere to best deductive and inductive practices, and align your aims and intentions; crucially, you need not have any particular prudential or moral concerns). Suppose you're in the path of oncoming traffic. You have a reason to move, according to RI, only if you would be motivated to move if fully informed and procedurally rational. We reject this account: we are "reasons externalists" (REs). It may be that you have no reason to move. But, if so, REs contend, this is not dependent on rational procedure, information, and your current motivations in the way that RI supposes.

The RI's reason "construction" proceeds as follows. We start with the agent's current "motivational set," S, which includes not only her ordinary desires, but also "such things as [her] dispositions of evaluation, patterns of emotional reaction, personal loyalties, and various projects [ . . . ] embodying [her] commitments" (Williams 1981: 105). We then "correct" her S so as to ensure that she is "fully informed"—false non-normative beliefs are eliminated, and any missing relevant true non-normative beliefs are added.8 Finally we set her to work following the rational procedures mentioned above—deduction, induction, and resolving conflicts among her aims and intentions. At the end **(p. 179)** of this process, the agent is motivated to perform certain acts. These are exactly the acts that, on this view, she has reasons9 to perform.

Two initial points of disagreement with advocates of RE concern the constitution of "full information" and the contents of an agent's S. RI, obviously, rejects the idea that fully informing an agent includes informing her about what she has reasons to do—since, of course, what she has reasons to do emerges at the end of the constructive procedure. So what about her beliefs about what she has reasons to do (tier two beliefs, as we'll call them)? Can these be part of her initial S? It would seem odd to deny this: couldn't an agent's deliberations about what to do involve thinking about what she has reasons to do, so that tier two beliefs could play a role in practical deliberation? And wouldn't such beliefs feature in an agent's "commitments"? Deliberating about what one has reasons to do is a key part of what it is to respond to reasons as reasons, in contrast to merely responding to reasons as stimuli (for want of a better expression), as perhaps many animals do. Fido responded to the fact that an intruder was lurking by barking, and we might want to say that the intruder's presence was an overriding reason for Fido to bark, so that he responded to the reason appropriately. But he didn't respond to the reason *as a reason*, in

the sense that he could have, for instance, entertained the question: "Is the intruder's presence a reason for me to bark?"

Yet, on the RI account, tier two beliefs would not be subject to correction or augmentation in the process of the agent becoming fully informed, since, as we just saw, tier two facts must be omitted from full information. Indeed, it is not even clear what the content of a tier two belief comprises—what does it mean, on this view, to say that an agent has a reason to A? Williams is puzzled over the meaning of external reasons claims (1981: 110– 11; 1995a: 39–40). But why is he any less puzzled over the meaning of internal reasons claims? He agrees (1995b: 187–8) that an agent can arrive by correct deliberation at the belief that she has a reason to A. But he (sensibly) denies that this is to arrive by correct deliberation at the belief that if she deliberated correctly she would be motivated to A. Williams agrees that "she has reason to A" is not equivalent to "if she deliberated correctly, she would be motivated to A" (1995b: 187–8). Thus it is unclear what the content of an agent's belief that she has a reason to A, or that of the question "what do I have reasons to do?", amounts to on Williams' view.

The RE, on the other hand, regards the notion of a reason as metaphysically (and conceptually) basic; and, were it possible to fully inform an agent, tier two facts would be crucial contributions. And agents can entertain questions about what they have reasons to do at any point in their deliberations. In denying that tier two facts are among the complement of facts to be included in an agent's full information, the RI can be seen as begging the question against the RE. But, naturally, the RI has various rejoinders.

First, Williams claims: "Internalist theory explains how it is that the agent's accepting the truth of 'There is reason for you to A' could lead to his so acting, and the reason **(p. 180)** would thus explain the action. It is obvious on the internalist view how this works" (1995a: 39). However, as we've just discussed, it's unclear what it would be for the agent to accept this truth on Williams' view. In fact, it seems clearer on RE "how this works": it is open to RE to hold that an agent's *accepting that* she has a reason to A leads to her being motivated to A (we discuss this claim in section 7.4). The RE claims that someone may have a reason to perform some particular act even though she could not be brought to be motivated (let alone moved) to do it, even when fully informed (in Williams' sense) and procedurally rational. But having a reason is distinct from believing that one has.

However, perhaps Williams is merely applying a "reasons implies can" principle: If you have reason to A, you must be capable of A-ing. But the RE can certainly accommodate this—whether you have reason to pursue some course of action depends on your capabilities: if you can't swim, you typically have no reason to jump in the deep end. More generally, the RE does not deny that reasons are personal—all practical reasons are reasons *for* agents to perform acts in the circumstances in which they find themselves, which include their own tastes and capabilities. For example, we have reason to seek innocent enjoyment, and enjoyment is certainly idiosyncratic.

Finally, Williams asks (1981: 110; 1995a: 39–40), why, when there is no procedurally rational route to motivation, does the RE speak of reasons? For example, rather than pointing out that the agent had strong reasons not to do something, we could criticize him in other ways (he was, say, cruel). The RE has two responses. First, the fact that an act would be cruel *is* a reason against it. Second, why suppose that rational procedures are so centrally important? Coming to see matters aright "may need some non-rational alteration" (McDowell 1995: 78). And this is not unique to practical reason—consider the Kuhnian paradigm shift (Kuhn 1962). Or, less radically, it might suddenly dawn on someone that the facts before her give her reason to believe some hitherto unconsidered possibility, just as it might dawn on her that they are reasons to perform some hitherto uncontemplated act, where, even though there need be no rational routes to these new realizations, yet they are veridical nonetheless.

Before we move on, another, more recent RI position warrants mention. Although she does not express matters in these terms, Sharon Street's (2006) constructivism is essentially a version of RI, with "evaluative attitudes" replacing "motivational set" (although she incorporates neither Williams's requirement of full information nor that of procedural rationality), and her evolutionary argument against realism is an argument against RE. This argument rests on the premise that "the forces of natural selection have had a tremendous influence on the content of human [practical] judgments" (Street 2006: 113), and its upshot is that our practical tier two beliefs arose and persisted because they were evolutionarily advantageous, not because they "tracked" the truth. Their truth is not metaphysically basic, but, rather, is dependent upon our taking them to be true. One response is to note that, while selectional forces may explain many of our *desires*—including, say, our desire to see our offspring thrive—it's a further step, as Street acknowledges, to claim that these forces explain why we believe that we have reason to favor our own offspring. We may desire something and also believe truly that we have no reason to pursue it. Street counters this line with the thought that her constructivism **(p. 181)** does not rule out rational reflection; it's just that such reflection cannot escape the bounds of our selectionally influenced evaluative attitudes.

One issue, then, is the extent to which rational reflection really is distorted by natural selection (and, following McDowell's suggestion above, might not some "non-rational alteration" enable us to access truths beyond our prior attitudes?). Another is that Street's argument may prove too much. Like her (2006: 156, n. 2), we think that, if it succeeds, it can be extended to *theoretical* normative facts. Indeed, she argues this explicitly (Street 2009), and concludes that the fact that you have reason to believe some proposition, just like the fact that you have reason to perform some act, ultimately depends on your evaluative attitudes. But now she is in danger of running up against standard difficulties with relativism: what is the status of her own argument to the effect that all the normative truths that she accepts stem from her own selectionally influenced evaluative attitudes? She purports, for example, to give us overriding *reasons* to believe that our practical judgments are *better* explained by selectional forces than by the tracking account (a claim that is subject to challenge). This radical normative subjectivity also impacts her reasons internalism concerning practical reasons. Williams's incorporation of an "objective" ac

count of procedural rationality adds plausibility to his view, but Street's rational reflection appears to be inevitably subjective—on her view there is, it seems, no fact of the matter as to who is being irrational when agents disagree over matters of procedural rationality.

Some of the foregoing thoughts also apply to Kantian constructivism, our next topic. We shall not repeat ourselves, however; rather, we shall focus upon two notions distinctive of the Kantian approach: autonomy and the rational will.

### **7.3.2 Kantianism**

According to Darwall:

In [the Kantian] view, as in that of [RI], something's standing as a normative reason ultimately depends on its being motivating (treated as a reason) in fully rational deliberation, where the latter is determined by internal, formal features of the deliberative process, not by its responsiveness to independently establishable normative reasons (2006: 299)

Where do these Kantians differ from RIs, then? They might be seen as simply extending Williams' notion of procedural rationality to include the requirement that practical reasoning accord with the categorical imperative (CI)—the first formulation (FF) of which reads: "Act only according to that maxim whereby you can at the same time will that it should become a universal law without contradiction" (Kant 1993 [1785]: 30). Like Williams, these Kantians deny that practical reasons are metaphysically basic. Rather, both accounts are constructivist about reasons—what you have reasons to do depends on what you would be motivated to do if fully informed (about non-normative matters) **(p. 182)** and procedurally rational. The difference comes in what is to be included under the procedural umbrella.

On the Kantian constructivist view, then, tier two facts—facts to the effect that we have practical reasons—are seen as "constructed" by a rational will in accord with a procedure that respects the CI. The RE opposition, which includes Parfit (1997, 2011), sees such facts as freestanding. As Scanlon puts it: according to the Kantian constructivist about reasons, justification "never runs [ . . . ] from claims about reasons to claims about what rationality requires," whereas Parfit, by contrast, appeals "to an idea of 'what one can rationally will' that presupposes an independently understandable notion of the reasons that a person has and their relative strength" (in Scanlon's response to Parfit in Parfit 2011, vol. ii: 121). We are not in wholehearted agreement with Parfit here, since we are not wedded to the Kantian notion of "what one can rationally will," but on both our views the tier two facts are freestanding and metaphysically basic.

Kantians focus upon the possibility of acting as morality requires, and doing so from the appropriate motive. And they hold that this is possible only if there are unconditional practical reasons—reasons sufficient to motivate the will of any rational being, independently of what that being desires. For the Kantian, the recognition of facts cannot play

this role. She can be seen, then, as sharing the error theorist's suspicion of "strange facts"—facts whose mere apprehension motivates us. On one version of the RE account there are facts about what we have reasons to do, and if we come to believe these facts we are motivated to perform the acts in question.10 But for the Kantian, the apprehension of facts that are "out there in the world," and thus external to the will, can motivate in only one of two ways: via desire, or through causal necessity. Awareness of a fact can combine with a desire to give the agent a (motivating) reason to act—but then the status of that fact as a reason is conditional on desire. Alternatively, we might be so constructed that our realization of certain facts removes choice, and causally determines action. But then the action would not be free.

The Kantian, then, maintains that reason has a practical as well as a theoretical role. But whereas theoretical reason uncovers facts that are independent of it, by sifting external evidence, pure practical reason, which is governed solely by the CI, and manifested in the rational will, is self-determining (an analogy here is the sovereign nation state). Being practically rational just *is* acting in accord with the CI—the CI determines both how the rational will does act and how it should. Thus the CI is a normative standard internal to practical reason, and the rational will has no other—it is beholden to no external standard. The rational will is, then, autonomous in the Kantian sense: it provides its own normative standards and obeys them. And if the possessor of such a will has a reason to perform some act, that is because she would be motivated to perform it after fully rational deliberation—deliberation that conforms to the CI.

RE, on the other hand, assimilates practical to theoretical reasoning by claiming that theoretical reason can uncover not only tier one but also tier two facts. But, says the **(p. 183)** Kantian, whatever facts are available to theoretical reason will still be facts external to the will. Merely adding new facts to its output cannot make theoretical reason practical. Practical reason is distinct, serving not to reveal the facts to us, but to make (metaphysically speaking) the rational will autonomous. RE agrees with the Kantian that beliefs with non-normative content do not, by themselves, have a practical role, but insists that when a belief's content is normative, its practical purport is unmysterious. RE holds, in short, that the role of reason—to uncover the facts—remains constant, and that practical import is supplied by normative content. The Kantian responds that it is only when we recognize that reason has two quite different roles—the practical and the theoretical—that we can grasp how reason can determine the will. Indeed, on one understanding, the Kantian denies that there are any tier two *facts—*rather, there are merely imperatives, as in FF.

The contention that the CI determines the nature of practical rationality accords with the idea that practical reasons must be universal, in the sense that if you act in a certain way in certain circumstances, then you will that any rational being similarly placed should act in the same way. There is no reason to steal, for example, because the thief is not advocating a general rule (T) that everyone steal in circumstances similar to his—he is, instead, willing that *he* steal, but no one else. Willing (T) universally would involve a contradiction "in conception": if everyone stole promiscuously, this would undercut the very possibility of property (or so the thought might go), thereby rendering stealing conceptu

ally impossible. More generally, rationality requires avoiding contradiction; thus rationality requires conformity to the CI. It is not as though the rational will has a choice, then, in the normative standards it provides for itself.

There are several well-known difficulties with the Kantian approach. Here are two. First, there is the issue of the adequacy of the CI. In many cases of morally impermissible acts, such as child abuse, it is unclear how FF is violated. And, on the other side of the coin, there are permissible acts whose maxims do violate FF—for example, I make it my maxim to open the door for others.

Then there is the complaint that the Kantian strategy must presuppose normativity at the start in order to get it out at the end, as it were. As O'Neill (a prominent Kantian) puts it, the danger is that if "the standards of practical reasoning are fundamental to all human reasoning, then any vindication of these standards is either circular (since it uses those very standards) or a failure (since it is not a vindication in terms of the standards that are said to be fundamental)" (O'Neill 1989: 29). Admittedly, if practical reason can be generated from FF, then the normativity presupposed might be said to be mere "formal" rationality—the avoidance of contradiction—as opposed to something more substantial. The RE posits substantial normativity with no justification, whereas the Kantian constructivist project might be construed as deriving substantial normativity from mere formal rationality. But we are skeptical that merely formal input can generate substantial output.

Another version of the CI, for example, is Kant's "Formula of Humanity" (FH): "So act that you use humanity, whether in your own person or in the person of any other, always at the same time as an end, never merely as a means" (1993 [1785]: 36). On one **(p. 184)** interpretation, FH is more substantial than the first formulation—if we assume a particular substantial interpretation of the notions of "end" and "means," for example, it is clear how child abuse violates it. But how is FH to be justified?

Here's one attempt (based on that due to Korsgaard 1996: 259–62). If anything is unconditionally good, humanity is. And if humanity is unconditionally good, this justifies FH. But how can we establish that there is something of unconditional value? Well, rational agents act for ends, which they must assume to have value. Suppose, for *reductio*, that all ends are assumed to have only conditional value. But what about the value of these conditions? Surely they must be unconditionally valuable, on pain of regress. What serves as a condition of something's goodness must itself be unconditionally good. Thus agents must take it that something is unconditionally good—and if agents must take it to be so, it is so (this is an instance of Kant's transcendental idealism).

This argument is open to dispute, however. First, transcendental idealism in general is open to challenge. Second, why is it that, if anything is unconditionally good, humanity is? Third, the condition of a thing's goodness need not itself be good (see e.g. Darwall 2006: 299–300). Compassion, say, is only good when directed at an appropriate object—at a suffering being who deserves pity. But the existence of a suffering and pitiable being is not good.

We suspect, then, that if FH is substantial, it is unsubstantiated—at least, it cannot be substantiated with merely formal resources. And, if it is unsubstantial, like FF it at best renders verdicts about moral impermissibility, and this omits large portions of the practical realm—the CI might rule out various of my current options as impermissible, but it doesn't tell me what I do have reason to undertake. Furthermore, the manner in which FF arrives at verdicts of impermissibility, by declaring immoral maxims self-contradictory in some way, seems to miss the point—even if the child abuser does act on a self-contradictory maxim, this is not what makes child abuse wrong. Even if, *per impossibile*, some purely formal procedure such as FF were adequate, why would it be a reason-*maker*, as opposed to an epistemic *check*? (You think you have a reason to perform some act, but, just in case, you might run it through some procedural check, if such were available.)

So, to sum up, whereas the RE sees normativity as metaphysically basic, and something that the rational will might latch onto, one of the Kantian's central ideas is that normativity and motivation (in the ideally rational case) arise from a single formal procedure: the application of the CI. This Kantian "two for one deal" is certainly economical, but we find it to be ultimately untenable—although we acknowledge that, to some extent at least, the dispute between ourselves and the Kantian constructivist is an opposition between two very different accounts of ourselves as rational and reasoning beings, with very different presuppositions, so that the stand-off is unlikely to be resolved by argument. Rather, what is required is a perspectival shift.

We turn now to two arguments, based on motivational considerations, to the effect that there are no practical normative facts—not even in the attenuated sense of the constructivist.

## **(p. 185) 7.4 Noncognitivism, the Error Theory, and Motivation**

Some might doubt that there are practical normative facts because they doubt that there are *any* normative facts. But this position is in danger of undermining itself: if there were no normative facts, then we could have no reason to believe this, since, if we did, it would be a fact that we have a reason to believe it, and this would be a normative fact. Noncognitivists and error theorists, however, do not follow this route. Rather (like the Kantian), they see a sharp distinction between practical and theoretical normative claims, and it is only the former that they challenge.

Assuming there are practical tier two facts, what role do they play in motivating (and moving) agents to act? On one account (A ), "practical opinions" are tier two beliefs—beliefs that tier two facts obtain. And these, when combined with suitable tier one beliefs (beliefs that tier one facts obtain), motivate agents to act,11 without the need of any independent desires. 1

Another account (A ), however, while agreeing that practical opinions are tier two beliefs, sees independent desires as required for motivation. On this alternative, rational agents have a standing desire (D) that they do what they have most reason to do. And it is the combination of D with the relevant tier one and two beliefs that moves agents to act. My beliefs that it's cold, and that this is an overriding reason for me to wear my coat, combine with D to move me to wear my coat. All three components are necessary for motivation, and D is independent of any particular beliefs.12 2

A third account (A ) has no place for tier two beliefs—it sees motivation as arising from the combination of desires (the practical opinions on this account), and tier one beliefs. I am motivated to put on my coat by my tier one beliefs that it's cold, and that my coat will keep me warm, combined with my desire to keep warm. 3

For present purposes, we'll suppose that these three options exhaust the possibilities. A and A are forms of "motivational internalism" (MI) since, unlike A (a form of motivational externalism, ME), they do not posit any motivational mental states "external" to the tight-knit group comprising practical opinions and relevant tier one beliefs. 1 3 2

Beliefs are either true or false (they are "cognitive" mental states), but desires are neither (they are "noncognitive")—while it may be true that I desire to A, the desire itself is neither true nor false. A and A , then, are cognitivist views, whereas A is a form of noncognitivism. 1 2 3

**(p. 186)** The argument against the view that there are practical normative facts (practical normative realism, PNR), and in favor of noncognitivism (to put matters anachronistically), dates back at least as far as Hume (1978 [1739]). His account of motivation, in modern guise, has two components. First, beliefs and desires are independent of one another (the Humean independence thesis, HI). Second, motivation to act requires both beliefs and desires (the Humean belief–desire thesis, HBD; see also section 7.1). We'll assume that HBD is correct in some form.13

A violates HI. Thus A , noncognitivism, is the only form of MI consistent with both HI and HBD. And assuming that, if there were practical normative facts, we'd believe some of them, and these beliefs would play a motivational role, A entails the denial of PNR. 1 3 3

PNR must plump, then, for A or A . Given HBD, A requires a form of MI that posits belief dependent desires. Here are two possibilities: 1 2 1

(MI ) Necessarily, an agent who believes she has a reason to A desires to A (where this desire stems from the belief). 1

(MI ) Necessarily, a *rational* agent who believes she has a reason to A desires to A (where this desire stems from the belief).14 2

One argument against MI focuses upon the possibility of an agent who suffers from extreme apathy. The claim is that such an agent might believe, say, that she has a reason to get out of bed, but have absolutely no desire to do so. This is impossible by the lights of 1 MI . MI , by contrast, is consistent with the possibility of such an agent—he is irrational in having the belief but lacking the desire. 1 2

A can also accommodate extreme apathy by pointing to a temporary irrational lack of desire, but now the lacking desire is D. A , however, might be challenged on phenomenological grounds—no one has a "felt" standing desire corresponding to D. But perhaps desires need not be felt. There is an alternative model according to which some desires are merely dispositional states with no associated phenomenology. On this **(p. 187)** model, D could be a disposition on the agent's part to form a desire to A whenever she believes she has overriding reason to A. This approach also answers a complaint against A to the effect that, by its lights, rational agents would always be acting out of a felt and obtrusive desire that they do as reason demands, as opposed to desires for such things as fun or others' well-being.15 2 2 2

But now there is another difficulty: if A posits D as a rationally required disposition, then MI entails A , since MI posits as a rational requirement that agents have dispositions that include D. 2 2 2 2

What of the difference between MI and A , on the one hand, and MI on the other? The advocate of the latter maintains that whenever you believe that you have reason to A, you desire to also—but the desire can be exceedingly weak. Thus much hinges on the distinction between not being motivated in the least, and being motivated only very little**—**but how important is this distinction? And when it comes to believing that you have a reason to act in some way, what are the criteria for having such beliefs? One criterion might be that such beliefs are linked to motivation. But how is the debate over this criterion to be adjudicated? And how significant would an answer in one direction or the other be? It is, rather, the difference between A and its alternatives, rather than those among the latter, that is key. 2 2 1 3

How persuasive is noncognitivism as an alternative to PNR? The arguments are manifold. Among the more novel, David Lewis (1996) mounts a decision-theoretic argument against A ; but since this argument is somewhat technical, we respond to it in appendix I. On the opposite side, the noncognitivist faces the difficulty of preserving various features of our common discourse about reasons. For example, if practical opinions are pure desires, it seems people can't disagree about what they have reasons to do in the appropriate way: desires do not clash in the way that beliefs do. Further, the following argument appears valid: 1

(ARG) If you have a good reason to avoid him, then you have a good reason to warn your little sister about him; you do have such a reason; thus you have a good reason to warn your little sister.

Validity is defined in terms of truth preservation, but the noncognitivist denies that practical normative remarks have truth-values. And any attempt to surmount this obstacle has to accommodate embedded clauses, such as those in the conditional that constitutes the first premise of ARG.16

In contrast to the noncognitivist, the error theorist accepts A . But, in light of this, she claims that if there were tier two facts, they would be metaphysically suspect17—your merely believing them would motivate you. Thus all tier two beliefs are in error: there **(p. 188)** are no tier two facts. But we disagree: what's so odd about your apprehending that you have a reason to visit Anne motivating you to make the trip? 1

## **7.5 Oughts and Reasons**

Let us suppose that we are correct, and that there are indeed tier two facts. The following question then arises: what is the relation between what I ought to do and what I have most reason to do?

On our view, practical reasoning consists, roughly speaking, in assessing what reasons we have to pursue our various options, in some particular case, and how weighty they are. Some reasons are weightier than others, and in many cases18 the preponderance of weight will favor one particular course of action. So what ought I to do? An obvious suggestion would be:

(OMR) I ought to do what I have most reason to do.

But there are problems with this suggestion.

There are cases, indeed, in which you know that you ought *not* to do the act that you have most reason to do. Suppose a doctor has at her disposal three pills, about which she knows the following:

The first two pills would each either cure the patient of his moderately debilitating illness, or kill him. The first would kill just if the second would cure, but she has no way of finding out which would kill and which cure. The third pill is merely palliative.19

The doctor knows she ought to prescribe the third pill, even though she knows that this is not the act that she has most reason to perform—she knows that she has most reason to cure the patient, and so she knows that she either has most reason to prescribe the first pill or most reason to prescribe the second, but she also knows that she can't find out which.

There are also cases in which you ought to do something despite lacking any reason to do it. Suppose you are approaching an unmarked traffic junction with limited line of sight. Do you have reason to slow down? Well, if no vehicle is approaching on the road you intend to cross then, no, you don't have a reason. But surely you *ought* to slow down, given your limited view. This example is due to Prichard (2002: 93), who also rejects **(p. 189)** OMR. And, in addition, he rejects the view (as do we) that there is an objective probabili-

ty that a car is coming, and that the agent ought to slow down because this probability is greater than zero. Rather, Prichard's view is suggestive of Bayesianism, according to which all probabilities are subjective. On the "pure" version of this view, probability assignments held by an agent are criticizable if and only if they collectively violate Kolmogorov's (1933) axioms. This comports with the idea of rationality as internal consistency: internal consistency of subjective probabilities (also known as "degrees of belief" or "credences")—or "coherence"—is conformity to Kolmogorov's axioms. And you can have quite, shall we say, unconventional credences that are yet coherent.

Prichard (2002) is concerned with moral duty, but we shall adapt his view20 to "oughts" more generally, before contrasting it with our own. Prichard contends, in line with the thought that "ought implies can," that an agent should be capable of knowing what she ought to do, and he has stringent criteria for knowledge: "Even in the case of moving our arms or making a noise we do not *know* that, if we were to set ourselves to do it, we should do anything" (2002: 97). Thus what I ought to do is *set myself to* perform some act. And what I ought to set myself to do is based, in part, upon my credences concerning the effects of my willing. He thinks, for example, that if a "would-be torturer [were] in a very high degree confident that torturing, and torturing only, would save the heretic, he [should set himself to] inflict the torture" (2002: 94). Because of this reliance upon subjective confidence, Prichard dubs his view "subjective." (We'll omit "set oneself to" henceforth.)

Having laid out the objective (roughly, OMR) and subjective views, as he sees them, Prichard (2002: 95) claims "there is no third course." We disagree. Our view is that "reasonable" agents pay attention to the empirical evidence available to them, and think carefully about what is a reason for what. Given that they do this, they will (implicitly, at least) arrive at a range of probability estimates concerning these matters that are "reasonable" for them, given their circumstances. Admittedly, the notion of reasonable credence, requiring more than mere coherence, is imprecise, and what credences are reasonable is subject to debate.21 But reasonableness of credences is hardly alone in this.

What a person ought to do, then, depends upon what credences it is reasonable for her to hold concerning her situation, including the strengths of her practical reasons to do various things. (This account is further developed in appendix I.) When you ought to slow down at a traffic junction, then, this is not because you merely happen to have a **(p. 190)** non-zero degree of belief that traffic is present, but because such a credence is reasonable, as is a high credence in the proposition that the presence of traffic is a very strong reason to slow down.22 Prichard's torturer has an unreasonably "high degree" of confidence that torture is required for the heretic's salvation, and hence he ought not to torture.

While not objective in Prichard's sense of appealing to objective probabilities, our view is objective in another sense: there is a fact of the matter as to whether a particular credence (or range thereof) in some proposition is reasonable for an agent in her circumstance. And this is consistent with "ought implies can," since reasonable agents can come to have reasonable credences, and hence come to know what they ought to do.

When we engage in practical rational reflection, we try to determine what we have most reason to do. The fact that a dog is chasing it is an overriding reason for the cat to climb a tree. But the cat is incapable of appreciating this normative fact—unlike us, the cat cannot respond to reasons under their guise as reasons. However, even for us, ignorance intrudes, and verdicts concerning what we ought to do take account of this, forcing a separation from what we have reason to do. Admittedly, the way in which we separate ought from reasons is partly stipulative, but it also helps resolve some puzzles of common usage. For example, in retrospect, we sometimes claim both that we made the wrong choice and that our choice was the best we could have made. You slow down at the unmarked traffic junction, only to discover your way is clear. You acted correctly given the evidence available. Yet you also acted incorrectly in that you slowed unnecessarily. So there are two standards of correctness. You had most reason to continue apace: it would have been the correct choice in the "reasons sense." But you chose as you ought: slowing was the correct thing to do in the sense that it was based on reasonable credences.

## **7.6 Conclusion**

We began by discussing Davidson's view that motivating reasons are desires paired with tier one beliefs, but, in response to a realist view about normative reasons, it was mooted (section 7.4) that an agent's motivations can stem from her tier two beliefs. Next (in section 7.5) we added credences23 to the mix to yield an account of what an agent ought to do, about which agents form beliefs24 that play a key role in action. Such beliefs may be false on our account, but reasonable agents work out the truth, and do as they ought, even in the face of strong desires to do otherwise.

**(p. 191)** In discussing Davidson, we raised a concern about the absence of a role for the agent in her actions—she seems to be merely a vessel propelled by her desires in light of her tier one (instrumental) beliefs. One attempt to get around this sort of worry is to invoke second-order desires—you may, for example, desire to A while at the same time desiring to be rid of this desire. Harry Frankfurt (1982; see also O'Connor 2014) proposes that you act freely when you fulfill desires that you desire to fulfill, and that it is your second-order desires that express your true self. But this raises questions. Why stop at the second order? And if you modify your second-order desires to align with your first-order desires, rather than the other way around, and act on these, are you acting freely? Would these second-order desires then express your true self? Our view is that cognitive judgments, such as your belief that you ought to A, express your true self—an approach that does not suffer the same regress and alignment problems as Frankfurt's. And, as regards free action, perhaps a necessary condition of your acting freely, in one sense, is that you do as you believe you ought.

On our proposal, in deliberative cases at least, the (reasonable) agent ponders what she has reason to do, taking into account her own ignorance, and arrives at a belief about what she ought to do. She then adjusts her motivations in its light. It may be protested that we have merely substituted normative beliefs for desires, again leaving no role for the agent in her actions. But the thought is that, if normative beliefs play a key role in regimenting our motivations, at least this source of action is subject to the agent's rational input. We noted in section 7.1 that Davidson also has a place for ought judgements, and that his view is at least consistent with the possibility that these express both beliefs and desires. He could maintain that the beliefs are parasitic upon the desires, as it were, but this seems implausible in many cases—surely, if, after much deliberation, I decide that I ought to take the job, this is not (in the standard case) parasitic upon my desire to do so; it's the other way around. So perhaps, after all, our position is consistent with Davidson's in this respect.

## **Appendix I Lewis on "Desire as Belief"**

Lewis (1996) challenges the possibility of there being desires necessarily connected to beliefs. His main argument is directed at a "simple theory" he calls "Desire as Belief" or "DAB," one version of which states:

Necessarily, and regardless of one's credence distribution, one must desire A exactly to the extent that one believes it to be good. (1996: 308)

That is, if V(A) is the degree to which you desire A, and A* is the proposition that A is good, then, necessarily, for any credence distribution C you might have, the following holds:

(DAB) V(A) = C(A*) (p. 308)

**(p. 192)** Lewis attempts to discredit DAB by establishing that if it holds under one credence distribution "it will cease to hold under almost all redistributions of credence" (p. 308).

Rawling (2016)25 contends that Lewis's own argument against DAB fails, but that there is an alternative that works. Thus, with Lewis, we reject DAB. However, by Lewis's own admission, there may be alternatives to DAB that are not defective.

Recall:

(MI ) Necessarily, a *rational* agent who believes she has a reason to A desires to A (where this desire stems from the belief). 2

How are credence and strength of desire to be incorporated into this formulation? For a rational agent, the strength of her desire to A, it seems, should depend in some way on her credence about the *strength* of her reason(s) to A. The strength of her desire to A, then, is *not* to be equated with her credence merely that she *has* a reason to A, as might

be suggested by a parallel with DAB. Rather, this desire strength is determined by two components: the possible strengths of her reasons, and her credences that she has reasons of these strengths. She might have, say, a high credence that she has a very weak reason to A, or a low credence that she has a very strong reason to A. In these two cases, the subjective expected strength of her reason to A—and hence, on this approach, the rational strength of her desire to A—might well be identical.

In general, an agent might have various credences that she has reasons of various strengths to act in some particular way. Consider, for instance, the strength of your desire to give Anne an aspirin (A). As noted, it is *not* equal to your degree of belief that you have a reason to A. Rather, on this view, if (a) you are rational, (b) Rj is the proposition that your reason to A is of strength j (we assume some suitable measure of reason strength is available, based on a ranking of reasons by strength), and (c) C(Rj) is your credence in Rj, then:

(Eq1)

Rj is a normative proposition—depending on whether j is positive or negative, it asserts in part that you have, respectively, a reason for or against A-ing. R(1) is the proposition that you have a reason of strength one (on some suitable scale) to A (perhaps Anne has a headache and an aspirin would relieve it); R(–2) the proposition that your reason to A is of strength minus two—that is, you have a reason of strength two against Aing (perhaps aspirin would harm Anne). Suppose your credence in R(1) is .8, and in R(–2) is .2. Thus:

$$\begin{aligned} \mathcal{C}(\mathcal{R}(\mathbf{1})) &= \mathbf{.} \\ \mathcal{C}(\mathcal{R}(-\mathbf{2})) &= \mathbf{.} \end{aligned}$$

and

$$\mathbb{ZR}\left(\mathbf{A}\right) = \left[\mathbf{1}\left(.\mathbf{3}\right)\right] + \left[-\mathbf{2}\left(.\mathbf{2}\right)\right] = .\mathbf{4}$$

**(p. 193)** Of course, this is massively oversimplified, and ER(A) is meaningless in the absence of expected reason strengths for other acts with which to compare it. The idea, of course, is that ER(A)>ER(B) if and only if, by your lights, your A-ing is more choiceworthy than your B-ing. And what you ought to perform is the act with the highest ER (or one of them in the case of a tie). Note that we can drop the thought that ER must mirror desire strength (except, perhaps, in perfectly rational agents). You can think that you ought to A because A-ing has the highest ER, even if you most desire to do otherwise.

How does expected reason strength relate to expected utility, as standardly conceived? The thought is that reason strength equals utility: the strength, j, of my reason to A in state Sj26 equals the utility of my A-ing in Sj (assuming we have sorted out the relevant scales). Thus:

$$j = U\left(\mathcal{A} \text{ ùn } \mathcal{S}_j\right)$$

And:

Hence (Eq 1) is equivalent to:

$$\mathbb{E}\mathbb{R}\left(\mathcal{A}\right) = \sum_{j} U\left(\mathcal{A}\text{ in } Sj\right) \cdot C\left(Sj\right)$$

(Eq 2)

But

is equal to to the expected utility of act A as calculated according to causal decision theory27 (CDT), in which it is assumed that the agent believes the states in question to be causally independent of her possible acts. Hence we have arrived at:

$$ER\left(\mathcal{A}\right) = \text{Causal expected utility of act } \mathcal{A}\left(= EU\left(\mathcal{A}\right)\right)$$

(Eq 3)

And key to CDT is the result28 that:

(by the rational agent in question)

That is, causal expected utility, like expected reason strength, mirrors rational choiceworthiness among acts.

**(p. 194)** The expected reason strength approach is clearly consistent with PNR, and thus so is CDT. However, both are also consistent with the denial of PNR, and thus we do not have here an argument in either direction. But we hope to have allayed fears that normative realists who reject HI must reject decision theory.

## **Appendix II Reasons and Future Contingents**

We have supposed that there are facts to have credences about. Sometimes, however, we're looking to the future in deciding what to do. Should I take an umbrella? This depends upon whether it will rain later in the day—a causally contingent matter, perhaps, if one holds an indeterministic view of the world. And, on some indeterminist views, no future contingent is true (or false) now. If so, how are credences to be incorporated in such cases, in which they are not credences in the truth of a proposition? Given the clouds, it seems I ought to take my umbrella because it's reasonable for me to have a high cre

dence that it will rain later. But how can this be if it's also reasonable for me to have a relatively high credence in the proposition that future contingents lack truth-values?

Thomason (1970), building on the work of Prior (1967) and Van Fraassen (1966, 1968), develops a view according to which future contingents lack truth-values in the present. On this account, there are various world "histories" (sets of times) that coincide up to now, and then diverge into disjoint future branches (to reflect indeterminism). Each history respects bivalence, but no proposition of the form:

*p* will be true in the future (abbreviated as "F*p*")

is true (*simpliciter*) now unless *p* is true on every future branch. If *p* is true on some future branches, but false on others, then F*p* lacks an overall truth value now.29 But we want to assign a credence to F*p*, even when F*p* lacks a truth-value—so is, for example, F*p* a proposition? If not, what is your credence a credence concerning? On one account of propositions, a proposition is considered to be identical to the set of possible worlds in which it's true; in similar vein, we suggest that a future contingent be identified with the set of histories in which it's true. The sets of histories constitute a field of sets, hence the standard Kolmogorov (1933) probability axioms can be applied. And there is precedent for probabilities that are not probabilities of truth—consider, for instance, Ernest Adams's view that the probability of a conditional is a conditional probability.30

Even in the absence of facts about the contingent future, then, we can still maintain a semblance of the two-tier view concerning it. At tier one, we can appeal to reasonable credences about sets of histories in their role as future contingents. At tier two, we can make a parallel appeal to an agent's reasonable credences concerning the strengths of her reasons to act given a particular set of histories. And the results and framework from appendix I then apply.

## **References**

Alvarez, M. (2016). "Reasons for Action: Justification, Motivation, Explanation." In E. N. Zalta (ed.), *The Stanford Encyclopedia of Philosophy* (Winter). <**https:// plato.stanford.edu/archives/win2016/entries/reasons-just-vs-expl/**>.

Bennett, J. (2003). *A Philosophical Guide to Conditionals*. Oxford: Oxford University Press.

Darwall, S. (2006). "Morality and Practical Reason: A Kantian Approach." In D. Copp (ed.), *The Oxford Handbook of Ethical Theory*, 282–320. Oxford: Oxford University Press.

Davidson, D. (1980a). "Actions, Reasons, and Causes." In *Essays on Actions and Events*, 3–19. Oxford: Clarendon Press.

Davidson, D. (1980b). "Mental Events." In *Essays on Actions and Events*, 207–25. Oxford: Clarendon Press.

Davidson, D. (1980c). *Essays on Actions and Events*. Oxford: Clarendon Press.

Davidson, D. (2005). *Truth and Predication*. Cambridge, Mass.: Harvard University Press.

Frankfurt, H. (1982). "Freedom of the Will and the Concept of a Person." Repr. in G. Watson (ed.), *Free Will*, 2nd edn, 322–36. Oxford: Oxford University Press, 2003.

Hume, D. (1978) [1739]. *A Treatise of Human Nature*, ed. L. A. Selby-Bigge and P. H. Nidditch. Oxford: Clarendon Press.

Jackson, F. (1991). "Decision-Theoretic Consequentialism and the Nearest and Dearest Objection." *Ethics* 101: 461–82.

Jackson, F. (1998). *From Metaphysics to Ethics: A Defence of Conceptual Analysis*. Oxford: Clarendon Press.

Kant, I. (1993) [1785]. *Grounding for the Metaphysics of Morals*, trans. J. W. Ellington, 3rd edn. Indianapolis: Hackett.

Kolmogorov, A. N. (1933). *Grundbegriffe der Wahrscheinlichkeitsrechnung*. Berlin: Springer. English translation: *Foundations of the Theory of Probability*, ed. N. Morrison. New York: Chelsea Publishing, 1950.

Korsgaard, C. (1996). *Creating the Kingdom of Ends*. Cambridge: Cambridge University Press.

Kuhn, T. S. (1962). *The Structure of Scientific Revolutions*. Chicago: University of Chicago Press.

Lewis, D. (1981). "Causal Decision Theory." *Australasian Journal of Philosophy* 59: 5–30.

Lewis, D. (1996). "Desire as Belief II." *Mind* 105: 303–13.

Mackie, J. L. (1977). *Ethics: Inventing Right and Wrong*. London: Penguin.

McDowell, J. (1995). "Might There Be External Reasons?" In J. Altham and R. Harrison (eds), *World, Mind and Ethics: Essays on the Ethical Philosophy of Bernard Williams*, 68– 85. Cambridge: Cambridge University Press.

McNaughton, D., and P. Rawling (2003). "Descriptivism, Normativity and the Metaphysics of Reasons." *Proceedings of the Aristotelian Society*, supplementary vol. 67: 23–45.

McNaughton, D., and P. Rawling (2004). "Duty, Rationality and Practical Reasons." In A. Mele and P. Rawling (eds), *The Oxford Handbook of Rationality*, 110–31. Oxford: Oxford University Press.

Mulligan, K., and F. Correia (2013). "Facts." In E. N. Zalta (ed.), *The Stanford Encyclopedia of Philosophy* (Spring). <**http://plato.stanford.edu/archives/spr2013/entries/ facts/**>.

Nissan-Rozen, I. (2015). "A Triviality Result for the 'Desire by Necessity' Thesis." *Synthese* online, 1–22.

O'Connor, T. (2014). "Free Will." In E. N. Zalta (ed.), *The Stanford Encyclopedia of Philosophy* (Fall). <**http://plato.stanford.edu/archives/fall2014/entries/freewill/**>.

O'Neill, O. (1989). *Constructions of Reason*. Cambridge: Cambridge University Press.

**(p. 196)** Parfit, D. (1997). "Reasons and Motivation." *Proceedings of the Aristotelian Society*, supplementary vol. 71: 99–130.

Parfit, D. (2011). *On What Matters*. 2 vols. Oxford: Oxford: Oxford University Press.

Prichard, H. A. (2002) [1932]. "Duty and Ignorance of Fact." In H. A. Pritchard, *Moral Writings*, ed. J. MacAdam, 84–101. Oxford: Oxford University Press.

Prior, A. (1967). *Past, Present and Future*. Oxford: Oxford University Press.

Ramsey, F. P. (1988) [1926]. "Truth and Probability." In P. Gärdenfors and N. Sahlin (eds), *Decision, Probability, and Utility*, 19–47. Cambridge: Cambridge University Press.

Rawling, P. (2016). "Decision Theories for Internalist Realists." MS.

Schroeder, M. (2010). *Noncognitivism in Ethics*. London: Routledge.

Smith, M. (1994). *The Moral Problem*. Oxford: Blackwell.

Street, S. (2006). "A Darwinian Dilemma for Realist Theories of Value." *Philosophical Studies* 127: 109–66.

Street, S. (2009). "Evolution and the Normativity of Epistemic Reasons." *Canadian Journal of Philosophy*, suppl. vol. 35: 213–48.

Thomason, R. (1970). "Indeterminist Time and Truth-Value Gaps." *Theoria* 3: 264–81.

Van Fraassen, B. (1966). "Singular Terms, Truth-Value Gaps, and Free Logic." *Journal of Philosophy* 63: 481–95.

Van Fraassen, B. (1968). "Presupposition, Implication, and Self-Reference." *Journal of Philosophy* 65: 136–52.

Weirich, P. (2012). "Causal Decision Theory." In E. N. Zalta (ed.), *The Stanford Encyclopedia of Philosophy* (Winter). <**http://plato.stanford.edu/archives/win2012/entries/decision-causal/**>.

Williams, B. (1981). "Internal and External Reasons." In *Moral Luck: Philosophical Papers 1973–1980*, 101–13. Cambridge: Cambridge University Press.

Williams, B. (1995a). "Internal Reasons and the Obscurity of Blame." In *Making Sense of Humanity and Other Philosophical Papers 1982–1993*, 35–45. Cambridge: Cambridge University Press.

Williams, B. (1995b). "Replies." In J. Altham and R. Harrison (eds), *World, Mind and Ethics: Essays on the Ethical Philosophy of Bernard Williams*, 185–224. Cambridge: Cambridge University Press.

Wilson, G., and S. Shpall (2016). "Action." In E. N. Zalta (ed.), *The Stanford Encyclopedia of Philosophy* (Winter). <**https://plato.stanford.edu/archives/win2016/entries/action/** >.

## **Notes:**

[^000]: We have benefited from discussing this material with people too numerous to mention. However, we would like to acknowledge the helpful comments of Barry Maguire, who reviewed a draft of this chapter for Oxford University Press.

[^1]: This, it may be complained, conflates explanatory and motivating reasons. Unfortunately, space precludes our discussing this issue here; see Alvarez (2016).

[^2]: In order to avoid potential confusion, please note the following. We shall sometimes speak of an agent "having a reason" as shorthand for an agent "having a normative reason to do something." And sometimes we shall speak of the existence of reasons, by which we mean that there are normative reasons for agents to do things.

[^3]: We speak of *practical* normative facts to distinguish them from their theoretical counterparts—roughly speaking, the former are concerned with action, the latter with belief. And by "a normative fact" we mean one that has normative content—content that has a prescriptive element. Note that adverting to content is crucial here—normative facts can be picked out using non-normative vocabulary: for instance, "the first fact David thought of when waking today" might pick out the fact that he has reason to go into the office.

[^4]: See McNaughton and Rawling (2003), in which we also discuss descriptivism and supervenience in greater detail.

[^5]: See Mulligan and Correia (2013), on the "modal criterion" for further discussion.

[^6]: We say this is only the basic idea because the water is muddied by the fact that there may be practical reasons with normative content—recall our discussion of the simple twotier view and undeserved harm. However, as we noted, in any case of such a reason, there will be (we claim) non-normative facts that are equivalent to it as a practical reason. These non-normative facts can be substituted for such a reason in the relevant supervenience base, allowing matters to proceed as if all reasons were non-normative facts for the purposes of accounting for supervenience.

[^7]: We discuss these matters in more detail in McNaughton and Rawling (2004); see also the references listed there.

[^8]: Williams (1981: 102–3, 1995a: 36); see also Smith (1994: 156) and Parfit (1997: 100).

[^9]: Note that, as throughout this chapter, reasons are not "all-in" (Williams 1981: 104): One can have a reason to A whilst having stronger reasons not to.

[^10]: See section 7.4 for more on the error theory and this RE account.

[^11]: Or suffice for the agent to be motivated, in the absence of any independent desire. For the sake of simplicity, we set aside here the issue of whether such states motivate or, rather, constitute a state of being motivated.

[^12]: There are, of course, many different forms of "independence"—causal, modal, and rational, to name three. We take the view to be that D is independent of any *particular* beliefs in all these senses. But this is consistent with the view that D cannot be possessed by a being that lacks all beliefs about reasons.

[^13]: This might be challenged by someone who maintains that, when you believe that you have a reason to A, the state you are in either is or "contains" the state of your being motivated to A, where a state of being motivated is not a desire; and, indeed, the thought is that there is no desire required for motivation here—the belief plays both roles. Thus we seem to have a counterinstance to HBD. However, the belief obviously cannot play both roles with respect to one and the same content. You believe that you have a reason to A, but what you are motivated to do is A, not make it the case that you have a reason to A. Perhaps you can be motivated to A without having a desire to A, but, even if this is the case, your state of being motivated to A is at least desire-like in that it will be fulfilled if, and only if, you A (whereas your belief that you have a reason to A is "fulfilled" if and only if you have a reason to A). So even this view does not ultimately reject some version of HBD. Lewis (1996: 308, n. 4) takes "desires necessarily connected to beliefs," "beliefs that function as if they were desires," and "states that occupy a double role, being at once beliefs and desires" to be equivalent descriptions. We might quibble with this in some respects, but we would agree with Lewis to the extent that any differences are not relevant as far as HBD and HI are concerned.

[^14]: Smith (1994: 148) considers a similar proposal.

[^15]: Cf. Michael Smith's moral "fetish" objection (1994: 75).

[^16]: This is the famous "Frege–Geach problem'—see e.g. Schroeder (2010) for an account of this and other worries for the noncognitivist as they apply to ethics, and how she might respond.

[^17]: This complaint, as applied to ethics, is due to Mackie (1977).

[^18]: But not all. However, for the sake of simplicity we shall ignore cases where the reasons do not favor a unique course of action.

[^19]: This is a variant of one of Jackson's (1991) cases.

[^20]: This task is complicated by the fact that Prichard added various corrective notes at the end of "Duty and Ignorance of Fact" after its initial publication in 1932. These notes are published in Prichard 2002; and in laying out his view we have endeavored to take them into account.

[^21]: Ramsey (1988 [1926]: 44, n. 8), for example, sees credences as reasonable if they result from mental habits that "are conducive [ . . . ] to entertaining such degrees of belief as will be most useful." It is mental habits that are the primary objects of evaluation. This account has appealing features, but Ramsey is concerned with tier one credences—what about our tier two dispute with expressivists and error theorists? Members of the latter camps may well assign a credence of zero to any claim of the form "A has a reason to ϕ," and they no doubt see this assignment as resulting from their useful mental habit of reasoning correctly. But, of course, we see correct reasoning as yielding an opposing conclusion.

[^22]: Note that the reasonableness of a tier one degree of belief (such as that concerning the presence of traffic) is not a practical matter having to do with e.g. the potential costs of being incorrect. Those potential costs come in at tier two—they are factored into the reasonableness of degrees of belief about reason strength (such as the reasonableness of a high degree belief in the proposition that the presence of traffic is a very strong reason to slow down).

[^23]: Which Davidson also employs—see e.g. Davidson (2005: 67–73).

[^24]: Strictly speaking, perhaps, this should be a credence, but we won't go into that here.

[^25]: Many more details are developed in this paper. See also Nissan-Rozen (2015).

[^26]: If I believe I have a reason of strength j to A in two or more states, let Sj be their Boolean sum. And, to add a further complication, after finely individuating states as much as I can, there may stilI be states in which I do not believe that I have a reason of, say, strength j to A; rather, j might be the subjective expected strength of my reason to A in that state—i.e.

j = ∑ i.C(i is the strength of my reason to A in the state in question) i

Rj would then be the proposition that my reason to A is of *expected* strength j.

[^27]: See e.g. Lewis (1981) and Weirich (2012).

[^28]: On one approach, this result is derived from placing various constraints on rational preference (such as transitivity) and proving a representation theorem (see e.g. Weirich 2012).

[^29]: Note that [F*p* or not F*p*] is true on every branch, and hence is true *simpliciter*, as is [F*p* or F(*not p*)] (which is sometimes referred to as "future excluded middle"). ([F(not *p*)] is equivalent to [not F*p*] on this view.) Hence not only is excluded middle preserved, but future excluded middle is also.

[^30]: See e.g. Bennett (2003: 58, 104).

# 8. Psychologism and Anti-Psychologism about Motivating Reasons

*Eric Wiland*

### **Abstract and Keywords**

People do things for various reasons. Are these motivating reasons psychological? This question is the focus of this chapter. I argue here that such reasons are typically not purely psychological. Yet there is an important psychological element or aspect of these reasons. I proceed by first reviewing some arguments for and against psychologism about (motivating) reasons. Next, I do the same for the view that reasons are typically non-psychological facts. I then explore some additional alternatives: (a) disjunctivist views, (b) the appositional account, and finally (c) naïve action theory, which I favour. Naïve action theory transcends and preserves the best features of both standard psychologism and standard anti-psychologism.

Keywords: psychologism, motivating reasons, factualism, disjunctivism, Jonathan Dancy, naïve action theory

## **8.1 Introduction**

People do things for various reasons. Are these motivating reasons psychological? This question is the focus of this chapter. I argue here that such reasons are typically not psychological. Yet there is an important psychological element or aspect of these reasons.

Let's start with a humdrum example. Suppose Fred is searching for his bow tie. We might wonder what his reason for doing so is. Later, we learn that Fred is scheduled to impersonate George Will at a comedy club. Let's suppose there's nothing else funny about the case. We now seem to know what Fred's reason for searching for his bow tie is. But how are we to best characterize this reason? We might think that Fred's reason for searching for his bow tie is or involves some aspect of his own mind. One candidate is "Fred *wants* to wear his bow tie to the comedy club." Or, more complexly, "Fred *wants* to wear his bow tie to the comedy club, and he *believes* that he needs to search for his bow tie in order to wear it to the comedy club." The psychological details might not matter so much here. What matters is that his reason for action seems to be psychological.

But we might think about Fred's reason a different way: Fred is searching for his bow tie for the reason that he will be impersonating George Will at the comedy club tonight. And that's a fact. And it is also the reason he is looking for his bow tie. Indeed, if you were to ask Fred himself why he was searching for his bow tie, he might say something about the evening's event rather than his own mind. This suggests that the reason for which Fred acts is not psychological at all. It's a part of the (non-psychological) world.

So are motivating reasons for action psychological or not? Before we prosecute this debate, it's important first to pinpoint the target concept. We are discussing **(p. 198)** reasons for acting. There are reasons why things (including things such as actions) occur that are not themselves reasons for acting. For example, the reason why I yelled at my critic might be that I am very tired. But this reason, a reason why I yelled, is not itself a reason for which I yelled. At best, motivating reasons for action are a proper subset of reasons why actions occur. The two are not perfectly coextensive (see Alvarez 2009).

Further, a person can be motivated by things that are not themselves motivating *reasons*. And at least some of these motives are psychological attitudes. You might be motivated to clean your bathtub every day because you are afraid that your deceased mother will somehow criticize you for your slovenly ways. You are terrorized by memories of the way she disapproved of the way you kept your bedroom, and this terror is affecting you now. Your fear, however, is not a *reason* for which you are cleaning your bathtub. Nevertheless, your fear is motivating you to break out the scrub brush. Sometimes feeling, moods, desires, and emotions motivate us to do things, without thereby being reasons for which we do them. Those who deny that motivating reasons are psychological attitudes recognize that people can be motivated by psychological attitudes. They claim only that in such cases the psychological attitude isn't a motivating reason.

The kind of reason for acting investigated here, a motivating reason, is often distinguished from a normative reason for action (see Smith 1987, 1994). A normative reason for action *justifies* acting in a particular way. You might have a normative reason to clean your kitchen now. But you aren't cleaning your kitchen now; you are instead reading this chapter. It might be true that you have a normative reason to clean your kitchen even if you aren't the least bit motivated to do so, even if there is *nothing* you are doing for that reason. It appears that often people are not motivated to do what they have normative reason to do. Alas, alack. This is why it seems to make sense to distinguish normative reasons from motivating reasons.

But I also want to note that some (the author included) think that the distinction between motivating reasons and normative reasons distorts the phenomena. This distinction encourages the thought that there are two distinct kinds of reasons for action, whereas it might instead be true that there is only one kind of reason for action, and only some of these reasons motivate. The fact that only some reasons motivate does not itself entail that motivating reasons form a distinct class of reasons, no more than the fact that only some airplanes are operational entails that operational airplanes form a distinct class. I won't pursue this distinction further right here. (For more on this distinction, see the

Chapter 7 this volume by McNaughton and Rawling, as well as a brief discussion below.) In order to remain neutral about the propriety of the distinction, from now on, whenever I refer to reasons without any qualification, I mean to refer to what those who do draw this distinction mean by "motivating reasons."

I proceed by first reviewing some arguments for and against psychologism about (motivating) reasons. Next, I do the same for the view that reasons are typically non-psychological facts. I then explore some additional alternatives: (a) disjunctivist views, (b) the appositional account, and finally (c) naïve action theory, which I favor.

## **(p. 199) 8.2 Psychologism**

If there is a standard view about motivating reasons, it is psychologism. It seems that most philosophers hold that a person's reasons for action either are or essentially depend upon the psychological attitudes of the person whose reasons they are. It would help to examine a particular argument for a psychologistic view of motivating reasons.

Donald Davidson's (1963) is the most influential example of such a view. He held that a reason for action is a pair of related psychological attitudes. One of these is what he calls a pro-attitude. A pro-attitude is one of a wide variety of possible psychological stances, including "desires, wantings, urges, promptings, and a great variety of moral views, aesthetic principles, economic prejudices, social conventions, and public and private goals and values in so far as these can be interpreted as attitudes of an agent directed toward actions of a certain kind." That's quite a list. The second attitude is a belief that some specific action would satisfy this pro-attitude.

Davidson (1963: 686) then writes: "Giving the reason why an agent did something is often a matter of naming the pro attitude (a) or the related belief (b) or both; let me call this pair the primary reason why the agent performed the action." For instance, I might (1) want to turn on the light and (2) believe that if I flip this switch, I will turn on the light. When I flip the switch, my reason for doing so is just this pair of psychological attitudes, 1 and 2.

Reasons are pairs of psychological attitudes, Davidson thought, because only pairs of psychological attitudes can explain actions in the way that reasons do. When you act for a reason, your reason explains what you do. Any account of reasons should be able to capture this explanatory function of reasons for action. We can explain an action in the way reasons do just by citing the pair of psychological attitudes that explains your action.1

But why think that only psychological attitudes can explain action in this way? Davidson argues that an account of reasons needs to account for the following phenomenon. You can *have* two or more reasons for one and the same action, and yet *act* on only one of the two reasons. Thus only one of the several reasons you have is really a motivating reason; the rest are merely normative reasons. For instance, as Kant noted, you might charge your inexperienced customer the ordinary price either because it is honest to do so, or to

preserve your reputation for honesty, thereby earning the most money. You might *have* these two reasons. And yet it is possible to act only to preserve your reputation for honesty, and not at all for the reason that it is indeed honest. Davidson worried that an account of reasons for action that is purely "logical" or "justificatory" probably will not be subtle enough to distinguish between reasons that are **(p. 200)** genuinely explanatory and those that are idle. Reasons thus must be psychologically real in order to explain what reasons explain.

Here's a related argument for the same conclusion. Two people could be in the same circumstances, and yet act for different reasons. Since their circumstances are identical, the only way to explain how the two are acting for different reasons must involve something different about the people themselves: their psychological attitudes.

But we should be careful in drawing conclusions. These arguments do seem to show that psychological attitudes play *some* role in reasons explanations. But they do not by themselves demonstrate that reasons for action just *are* psychological attitudes, as Davidson claims.

Why think that these arguments fail to establish the more ambitious claim? We need to better understand the explanatory role that Davidson thought reasons play when they are cited in action explanation. Consider again the shopkeeper who charges his inexperienced customer the ordinary price. He does so for the reason that it preserves his reputation for honesty. But to say that this reason explains his action is just to say that this reason in some sense *causes* his action. In other words, the shopkeeper charged his inexperienced customer the ordinary price *because* doing so preserves his reputation for honesty. And so to understand what explains action in the way that reasons do, we must understand what can cause actions in the way reasons do. Reasons for action cause the actions that they are reasons for. And it seems that only psychological attitudes are poised to cause action in this way. To summarize:

- **(1)** One can have multiple reasons for some action.
- **(2)** One can act for only one of these reasons.
- **(3)** The best way to account for the difference between the reason one acts upon and
- the reasons one does not is that only the former reason causes the action.
- **(4)** A reason can cause an action only if the reason is psychological.

Let's evaluate each claim. The first seems highly plausible. If crude rational hedonism were true, then one would have only one reason for any action: (a desire for) pleasure. But reasons pluralism seems true.

The second claim seems plausible too. But it can be questioned. Suppose that reasons are just Davidsonian belief–desire pairs. Why, then, should we be certain that you can *have* such a reason that is in fact *entirely* motivationally inert? If psychological attitudes are characterized functionally, and if desiring is just a matter of being motivated, then it is ar

guable that one could not genuinely have a desire to V without this being at least slightly causally responsible for any V-ing that one does.

Here's a better argument against the second claim. Consider the case of multiple reasons for *belief*. Suppose that someone tells you it's now raining outside. Suppose also that you remember feeling the rain when you were outside a few moments ago. You thus seem to have two reasons to believe that it is now raining. If you really have both of these reasons, is it possible to believe that it is raining for only one of the two?

**(p. 201)** If you are unaware of one of the two reasons—possibly you failed to understand what the speaker said—then of course you might then believe that it is now raining for only the reason that you remember that it was raining a few moments ago. But then you really don't *have* the other reason. So this example does not show that you can believe something for only one of the reasons you *have*.

But let's imagine that you do have or grasp both reasons for believing that it is raining outside. Can't you still believe it for only one of them? We must be careful to distinguish the question "For what reason do you believe that?" from the superficially similar questions "For what reason did you start believing that?" and "How did you come to believe that?" A person may believe p for one reason, and later acquire a second reason for believing it, at which point she then believes p for both reasons. That she later believes p for both reasons is not contradicted by the fact that she came to believe p for only one reason. How she came to believe p, and for what reason(s) she now believes p, are not identical matters.

We must admit that we sometimes say things like "I believe p because of q, not r." But (a) sometimes this indicates only that the speaker does not take r to be a reason at all. Granting that does not show that the speaker failed to believe p for a reason she had. And (b) sometimes this claim means that q but not r is a *sufficient* reason for believing p. Granting that does not indicate that r is no reason for believing p at all. Finally, (c) sometimes the claim means that q is merely the most important reason for believing p. And that, of course, is compatible with r also being a reason for believing p. It seems that thinking about reasons for belief will not help us see that you can act for only some of the reasons you have.

I do think, however, there is a way to vindicate the second claim. To do this, we need to return to the case of action. Suppose the shopping mall closes in thirty minutes. You want to buy a scarf at the mall, so you have a reason to go there right now. You also want to return some shoes to a store at the mall, so you have a second reason to go there right now. But you know that you do not have enough time to do both things. So, you could go to the store for either reason. But it would be somewhat irrational or senseless to go to the mall for *both* reasons, this because you can't accomplish both ends. And since it would be irrational to go to the mall for both reasons, it must be at least possible to go to the mall for only one of them. Thus, it is possible to act for only one of multiple reasons for the same action, reasons that the agent fully grasps.2

Let's next look at the third claim, which says that the way to account for the difference between the reason one acts upon and the reasons one does not is that only the former reason *causes* the action. This claim specifies in virtue of what an agent can act for one reason rather than another: it is because only the one reason causes the action for which it is a reason. Reasons explanation is claimed to be a form of causal explanation.

**(p. 202)** Whether reasons for actions are causes of the actions for which they are reasons is a venerated philosophical topic, one we will be unable to resolve here. But it is perfectly natural to use expressions like "I am searching for my bow tie because I'm impersonating George Will tonight," expressions that link an action and a reason with a "because." And so there is at least a prima facie case that the link between the two is indeed causal.

Even so, there are causes and there are causes. One possibility is that a reason is an *efficient* cause of the action for which it is a reason. Another is that it is a *formal* cause of the action for which it is a reason.3 Yet another alternative but compatible possibility is that the reason is a *final* cause of the action for which it is a reason. Since the fourth claim above is based upon the third, we must be sure that both claims employ the same notion of causation. The fourth claim—that only psychological attitudes cause action—is most plausible if the type of causation in question is efficient causation. If an action has an efficient cause, it is most plausible that it is psychological in nature.

So let's understand the reference to causation in the third claim also as efficient causation: the best way to account for the difference between the reason one acts upon and the reasons one does not is that only the former reason *efficiently* causes the action. (Hereafter, "causation" means efficient causation unless otherwise qualified.) It is widely thought that this view faces a serious problem: a psychological attitude can cause an action even though the action was not performed for that attitude. If this is true, then the difference between a reason for which one acts and a reason one does not act cannot be that only the former causes the action for which it is a reason, since a reason for which one does *not* act for may nevertheless cause an action. Davidson himself recognized this problem, the problem of *deviant causal chains*. To illustrate, let's consider his own example.

A climber might want to rid himself of the weight and danger of holding another man on a rope, and he might know that by loosening his hold on the rope he could rid himself of the weight and danger. This belief and want might so unnerve him as to cause him to loosen his hold, and yet it might be the case that he never chose to loosen his hold, nor did he do it intentionally. (Repr. in Davidson 1980: 79)

The climber has a belief–desire pair that, if psychological attitudes are reasons, is a reason for loosening his hold on the rope. The climber's belief–desire pair causes him to loosen his hold on the rope. Yet the belief–desire pair is not a reason for which he loosened the rope; he did not loosen the rope for any reason—it was a mistake. But if reasons are just psychological states that together cause the kind of action mentioned in the be

lief, then it would be difficult to explain just why the climber's psychological states are *not* motivating reasons.

The problem of deviant causal chains has spawned a tsunami of literature (Stout 2010). This is not the place to review or even summarize this literature. Suffice it for now to say that it remains a worry for causal theories of action.

**(p. 203)** Perhaps the most promising response to this problem is a partners-in-guilt approach. *Many* notions are naturally understood as at least partially causal; for example, some perception is a memory only if it is caused by another perception with the same content. But clever philosophers can generate examples wherein the causation happens through some bizarre way, and thus the resulting perception is not a genuine memory. The solution to this general problem seems to be to specify *which* way an impression causes a memory, or here, which way a pair of psychological attitudes causes an action. Davidson himself observed that psychological attitudes must cause the action in the *right* way. But even if true, we still don't know what it *is* to be the right way. We should acknowledge that there is more work to do. If reasons are psychological attitudes that cause in the right way the action for which they are a reason, what *is* the right way? I suspect there is ultimately no way of providing a substantive answer to this question, as is suggested by the fact that there is still no generally agreed-upon solution to the problem of deviant causal chains.

But the case for psychologism depends not on whether an argument for it is airtight, but on whether the argument for it is better than the argument for any alternative view. So, let's turn to its rivals.

## **8.3 Factualism**

If we view the task of giving reasons for action as the task of explaining another person's action, it will be natural to do so by referring to her psychological attitudes. Psychologism and the third-person perspective mesh well.

Things look differently from the first-person perspective. If I am asked the reason for which I am (for example) looking for my keyring, I am apt to respond by saying something about the world rather than my own mind: "My class begins in a half hour." Our friend Fred above is likewise apt to respond to a reasons-question with something like "It's for my George Will costume" or "Tonight I'm performing at the comedy club." When you consider your own reason for acting, your attention typically focuses on the world, not yourself. Reasons appear to be non-psychological facts.

One reason to privilege the first-person standpoint is that intentional action itself is the sort of process or event about which the agent has unmediated knowledge (Anscombe 2000, Setiya 2007). When you are writing a letter to your brother, you know this without needing to *observe* what you are up to in the way that another person would. You don't need to see or guess what you are doing. You just know that you are writing a letter to

your brother. If you don't know that you are writing a letter to your brother, then you aren't writing a letter to your brother intentionally. Intentional actions, unlike other processes, are typically like this. And since the set of actions performed for reasons is identical to (or nearly exhausts) the set of actions performed intentionally, it is natural to think that the first-person perspective is likewise central to characterizing what it is to act for a reason. This supports the thought that what seems to the agent to motivate her is really what motivates her: facts about the world she faces.

**(p. 204)** One might be tempted to think that prioritizing the first-person perspective does *not* oppose psychologism. For whenever it appears to be true that an agent acts for some non-psychological reason ("He's looking for his bow tie because he's performing at the comedy club later"), some psychological version of this statement is still also true ("He's looking for his bow tie because he believes that he's performing at the comedy club later" and/or "He's looking for his bow tie because he wants to perform at the comedy club later"). But *this* fact by itself does not establish that reasons are indeed psychological; indeed, Thomas Nagel (1971) famously argued that the always-available psychological explanation depends upon the non-psychological explanation, rather than the other way around. Nevertheless, the fact that substituting a psychological explanation is always possible does play an important role in a larger argument favoring psychologism.

To see this, consider next the fact that agents are sometimes wrong about how things are. Fred might be looking for his bow tie despite the fact that he is confused about when he is scheduled to perform at the comedy club. Suppose he was really scheduled to perform last night! Even so, Fred is now looking for his bow tie for a reason. But it appears that he isn't doing so for the reason that he is performing at the comedy club tonight, since as a matter of fact, he is not. Fred may be *thinking* that he is searching for his bow tie because he is performing tonight, but if so he is wrong about what his reason is. Instead, it appears that Fred is searching for his bow tie merely because he *believes* that he is performing at the comedy club tonight. The fact that Fred believes this obtains whether *what* he believes is true or not, so his belief is available to serve as his reason in the case where he is indeed incorrect. His reason here seems to be psychological.

Let's put these two claims together. First, any reasons explanation that cites a fact as a reason implies the truth of a different explanation citing a psychological attitude as the explanans. Second, whenever someone acts for a reason, there is always a true explanation citing a psychological attitude, but not always a true reasons explanation citing a fact. That is, it is not the case that any explanation that cites a psychological attitude as an explanans implies the truth of a reasons explanation that cites a fact as a reason. Thus, explanations citing psychological attitudes, rather than non-psychological facts, seem more fundamental. This suggests that psychological attitudes are themselves reasons.

This appearance is reinforced if we focus upon the proximity of rival explanantia. Fred is searching for his bow tie because he is performing at the comedy club tonight and/or because he believes he is performing at the comedy club tonight. Even if we are tempted to go for only the former explanation, we must recognize that the explanans (he is perform

ing at the comedy club tonight) will motivate Fred only if he somehow cognitively grasps it. The explanans can't motivate Fred behind his back, as it were. So again, it seems Fred's reason for action is really something about his psychology. His psychological attitudes are in a way "closer" to the action to be rationalized than are the facts about which Fred has attitudes toward. Even if the facts distally explain his **(p. 205)** action, Fred's psychological attitudes proximately explain it. And the more proximate explanation can seem more relevant. Perhaps the Big Bang is the *ultimate* distal explanation for Fred's action. But when we ask for the reason for his action, we are asking about something much more proximate than that. His psychological attitudes appear to do the trick.

Arthur Collins (1997), however, has offered a powerful reply on behalf of the factualist. When Fred tells us that he is searching for his bow tie because he is performing at a comedy club tonight, *he* is not neutral about whether he is performing at a comedy club tonight. He is telling us that he *is* performing tonight. His explanation of his action is committed to *this*.

Now, it is indeed true that Fred could instead explain what he is up to with the words "I'm searching for my bow tie because I believe I'm performing at a comedy club tonight." That too is a satisfactory explanation. But, Collins argues, Fred does not thereby withdraw his commitment to whether he is performing at a comedy club tonight when *he* shifts to psychologistic language. Fred is still committed to the truth of the claim that he is performing at the comedy club tonight. That doesn't go away.

Inserting the words "I believe" into the explanation serves a very different function: it expresses a kind of epistemic fallibility. If Fred says "I'm searching for my bow tie because I believe I'm performing at a comedy club tonight," he thereby expresses the idea that he could be wrong about whether he is performing at a comedy club tonight. But it is one thing to acknowledge that one could be wrong. It is a very different thing to withdraw commitment altogether to the thing that one thinks one could be wrong about. Let's not confuse the two.

So no matter whether Fred explains himself by saying "I'm searching for my bow tie because I'm performing at a comedy club tonight" or by saying "I'm searching for my bow tie because I believe I'm performing at a comedy club tonight," he is committed to the truth of the claim that he is performing at a comedy club tonight. That commitment does not disappear merely by his introducing "I believe" into the explanans.

Of course, if *another* person explains Fred's action by use of the form "Fred believes ____," *she* is not thereby committed to what Fred himself is. She can remain completely neutral about whether things are as Fred believes them to be. But, Collins concludes, this just shows that the third-person and the first-person use of psychological language in the explanans of an action explanation differ from each other. And so, even though the thirdperson use of psychological language in the explanans of an action explanation takes no stand upon how things are outside the mind of the agent who is acting for a reason, the first-person standpoint remains stubbornly committed to explanantia that involve the world. Thus, so long as we think that the first-person perspective is the perspective from

which reasons for action come into view, an agent's reasons for action will not typically involve his own state of mind.

Even if Collins is right, however, we still need some way to understand the nature of the reason for which an agent acts when her belief is in fact false. Disjunctivist views offer us one way to think about this.

## **(p. 206) 8.4 Disjunctivism**

Perhaps when Fred falsely believes that he is performing at the comedy club tonight, his reason for action is some psychological attitude(s) of his. But when Fred knows that he is performing at the comedy club tonight, his reason for action is not some psychological attitude, but the world to which he is responding. Call this view *reasons disjunctivism* (see Dancy 1995b, Stout 1996). This view holds that in the normal case where the agent's views are correct, reasons are the facts to which the agent responds. But in the comparatively unusual case where the agent's view is incorrect, her reason is as psychologism holds. Of course, when the agent's relevant belief is false, she will also be mistaken about what her reason is. But that seems appropriate. So reasons disjunctivism sees reasons in two very different ways: facts in the normal case, and psychological attitudes only in the unusual case.

A psychologistic rejoinder to reasons disjunctivism takes issue with the way the form of the explanation varies with the truth of the agent's beliefs. Bernard Williams (1981), for instance, argued that the true/false distinction should not affect the form that reasons explanation take. In other words, when an agent acts in light of something she believes falsely, it seems we *have* to cite her belief in order to give her reason for so acting. Only her false belief seems to be available to explain her action. Williams argued (well, asserted) that if we must cite the agent's psychological states as her reason when the agent's beliefs are *false*, then we must also go psychological when they are true. Why think that the proper *form* of the explanation is radically different when the agent's belief is true and when it is false? The truth-value of the belief seems irrelevant to the issue about what form the reasons-explanation of her action should take.

Here are three distinct replies to Williams' argument. The first is a partners-in-guilt strategy. Disjunctivism is a respectable and plausible view in many other areas of philosophy, most notably in the case of perception (Haddock and Macpherson 2008). The fact that in cases of hallucination we do not see external objects does not imply that we fail to see external objects in all cases. Different cases sometimes call for different kinds of explanation.

A second and related reply takes issue with the way psychologism understands the case of error. Perhaps when Fred is mistaken about which night he is performing, the psychological attitude that explains his action is not a reason for his action at all. The explanation citing his psychological attitude, it may be argued, is not a *reasons* explanation, but a different sort of explanation. His psychology surely explains why he acts as he did, but perhaps there was *no* reason for which acted. We already recognize ways psychological attitudes explain action other than by citing motivating reasons for them: there are Freudian explanations, addictive explanations, and behavioral economic explanations. Perhaps *reasons* for action are always non-psychological, but whenever we have to explain an action by mentioning a false belief, we have left the field of reasons for action altogether.

**(p. 207)** A third distinct reply zeroes in on why we are tempted to go psychological in the first place (Wiland 2003). Because Fred could be wrong about whether he is performing at the comedy club tonight, it seems we need to cite a reason for his action that works even if the world does not match Fred's belief, even if he believes falsely. Even if Fred never *in fact* believes falsely, it is the *possibility* of error that pushes us to look inside Fred's mind to identify what is motivating him. But a moment's reflection should reveal why this fails to establish psychologism. Fred can be wrong not only about whether he is performing at the comedy club tonight, but also about nearly *any* aspect of his mind that might seem to serve as a reason for action. If the possibility of error disqualifies non-psychological facts from being genuine reasons, it should disqualify psychological facts too. But where would that leave things? This shows that the possibility of error does not in fact favor psychologism. Perhaps reasons disjunctivism, then, is indeed a solution, so that the form of a reasons explanation can vary with the truth of the agent's beliefs.

So far we have considered the idea that reasons for action are psychological attitudes, that reasons for actions are facts, and a disjunctivist hybrid of the two. It's time to get some more options on the table.

## **8.5 The Appositional Account**

Jonathan Dancy has developed a very distinctive view of the nature of reasons for action, one he calls "the appositional account" (2003: 128). According to this account of reasons, the reason in question is *what* the agent believes, but not his believing it. To illustrate, reconsider Fred. Dancy holds that Fred is looking for his bow tie because he is performing at the comedy club tonight, as he (Fred) believes. The phrase "as he believes" here functions paratactically; it isn't part of the reason, but is merely attached to it. It indicates that the reason for which Fred is acting is also something that Fred believes, but Fred's believing it isn't what makes it a reason. Still, it is part of the explanation for why Fred is searching for his bow tie, even though it isn't the *reason* part of it.

One odd feature (or bug) of the appositional account is that the reason for which someone acts need not be true. That is, on Dancy's view, the reason Fred is looking for his bow tie is that he is performing at the comedy club tonight, even if it is not true that Fred is performing there tonight—even if Fred is getting that matter wrong. In this respect, the appositional account differs markedly from its rivals (Dancy 2003: 131–7).

According to psychologistic views, Fred's reason is at least in part *his belief that* he is performing at the comedy club tonight. And even if his belief is false, even if he is not performing at the comedy club tonight, it is still true that Fred believes that he is. Since psychologism maintains that his reason is in part his belief, then the reason is something that is the case. Likewise with reasons disjunctivism. In the ordinary case, where Fred isn't mistaken about the club schedule, his reason for action is something about the world, something which indeed obtains. In the case where Fred is mistaken about the club schedule, his reason is, as psychologism says, his psychological attitude, **(p. 208)** again something which is the case. In no instance is Fred's reason something that is not the case. Psychologism and reasons disjunctivism are alike in that they take reasons explanations to be *factive*. They both hold that the explanantia must be true.

The appositional account, by contrast, holds that the explanantia of reasons explanations are non-factive: they need not be true in order to explain the actions for which they are reasons. Fred's reason for searching for his bow tie is that he is scheduled to perform at the comedy club tonight, *even when he isn't*. But how can something that is not the case explain and thus be a reason for something that is the case?

Dancy appreciates how odd this sounds. He attempts to mitigate the oddness by pointing to other examples of nonfactive explanations (2003: 136). Suppose Clara is imprisoned for robbing a bank. Clara maintains she was innocent. Still, if someone asks her why she is imprisoned, she could truthfully reply, "For robbing a bank." To reply this way may pragmatically imply that that she indeed robbed a bank. But this reply does not assert that she robbed a bank, for she also can sensibly say, "I am imprisoned for robbing a bank, but I didn't rob a bank." The fact that she can sensibly add the clause "but I didn't rob a bank," thereby cancelling any presupposition to the contrary, reveals that the original explanation ("for robbing a bank") is consistent with the fact that she did not rob a bank. The original explanation is thus non-factive. And if *this* kind of non-factive explanation is palatable, then, Dancy concludes, non-factive reasons explanations should be too.

I admit non-factive explanations are sometimes benign. In the imprisonment example, it does seem acceptable for Clara to explain her imprisonment by saying "for robbing a bank." But it would sound much stranger for Clara to shift from using this adverbial phrase to using a clause. That is, suppose now Clara were to utter "I am imprisoned because I robbed a bank, but I didn't rob a bank." That sounds, at a minimum, infelicitous. And so since reasons explanation are canonically expressed by use of a "because" and a clause, I suspect that reasons explanations must be factive after all.

It's a thorny issue. Much of it has to do with the relation between motivating reasons (our topic) and normative reasons. What justifies imprisoning Clara, if anything, is that she robbed a bank. If she robbed a bank, we might say that there is a normative reason to imprison her, even if no one imprisons her for this reason. And if she didn't really rob a bank, then nothing justifies imprisoning her: there is no normative reason to lock her up. When we say "Clara was imprisoned for robbing a bank," we are engaging a perspective from which her robbing a bank justifies imprisoning her. That is the ground for imprison

ing her, and not the fact that she also is, say, the President's nemesis. Note that even if what really motivates her accusers and jurors is the fact that she is the President's nemesis, it can still be true that she is imprisoned for robbing a bank (even assuming that she did rob it). My point is that the phrase "for robbing a bank" seems to express what justifies (or purports to justify) her imprisonment, and not necessarily what best explains why she is imprisoned.

Recall I have been treating motivating reasons as a topic in its own right, possibly distinct from the topic of normative (or justificatory) reasons. Most do. Treating the two separately encourages the conclusion that while normative reasons are objective and **(p. 209)** nonpsychological, the reasons that motivate individuals are psychological. But Dancy (1995a, 2003) argues that this greatly exaggerates the difference between motivating reasons and normative reasons. He allows that sometimes people are motivated by things that fail to justify their actions. And he also allows that often people are not motivated by the reasons that would justify a course of action not taken. But these facts do not license the conclusion that motivating reasons and normative reasons occupy different metaphysical categories. Dancy argues instead that there are just plain old reasons, reason that can either motivate and/or justify the actions they are reasons for (see also Heuer 2004).

Compare reasons to birds. Not all birds fly. Not all birds chirp. But it would be a mistake to think that chirping birds and flying birds are two very different kinds of things, each occupying a different metaphysical category. It's just that while most birds chirp and most birds fly, not all do both. Dancy sees reasons much the same way. Although not all reasons motivate, nor do all reasons justify, the reasons that do motivate and the reasons that do justify are of the same kind.

Remember that we are now considering the relation between motivating reasons and normative reasons because we are evaluating Dancy's non-factive view of reasons. The nonfactive view of reasons seems most plausible when we think about other non- factive explanations, such as the one about Clara's imprisonment. This "explanation" seems to really give the purported justification for her imprisonment. So here are two features of the explanation involving Clara: (1) it is non-factive, and (2) the way it explains is by offering a justification of sorts. Now Dancy compares reasons explanations to explanations like the one involving Clara. He maintains the counterintuitive view that reasons explanations are non-factive. But he also holds that the motivating and the justifying functions of reasons are not sharply distinct. So reasons explanations, as Dancy sees them, resemble explanations like that involving Clara in both of these ways. The non-factivity of (motivating) reasons and the link between motivation and justification are thus mutually reinforcing. Given that Dancy goes for one, it's no surprise he goes for the other.

Dialectically, however, this works against him. Most philosophers doubt that reasons explanations are non-factive. Most also separately sharply the motivational and the normative. So it's no surprise that those who separately sharply the motivational and the normative also insist that reasons explanations are always factive, especially if these two posi

tions mutually support each other. This hardly shows that the appositional account is incorrect. Perhaps we've reached a stalemate.

## **8.6 Naïve Action Theory**

But there is another way to understand the nature of the reasons for which we act. Earlier I was rather vague and indeed sloppy when discussing the view that the reasons for which we act are in the world, rather than psychological attitudes. For there are different **(p. 210)** ways that reasons can be "in the world." One way is to characterize reasons as elements of the world that typically make no essential reference to the agent whose reasons they are. For example, Dana might give John a hand because John needs help. "John needs help" is (purportedly) a fact, a fact that doesn't essentially involve Dana, even though it is a way to characterize the reason for which she acts. Often, non-psychological reasons may be expressed this way.

But there is a very different way to treat reasons non-psychologically. Some argue that reasons for action are just *other* actions, other actions performed by the same agent. I often find when I introduce this idea to another philosopher, his or her face undergoes multiple interesting contortions before verbally responding, no matter whether that response turns out to be positive or negative. So let me explain.

Often one natural way to express your reason for doing something is to describe how doing it fits into or serves some larger or longer or more general action you are also doing. The chicken is crossing the road because it is (thereby) getting to the other side. I'm buying some balloons because I'm throwing a retirement party. She's tugging on her earlobe because she is signaling her partner. In each of these examples, the agent is doing the first thing for the reason that she is doing the second thing. Michael Thompson (2008, 2011), the person most responsible for formulating this view, calls it *naïve action theory*. I am fine with that name, although I want to emphasize that naïve action theory is not merely a theory about what actions are, but also a theory about what a reason for action is.

According to naïve action theory, the actions that are reasons relate in multiple different ways to the actions for which they are reasons. Sometimes, they are ends for which the action to be rationalized is a means. Buying balloons is a means to the end of throwing a retirement party. Sometimes, they are parts of the actions that rationalize them. Writing the letter "a" is a part of writing the word "action." Sometimes, they are more general ways of describing some conventional action. Tugging on your earlobe is a way of signaling your partner. In each case, the actions they rationalize are all means, parts, phases, and/or other descriptions of them. The two actions thus all bear some sort of relation to one another—a relation that makes the reason relation between them also obtain.

Each of these reasons is an action with imperfective aspect, represented in English with the progressive. The reasons listed above are buy*ing* an omelette, writ*ing* the word "action," and signal*ing* your partner. These are all actions in progress, rather than completed

actions. And the actions they rationalize are (typically) going on at the same time as they are.

One attractive feature of naïve action theory is that it echoes one prominent psychologistic view about reasons for belief. Some have thought that the only thing that could be a reason for belief is another belief (Davidson 1986). When we believe things for reasons, we do so for other beliefs. (I don't think this is quite correct, but let's set that aside.) If reasons for beliefs are other beliefs, then the thought that reason itself is unified **(p. 211)** would pressure us to think likewise that reasons for actions are other actions. Perhaps reason relates things of *like kinds* to each other (Wiland 2003).

Is naïve action theory itself psychologistic? It seems not, since on its view reasons for action are not psychological *attitudes*. But reasons are not *completely* non-psychological either. Rather, according to naïve action theory, reasons are just as psychological as intentional action is. But how psychological is that? On the one hand, intentional actions are typically events or processes that take place in the world. They aren't just in the mind. On the other hand, some event or process qualifies as an intentional action only if its agent knows she is so acting. Nicole isn't drifting onto the shoulder of the road intentionally unless she knows that she is. So there is always a psychological element or aspect of intentional action.

This much is already fairly well known and understood. But it is also important to see how an agent's psychology is engaged not only in the intentional action to be rationalized, nor only in the intentional action that does the rationalizing, but also in the nexus between the two. Consider: you are reading this paragraph—intentionally, and so you know that you are. You are also reading this chapter—intentionally, and so you know that too. But you also know, in exactly the same way, that you are reading this paragraph *because* you are reading this chapter. That is, you know the nexus between the two, the nexus that makes it the case that the one *is* your reason for the other. You don't need to figure that out by means of observation, psychoanalysis, or guesswork. Your psychology is thus engaged by the entire nexus of descriptions of intentional actions whose form bears the mark of practical reason. And so, while reasons themselves are worldly processes, like making a quiche or filling a cavity, they wouldn't be reasons were it not for the way intentional agency constitutes their relation to the actions for which they are reasons.

Reasons for action understood as intentional actions, then, are both psychological and world-involving. (It might be fruitful to treat intentional action the way Timothy Williamson treats knowledge, as something both psychological and factive, but which cannot be factored neatly into an inner and an outer part.) To my mind, there is something satisfyingly Hegelian about the way naïve action theory sublates psychologism and antipsychologism.

I'll conclude by conceding that the metaphysical picture lying behind naïve action theory can look rather odd. Circularity and regress problems threaten. First, the circularity problem. If the reason for your A-ing is that you are B-ing, and your reason for your B-ing is that you are C-ing, and the reason for your C-ing is that you are A-ing, then your reasons for action loop back upon themselves. That would be very strange.

The circularity problem is avoided if there are no such loops. But then there might be a regress problem. If the reason for your A-ing is that you are B-ing, and your reason for your B-ing is that you are C-ing, and the reason for your C-ing is that you are D-ing, and this series never stops, then it appears you are doing an infinite number of things. This seems very unlikely. At best, it too would be very odd.

**(p. 212)** Both the circularity and the regress problems are avoided if the chain of actions that are reasons *stops* at some point. If the reason for your A-ing is that you are B-ing, and your reason for your B-ing is that you are C-ing, and the reason for your C-ing (and for many or all of your *other* actions) is that you are Z-ing, and there is no further reason for why you are Z-ing, the above problems are all dodged. Perhaps Z-ing is just your life: one very big action! But this too seems strange. Defenders of naïve action theory still need to explain how it can make sense to think that your life is the reason for which you do pretty much everything else.4 *Eudaimonia* played just this role in ancient philosophy. Whether it can still plausibly play this role remains an open question for us.

## **References**

Alvarez, M. (2009). "How Many Kinds of Reasons?" *Philosophical Explorations* 12(2): 181– 93.

Anscombe, G. E. M. (2000). *Intention*, 2nd edn. Cambridge, Mass.: Harvard University Press.

Collins, A. W. (1997). "The Psychological Reality of Reasons." *Ratio* 10(2): 108–23.

Dancy, J. (1995a). "Why There Is Really No Such Thing as the Theory of Motivation." *Proceedings of the Aristotelian Society* 95: 1–18.

Dancy, J. (1995b). "Arguments from Illusion." *Philosophical Quarterly* 45: 421–38.

Dancy, J. (2003). *Practical Reality*. Oxford: Oxford University Press.

Davidson, D. (1963). "Actions, Reasons, and Causes." *Journal of Philosophy* 60: 685–99.

Davidson, D. (1986). "A Coherence Theory of Truth and Knowledge." In E. LePore (ed.), *Truth and Interpretation: Perspectives on the Philosophy of Donald Davidson*, 307–19. Oxford: Blackwell.

Haddock A., and F. Macpherson (eds) (2008). *Disjunctivism: Perception, Action, and Knowledge*. Oxford: Oxford University Press.

Heuer, U. (2004). "Reasons for Actions and Desires." *Philosophical Studies* 121(1): 43–63.

McDowell, J. (1979). "Virtue and Reason." *The Monist* 62(3): 331–50.

Nagel, T. (1971). *The Possibility of Altruism*. Oxford: Oxford University Press.

Norman, R. (2001). "Practical Reasons and the Redundancy of Motives." *Ethical Theory and Moral Practice* 4(1): 3–22.

Schroeder, M. (2008). *Slaves of the Passions*. Oxford: Oxford University Press.

Setiya, K. (2007). *Reasons Without Rationalism*. Princeton, NJ: Princeton University Press.

Smith, M. (1987). "The Humean Theory of Motivation." *Mind* 96(381): 36–61.

Smith, M. (1994). *The Moral Problem*. Oxford: Blackwell.

Stout, R. (1996). *Things That Happen Because They Should*. Oxford: Oxford University Press.

Stout, R. (2010). "Deviant Causal Chains." In T. O'Connor and C. Sandis (eds), *A Companion to the Philosophy of Action*, 159–65. Chichester: Wiley-Blackwell.

Thompson, M. (2008). *Life and Action: Elementary Structures of Practice and Practical Thought*. Cambridge, Mass.: Harvard University Press.

Thompson, M. (2011). "Anscombe's *Intention* and Practical Knowledge." In A. Ford, J. Hornsby, and F. Stoutland (eds), *Essays on Anscombe's* Intention, 198–210. Cambridge, Mass.: Harvard University Press.

**(p. 213)** Wiland, E. (2003). "Psychologism, Practical Reason and the Possibility of Error." *Philosophical Quarterly* 53(210): 68–78.

Wiland, E. (2012). *Reasons*. London: Continuum.

Wiland, E. (2013). "In the Beginning Was the Doing: The Premises of the Practical Syllogism." *Canadian Journal of Philosophy* 43(3): 303–21.

Williams, B. (1981). "Internal and External Reasons." In *Moral Luck: Philosophical Papers 1973–1980*, 101–13. Cambridge: Cambridge University Press.

## **Notes:**

[^1]: A weaker psychologistic position makes no claims about what reasons *are*. Instead of making any metaphysical claims, it asserts only the biconditional: you have a (motivating) reason to V if and only if you have certain psychological attitudes involving V-ing. See Schroeder (2008).

[^2]: Note that constructing a parallel argument for reasons for belief seems not to be available. The above argument I also rehearse in some more detail in Wiland (2012).

[^3]: For more on this view, see Anscombe (2000: sect. 47 in light of sect. 42). [^4]: Wiland (2013) begins this task.

--- 

# 9. Reasons and Action Explanation

*Benjamin Wald and Sergio Tenenbaum*

### **Abstract and Keywords**

The problem of deviant causation has been a serious obstacle for causal theories of action. We suggest that attending to the problem of deviant causation reveals two related problems for causal theories. First, it threatens the reductive ambitions of causal theories of intentional action. Second, it suggests that such a theory fails to account for how the agent herself is guided by her reasons. Focusing on the second of these, we argue that the problem of guidance turns out to be related to a number of other issues in the literature on action explanation, and that it is much more general: it threatens not only causal theories but any theory of action. Finally, we suggest that a certain version of the view that acting has a constitutive or formal aim can overcome this problem.

Keywords: constitutive aim, practical reason, philosophy of action, action explanation, causal theories of action

## **9.1 Introduction**

In providing an intentional explanation of action, we cite the agent's reasons for action. Since Davidson's seminal "Action, Reasons, and Causes" (1967), the relation between these reasons for action and the explanation of intentional action has been at the forefront of philosophy of action. Davidson's answer to the question was, at least in broad outlines, widely embraced, and very quickly became the mainstream view in action theory. In a nutshell, according to Davidson, a reason for action both rationalizes and causes the action; this view has become known as the "standard account" or the "standard story" of action. Davidson immediately realized that such an account cannot easily become a reductive account of intentional action. Actions can be caused by beliefs and desires that rationalize the action while obviously failing to be a case of an intentional action done for that reason; in these cases the reasons that potentially rationalize action are said to cause the action in a "deviant" way. The problem of deviant causation has been one of the more serious obstacles for a proper causal theory of action. In this chapter, we first examine the advantages and difficulties of the causal theory. Investigating the problem of deviant causal chains reveals that there are in fact two related problems faced by a causal theory

of action. First, the problem of deviant causation shows that it is difficult to come up with a reductive account of intentional action that understands intentional actions as actions caused by mental states. Second, there is the problem that such a theory seems to fail to account for how the agent herself is guided by her reasons, what we call "the problem of guidance." Solving the problem of guidance will not on its own resolve the problem of causal deviance. However, addressing this problem is a precondition for a solution to the problem of causal deviance, since part of what an account of the right kind of causal link between attitudes and action must do is show how this causal link ensures that the agent guides the resulting action. Furthermore, we argue that the problem of guidance is **(p. 215)** related to a number of other issues in the literature on action explanation, and that it is much more general; it threatens not only causal theories but any theory of action. Finally, we try to suggest that a certain version of the view that acting has a constitutive or formal aim can overcome this problem.

## **9.2 Causal Theories and the Problem of Deviance**

One point of agreement among many otherwise disparate theories of action explanation is that action is explained by citing the agent's reason for acting, offering what is referred to as a "rationalizing explanation." However, it is less clear how the reason for acting serves to explain the action. What form of explanation is at work here? On the standard story introduced by Davidson, action explanation is a form of causal explanation, and thus the agent's reason for action plays a role in the causation of the action. On Davidson's view, actions are explained by citing a belief and a desire, or more generally a pro-attitude, that jointly cause and rationalize the action. We explain my going to the fridge by my desire to drink a beer and my belief that there is beer in the fridge, which jointly cause my going to the fridge.1

The causal theory of action has a number of benefits. It brings action explanation under the familiar heading of causal explanations, making clear how the agent's reasons are relevant to the explanation of action. Furthermore, it makes clear how we can differentiate the various reasons that an agent might have had from the one he or she acted on. Suppose Jay, a Scrabble aficionado, needs to vote on which of the shortlisted candidates will be offered a job in the Philosophy Department at University U. Jane is clearly the best philosopher among the candidates, but she is also an excellent Scrabble player. Both the fact that Jane is an excellent Scrabble player and the fact that she is the best philosopher in the pool rationalize the action. If any consideration that rationalized (or justified) an action counted as a reason the agent acted on, we would have to say that Jay voted for Jane *both* because she was an excellent Scrabble player *and* because she was the best candidate for the University U position. But it is at least possible that only one of them was *his* reason to vote for Jane; that is, it is possible that only one of them *explains* his voting for Jane. For instance, Jay might have taken no account of Jane's Scrabble skills, or he might have been so keen on having a suitable Scrabble opponent that no other considera

tions made a difference to his vote. The causal theory of action has an easy answer to the question "Which of the considerations that rationalize my action were the reasons that I acted on?" According to the causal theory, only belief–desire pairs that actually caused my action explain what I did. If we can have more than **(p. 216)** one reason for action, causal accounts seem well positioned to explain both how this is possible and the different extents to which the different reasons explain our actions (cf. Arpaly and Schroeder 2014).

Some philosophers have accused the causal theory of action of psychologism (cf. Dancy 2003). That is, the causal theory seems to imply that only my mental states can be reasons for action. But psychologism seems obviously false: the fact that, for instance, my best friend is in London can be reason for me to go to London, but my friend being in London is a fact about my friend, not about my mental states. However, it is a mistake to think that the causal theory of action requires that all our reasons for actions be mental states. A causal theory of action requires that the existence of certain mental states is implied by each genuine case of intentional action, but it is not committed to the view that reasons are mental states (cf. Davis 2010, Setiya 2007). Indeed, Davidson himself never says that the reasons for which we act are mental states. He says that primary reasons are mental states, and that "[i]n order to understand how a reason of any kind rationalizes an action it is necessary and sufficient that we see, at least in essential outline, how to construct a primary reason" (Davidson 1980: 4). "Primary reason," however, is a technical philosophical term, and need not line up with our everyday notion of the agent's reason. In other words, the reasons for which we act need not be mental states, but they will rationalize, and hence explain, our actions via primary reasons, which are belief–desire pairs. My reason for going to the fridge can be to get a beer, or perhaps that there is beer in the fridge, and neither of these names mental states. Still, my reason only rationalizes my action because it is represented by my belief and desire, and these cause my actions. Mental states are not themselves our reasons for action, but they are what allow facts about the external world to be our reasons for action.

However, the causal theory of action faces a significant challenge: namely, the possibility of deviant causal chains. A deviant causal chain occurs when a belief and a desire cause a bodily motion, and the bodily motion is of the right sort to be rationalized by the belief and desire; but the way in which the causation occurs seems incompatible with the agent having acted, or at least with the belief–desire pair in question being the primary reason for the action. Davidson's example is of a climber who desires to relieve himself of the burden of a fellow climber whom he is supporting via a rope, and who believes that he can relieve himself of this burden by loosening his grip on the rope. His coming to have this belief and desire makes him so nervous that he does end up loosening his grip on the rope (Davidson 1980). Here the belief and desire that would rationalize the action have indeed caused his bodily motion, but they have done so in a non-standard way. Intuitively, the climber's beliefs and desires in this case do not provide a rationalizing explanation of the action of letting go of the rope; in fact, it seems that "letting go of the rope" should not be classified as an intentional action at all. The challenge is to develop a causal account that does not incorrectly classify the bodily motions that stem from deviant causal

chains as actions. Davidson himself did not think that the problem of deviant causation could be solved, but he did not think that this was a fatal blow to the theory. According to Davidson, the belief and desire must cause the action in the right way, but he claims that he "despair[ed] of spelling out […] the way in which attitudes **(p. 217)** must cause actions if they are to rationalize the action" (Davidson 1980: 79). However, unless we can specify of what counts as "causing in the right way," we cannot avoid the suspicion that these theories are leaving out a central part of an account of acting for reasons: how reasons guide the agent in intentional action.

The literature on deviant causal chains is huge, far too large to be discussed in detail here. However, let us briefly consider some of the proposed solutions. Christopher Peacocke has provided an attempt to give a purely causal specification of the right kind of cause. On his view, the intention must not just cause but also differentially explain the action—a suggestion also adopted with further caveats by John Bishop (Peacocke 1979, Bishop 1989). A cause differentially explains its effect when, roughly, there is a function that relates a feature of the cause to a feature of the effect. For instance, there is a function that maps the degree to which a dimmer is rotated to the amount of current that travels through a lightbulb, and hence to the amount of light produced, and so the degree to which the dimmer is rotated differentially explains the brightness of the bulb. More formally, we have a simple case of differential explanation when the following formula holds:

where n ranges over numbers, t over times, k() is a numerical function. Consider an ordinary action: I take a drink of water. Then x is a drinking of water (F) and x is caused by a desire to drink water (G) with an intensity n at time t. X is then also a drinking of a specific quantity of water (H) at time t + δt, where the quantity drunk is determined by a mathematical function on the intensity of the desire (K(n)). Thus, since the desire differentially explains how much water I drink, it causes my action non-deviantly. On the other hand, consider a case of deviant causation such as Davidson's climber. According to Peacocke and Bishop, we would explain the deviancy of this case by the fact that the climber's desire to rid himself of the excess weight does not differentially explain any feature of his dropping of the rope. He drops the rope through nervousness, and it seems reasonable to hold that the precise way in which he drops the rope, the speed with which he opens his hand, and so on, is not sensitive to any feature of his desire; it would have been identical even if it had been the result of a slightly different desire.2

However, it is not clear that this account succeeds in ruling out all cases of deviant causation. All that differential explanation requires is that there be some function relating features of the cause to features of the effect. But there may well be some such function even in cases of deviant causation. Perhaps the strength of the desire, which we could express numerically, determines via a numerical function the intensity of the tremors that shake the climber. Indeed, as Scott Sehon (1997: 207) points out, the function could just be a constant function, mapping every variety of nervousness to the **(p. 218)** same drop

ping of the rope. The existence of such a numerical function would clearly not render his action intentional.3

In response to worries like this, Peacocke adds the requirement to state that the cause must strongly differentially explain the effect, where strongly differential explanations are such that we can recover the conditions of the cause from the effect—in other words, the function relating cause to effect is one-to-one (Peacocke 1979: 79–80). However, it is not clear that this helps. It is certainly conceivable that in a particular case of deviant causation each possible desire is paired up with a slightly different bodily motion. Furthermore, this requirement seems too strong. It seems perfectly possible that slightly different desires should result in the same bodily movement with the outcome still being an intentional action. To take Sehon's example, imagine a pitcher with great control over the speed of his pitches, and a maximum pitching speed of 75 mph. His intention for how fast to throw the ball will differentially explain the ball's speed. If he intends to throw it at 60 mph, the ball will move at 60 mph; if he intends to throw it at 40 mph, it will go at 40 mph; and so on. Now imagine that he intends to pitch the ball at 75 mph, and does so. The problem is that, since his top speed is 75 mph, had he intended to pitch the ball at 80 mph, it still would have gone at 75 mph. So the function from his intentions to the balls speed is not one-to-one, but it still seems clearly intentional (Sehon 1997: 209). The Peacocke/Bishop account seems to getting at something important missing from Davidson's view: it's not clear how in Davidson's account the agent is *guided* by her reasons (more on this below). The Peacocke/Bishop account might seem to give a more robust account of some sort of guidance: differences in the content of the agent's attitudes will result in systematic differences in the action. However, the objections above suggest that it cannot capture this idea properly.

Kieran Setiya offers a promising solution to causal deviance, invoking exactly the idea of guidance (Setiya 2007: 32–3; see also Frankfurt 1978). According to Setiya, what distinguishes a deviant cause from a non-deviant cause is that a non-deviant cause not only initiates an action but continues to guide that action throughout its performance. As Setiya puts it, "if I do something with the end of doing, I must have a plan for doing φ, by performing that action, and I count as doing φ, intentionally just in case I do it in accordance with my plan" (Setiya 2007" 32).4 So, for the climber example, the problem is that the momentary loosening of one's grip from nervousness may cause one to let go of a rope, but it does not guide this bodily motion in terms of any plan.

We might worry about how to apply this account to some very short action; how exactly does one guide the letting go of a rope once one has let go? And couldn't one change one's mind almost immediately, and so never actually guide the action after it is initiated, and yet have intentionally acted for the brief period of time preceding the change of heart? But there is a more important worry here. Let us start by asking what is meant by guidance in this account. It must be something more than just a requirement **(p. 219)** that the disposition persist in causing behavior over time. After all, the trembling climber, whose mountain-climbing looks increasingly ill-advised, could well be so nervous that his hands tremble for a prolonged period of time, thus ensuring that he cannot grab the rope

once it has begun to slip from his grasp. We can add a feedback mechanism to this example as well. Perhaps the realization that he is dropping the rope makes his desire to be rid of the weight more vivid, which in turn increases his nervousness, and this is what causes the trembling to continue. This is still a case of deviant causation, so Setiya must hold that this is not sufficient for the climber to count as having his trembling be guided by the goal of ridding him of the weight of the other climber.

We need the notion of guidance to be more robust. Setiya does not offer an explicit account, saying "sustained causation of a process toward a goal is not unique to intentional action: it is present in purposive behaviour that is not intentional. So although it is something of which we lack an adequate theory, there is no circularity in taking it for granted here" (Setiya 2007: 32). It is true that there is no circularity; but even if we take for granted some understanding of sustained causation toward a goal, it is far from clear that we can use it to draw some kind of deviant/non-deviant distinction, or that it will track the relevant distinction for intentional action. When the heart pumps blood to various organs, for example, it not only initiates but also sustains this process. However, it is still possible for this kind of sustained causation to admit of a difference between deviant and non-deviant forms of causation. A case in which one's heart "malfunctions" but fortuitously still causes blood to be pumped, even if such "malfunction" continuously causes blood to be pumped, will be a case of deviant causation. It would certainly be a case of deviant causation, and not of the right kind of sustained causation, if, for instance, the cells in my heart stopped beating in unison and instead began to beat in a complicated musical harmony with one another—a musical harmony that alien observers found pleasant and which therefore caused them to use their advanced technology to circulate blood through my body in order to continue enjoying the beat. My heart would still be sustaining the circulation of blood through my body, but this would be a highly deviant causal chain; my heart would not be instantiating its function of pumping blood or be performing its characteristic activity. Thus, the deviant/non-deviant distinction here is not accounted for in terms of whether or not we have sustained causation toward a goal. Of course, one might deny that such fortuitous "malfunction" cases count as cases of sustained causation toward a goal, exactly because the heart is not pumping blood in the right way. But, absent a more principled account of what the "right way" consists in, this response would risk explaining sustained causation in terms of non-deviance rather than the other way around.

One might hope that a principled account of the right sort of causation will be provided by another area of philosophy. For example, to provide an evolutionary explanation of the development of the heart, we might need to appeal to sustained causation toward a goal, and differentiate deviant from non-deviant versions of this form of sustained causation. However, even if this is true, it isn't clear that Setiya can help himself to just any such account of sustained causation in answering the issues arising in philosophy of action. It is plausible that the account of sustained causation in evolutionary **(p. 220)** biology will appeal to the evolutionary history of the organism. Perhaps the heart pumps blood non-deviantly when it pumps blood via causal mechanisms that are typical of the heart's evolutionary history. The problem is that there could be causal processes involving desire–belief pairs that were selected for, and thus non-deviant from the point of view of natural

teleology, but that were no less deviant from the point of view of intentional explanations.5 For example, perhaps an agent is so constituted that whenever they desire to avoid a predator and believe that they could do so by falling to the ground, all of their muscles are paralyzed and they fall to the ground. This might be a case of "sustained causation" such that, as long as the belief is occurrent, the effect still holds, and the agent's muscles continue to be paralyzed; and it is evolutionarily selected for a goal, avoiding the attention of predators. This tendency could well have been evolutionarily due to precisely this function; but even if it were, it would not render the causation any less deviant from the point of view of action explanation. In sum, it is far from clear that we can solve the problem of deviant causation even if we help ourselves to a notion of sustained causation available in the context of natural teleology; it is not clear how sustained causation can single out the cases in which *the agent* was being *guided* by her reasons to act, except by adding something like "the right kind of sustained causation."

The difficulty of resolving deviant causal chain worries suggests that this is no minor technical issue, but reflects some deeper feature of the explanation of action. David Velleman argues that what is missing is from the standard causal account of action is that "[i]n this story, reasons cause an intention, and an intention causes bodily movements, but nobody—that is, no person—*does* anything. Psychological and physiological events take place inside a person, but the person serves merely as the arena for these events: he takes no active part" (Velleman 1992: 461). In fact, this problem with causal accounts point to a tension for any account of action explanations that arises from the very intuitive idea that intentional actions are such that an *agent* is guided by *her reasons* to act.

We can separate two independent problems that the possibility of deviant causal chains raise for standard causal theories of actions. First, it raises doubts about whether the causal theory of action succeeds as a *reductive* account of intentional action; the need to appeal to "causation in the right way" suggests that the reduction failed. We will call this problem the "proper problem of deviance," or "the problem of deviance" for short. Second, they raise doubts about whether, at least on its own, the standard causal theory can succeed as an *account of* intentional action, or whether it leaves out an essential aspect of intentional agency; whether it can explain how agents are not only moved by their reasons but guided by them. Standard causal theories do a good job in capturing how the agent's reasons are involved in her action, but then they have difficulty explaining the role of the agent; in Velleman's words, the agent seems to take "no active **(p. 221)** part" in the action. Standard agent-causal theories suffer from the opposite problem. Even if we ignore metaphysical qualms about agent causation, theories in which the agents' causal powers are not determined by the causal powers of mental states such as belief, desires, and intentions will have a problem explaining how the fact that (I believe that) x is a reason to Φ is relevant to the explanation of my behaviour.6 We will call this "the problem of guidance."

In the next section, we will show more precisely how attempting to capture this form of agential involvement creates a dilemma for theories of action explanation, and that this dilemma is not restricted to causal theories, but is a problem for all theories of action ex planation. We then propose a specification of how an agent must be present in an action for it to count as an action, and thus a suggestion as to what causal theories may be missing as well as what they are getting right.

## **9.3 Being Guided by Reasons**

We have suggested that the possibility of deviant causal chains is due to the absence of the agent him- or herself from the production of the action; causal theories take the agent to be *responding* to reasons, but can't explain how the agent is *guided* by reasons. The action must not just be a response to the agent's reason; the reason must guide the agent. As Korsgaard puts it:

Neither the joint causal efficacy of the belief and the desire, nor the existence of an appropriate conceptual connection between them, nor the bare conjunction of these two facts, enables us to judge that a person acts rationally. For the person to act rationally, she must be motivated by her own recognition of the appropriate conceptual connection between the belief and the desire. We may say that she herself must combine the belief and the desire in the right way. (Korsgaard 2008: 63)

It is worth comparing this concern with the issues that philosophers inspired by Frankfurt's seminal work (1971) have raised. If the desire that causes the agent to act is not one that the agent identifies with, the action will not be full-blooded, or autonomous, or fully intentional. We need to identify a motive that, when it is involved in the production of action, constitutes the agent's active participation in the action. But what kind of motive could do this job? For any candidate motive, we might worry that the agent might find themselves alienated from this form of motivation, and hence this motive would not represent their agency in that instance. Velleman characterizes the issue, roughly, as trying to find a mental state such that when it acts, the agent acts (Velleman 1992). The problems might seem quite different, but we can see that these are similar worries about the role of the agent in a purely causal understanding of intentional action: Korsgaard is **(p. 222)** concerned that rational agency requires that the *agent herself* "must combine the belief and desire," while Velleman is concerned that we find a motive whose presence in action guarantees that the agent herself is active in the production of the action.

One possible solution to the issue of both agent involvement and guidance by reasons is to identify a constitutive aim of agency or form of agency. In a nutshell, we had difficulties understanding how merely responding to reasons could count as proper agency. But perhaps there is a way of responding to reasons whereby when we respond to a reason in this way, we are thereby acting. For instance, if seeking to maximize utility is constitutive of agency, then one can think that if one is responding to a reason because (one takes it that) responding to this reason maximizes utility, one is thereby acting. The presence of this motive will ensure the agent's active participation in the production of the action, since the motive will be constitutive of agency; the agent is not a passive observer of her

actions, for there is no conceptual distance between the motive producing the action and the action being brought about by the agent herself.7

Velleman suggests a candidate motive, that of making sense of our own actions, but we can also see other theories of agency as providing similar, though often non-reductive, accounts. For example, theories of agency that endorse the "guise of the good" thesis hold that for something to be an intentional action it must be motivated by something like an agent's "take" on the good (cf. Davidson 1980, 8 Raz 2002, Tenenbaum 2007). "Guise of the good" theories thus hold that the motive of doing good is constitutive of agency.

Such theories have additional resources to resolve the problem of deviance. Davidson's climber lets go of the rope under the causal influence of a relevant belief and desire. However, perhaps the explanation of the fact that this fails to be an intentional action is that the further motive constitutive of agency is absent from the causal story. For example, the motive of doing what is good does not seem to have any causal impact on this behavior. If the climber judged it good to let go of the rope, and this judgment causally contributed to his letting go of the rope, then perhaps we have a case of action after all. Or perhaps what is missing is the causal influence of a motive to satisfy as many of one's desires as can be mutually satisfied. Where such a desire to be causally efficacious, it would mean that the agent judged that dropping the rope would contribute to satisfying as many of one's desires as possible, and perhaps this is sufficient to render it an action. Of course, the details of this strategy will depend on what motive or aim we take to be constitutive of agency, or what we take to constitute the form of agency. But accepting some such motive offers us a promising route to addressing the worry of **(p. 223)** deviant causal chains, by providing a role for the agent's active participation in the production of the action.

This solution won't on its own resolve the problem of deviant causal chains. Even if we add a further motive that is constitutive of agency, there could be further intervening states between this motive and action. Let us take for instance the constitutive motive in Velleman's early account—namely, the motive of self-understanding. There could, it seems, be a case in which the motive of self-understanding is causally relevant and yet the action is still generated in a circuitous manner. Still, this strategy might provide additional resources for a solution to the problem. Perhaps the counterintuitiveness of counting some cases of deviant causal chains as actions could be shown to derive from suspicions about guidance, rather than causation per se. One might insist that as long as the motive causes and maintains the action (and satisfies whatever other conditions the theory imposes), then we have a genuine case of intentional action. But even if this strategy is not successful, the constitutive aim seems to address at the least the problem of guidance. As Velleman argues, even among cases in which the belief and desire causes the action in ways that are otherwise non-deviant, we can still have cases in which we have something that falls short of "full-blooded" intentional action, exactly because the agent is not in control of how her desires are issuing in action.9

However, in addressing this problem, this approach brings with it new challenges. We must determine how the motive that is posited fits into the agent's reason for acting. An advantage of the causal account of action, recall, was that it allowed us to determine the agent's reason for acting from all of the possible motivations that might have been at work. On the current account, however, the key role is played by the motive constitutive of agency. After all, it is the contribution of this motive that transforms a bodily motion into an action. Thus, the agent's reason for action seems to be given by this constitutive motive, and is the same for every action. Take as an example the view that the motive of doing good is constitutive of agency. Then it is the belief that the action is good combined with this motive that renders any bodily motion an action. Thus, it seems that our reason for acting is the same for every action—the goodness of the action.

This position seems to have a number of implausible consequences. An obvious problem with this view is just that we seem to act for more than one reason. What use would it be to ask someone why they did something if the answer would always be the same? (Cf. Korsgaard 2008.) A related but more serious problem for this view is that it renders agents problematically self-absorbed. Consider the view that the constitutive motive is the motive to do what is good or what one has sufficient normative reason to do. In that case, the agent's reasons for action always include that the action would be good or that one has sufficient normative reason to do. The problem is that, on this account, it seems that an agent always thinks "one thought too many," to use Bernard Williams' terminology (1981). The account seems to imply that no one ever jumps **(p. 224)** into the pool to save their drowning child for the reason that "my child is drowning." They must always take the further cognitive step and act on the reason that "saving my drowning child would be good." Douglas Lavin terms this "the problem of narcissism" (Lavin 2011).10 The problem is that on this account of agency we are narcissistically focused on the goodness of our own actions. We seem to care more about the goodness of our actions than we do about the well-being of our friends and family, the outcomes of our projects, or the suffering of those we aid. We seem to face a dilemma here. If we focus on the reasons for which the agent acts, and take them to be the primary explanans of the action, we run against the problem of guidance; it is not clear how the agent is being *guided* by the reasons, or how the agent is involved in the action. If we focus on the features that can potentially explain the involvement of the agent, such as a constitutive motive, we run up against the problem of narcissism.

Of course, the dilemma is not an artifact of choosing the motive of pursuing the good as the constitutive motive. The situation is no better if we consider other putative constitutive motives. On Velleman's suggested motive in his earlier work, that of self-understanding, agents end up narcissistically obsessed with the state of their own self-understanding, which is surely no better than being fixated on the goodness of one's actions. Even if the constitutive aim is to maximize utility or act on the strongest desire (or set of desires), we face a similar problem. On this view, our reason for acting on a given desire is not the content of the desire, but the fact that it allows us to satisfy our strongest desire; the father who jumps into the water to save his child does for the reason that doing so al

lows him to satisfy his strongest desire, rather than for the reason that his child is drowning.

Moreover, the challenge is not restricted to theories that postulate a constitutive aim or form of action, but includes any theory that distances itself from the model of understanding agency as a direct response to reasons. As we have said, the main advantage of the standard causal account is in explaining how the action is sensitive to reasons. A similar problem seems to be faced by, for instance, George Wilson's account of intentional action and action explanation (Wilson 1989). According to Wilson, an intentional explanation does not posit a causal relation between a desire and an action (or more generally between motivating reason and cause). Instead, locutions such as the following express an irreducible form of rational teleology:

Wilson claims that this is what explanations by reasons is, and the fact that this is supposed to be a form of rational teleology guarantees that 'ψ-ing' is the motive or the reason why the agent acted. But this account makes it difficult to understand the relation between the action and the putative normative reasons that would justify such an action. Given that there is no causal relation between the action and the agent's motivational state, it is not clear how the action could be responsive to the "good-making" or **(p. 225)** "reason-making" features of the action. Although we can say that, for instance, Jane gave a ride to Louis in order to help someone in need, it is not clear how we can say that Jane is *responding* to the good-making feature of the action.11

But perhaps the constitutive motive strategy can avoid our dilemma. The advocate of this strategy could argue that ordinary motives and constitutive motives play different roles in action explanation. In other words, one could argue that while the constitutive motive is indeed present in all our actions and plays a crucial role in rationalizing action, it does not do so by being an extra reason for acting. We want to preserve what we ordinarily take to be our reasons for acting, while still finding a way of explaining how the agent is *guided* by the reason, rather than just being the locus of the causal interaction between an external fact and movement of her body. There are three basic ways of doing this. First, one could argue that the constitutive aim of action is not "the" reason we act for, but it is an extra motive, added to the other motivating reasons. This is arguably Velleman's strategy in his early work (1992). The other is a strategy employed by a number of advocates of the "guise of the good," which we shall call the "attitude strategy": the constitutive aim of action is not part of the content of the relevant attitude but is constitutive of what the attitude is. The idea is not that attitudes that figure in the explanation of action, such as intentions and desires, have "good" as part of what is represented in the attitude. Rather it is that in *having* these attitudes, irrespective of their content, one aims at the good.12 This would give the constitutive aim of the action a quite different role than the reasons for action. This is essentially the strategy followed by one of us (Tenenbaum 2007, 2008, 2012) and Karl Schafer (2013). Finally, one can try to understand the nature of the attitudes in question such that they explain what it is to be guided

by a reason while not committing oneself to agency having any constitutive aim, or such that the agent is pursuing anything other than the object of her reason. Thus there is no competing aim or end to displace what we ordinarily take to be the reason for action. This is essentially the strategy implicit in Setiya's work (2007). We will briefly discuss the first and third option, and then try to explain the motivation for the middle option in the next section.

Let us begin with the first option, embodied in Velleman's invocation of the desire for selfunderstanding as a necessary element in explaining action in his earlier work. Velleman does seem to provide a way in which the constitutive aim of action plays a role in the production of action while preserving at the same time a sense in which the agent is responsive to the actual reasons. Without the participation of the motive of self-understanding, our bodily motions would not count as actions. But without the other sundry motives that move us to act, the motive of self-understanding would have nothing with which to work. We understand ourselves, according to Velleman, by ensuring that the motivations that best fit our self-understanding are the ones that **(p. 226)** move us to action. Without other motivations to favor or suppress, the motive of self-understanding would be empty. Thus, on Velleman's account, there is clearly a causal role for the ordinary desires that we take to establish our reasons for action, and hence for our responsiveness to our ordinary reasons for action.

However, it is not clear that Velleman can escape the charge of narcissism by merely adding a role for ordinary reasons for action. After all, even if we make room for both ordinary desires and the desire for self-understanding, both desires still seem to be playing the same type of causal role. If the desire to help the poor and the desire for self-understanding play the same role in the etiology of action, it seems that the right answer to the question "Why did you give Louis a ride?" is "Because Louis needed help *and* because if I did anything else my self-understanding would be compromised." The fact that the constitutive aim is now alongside the reason to help is unlikely to be much consolation; when the worry is that one's description of agency adds "one thought too many," adding yet more thoughts (or more roles to other thoughts) is unlikely to be the answer.

There are differences between the motive of self-understanding and our ordinary reasons for action; and a defender of a position like Velleman's could argue that this motive is sufficiently distinct in its operation that it ought not to be considered a reason for which we act. For instance, since it is by the participation of this motive that other considerations become reasons for which an agent (full-bloodedly) acts, and since it seems senseless to say the motive participates in itself, it would be inaccurate to call the constitutive motive itself a "reason." However, the challenge for one who wishes to pursue this strategy is to show how this move is more than a verbal stipulation. If the motive of self-understanding plays the same etiological role in bringing about action as do our ordinary reasons for action, and it contributes in an important way to rationalizing the action so brought about, it seems to be fulfilling all of the functions of the agent's reason for action. Thus, what we need is an explanation of why this further motive is not an instance of the problematic "extra thought."

A possible alternative approach is to reject the idea that the agent's responsiveness to their reasons is embodied in a motive or goal at all. Instead, it may merely be a requirement that a certain sort of internal structure be present. For example, Kieran Setiya, in his account of what it is to act for a reason, rejects what he calls "teleological accounts" of acting for a reason. On Setiya's account of acting for a reason, we begin with the traditional belief–desire pair. This, however, is not yet enough to make the resulting behavior a case of acting for a reason. We must add a further mental state, a hybrid state that combines a cognitive component with a motivational component. This mental state is reflexive —it has as its content "that one is *hereby* doing φ because of the *belief* that P" (Setiya 2007: 46). Acting for a reason is a representation of one's action as being caused both by itself and by the belief that P. The motivational component is similarly twofold. On the one hand, the attitude itself contributes motivationally to the production of the action. On the other hand, it also enables the motivational contribution of the belief that P. As Setiya puts it, "it is only when I *take* the fine weather as my reason for walking that **(p. 227)** my belief about the weather causes me to walk; until I do so, its causal power is muted. So taking something as my reason for doing φ is desire-like not only in causing my action, but in causing it to be caused by the relevant belief" (Setiya 2007: 43).

Let us leave aside our earlier concerns with whether Setiya's view can avoid the problem of deviance, and focus on whether it escapes both horns of our dilemma. At first, it does appear to succeed. The desire–belief attitude seems to show how the agent is guided by her reason and involved in the action without displacing the agent's reason for action. It is not an alternative goal or feature of the action that makes it the agent's own—instead, the missing feature is a reflexive self-awareness of the sources of one's own motivation. However, it does so by introducing two "becauses" in the explanation of the action; the agent acts because of the desire-like belief but also because of the specific belief that p. But it is not clear how this is possible; how it is possible for the desire-like belief to both cause my action and cause it "to be caused by the relevant belief"?13 Although obviously there are cases in which something causes a causal relation to obtain (when, for instance, I fix my computer so that typing "t" will now cause a "t" to appear in the screen), these typical cases seem very different from the relation being proposed here. The causal relation posited here is at the very least obscure. It seems that the dilemma is resolved by stipulating that, rather than explaining how, the two states make distinct contributions to the explanation of the action.

These are hardly conclusive arguments against views such as Velleman's and Setiya's. But we hope they at least give us some motivation to look into the views of second kind in more detail.

## **9.4 Action Explanation, Guise of the Good, and Reasons**

The most clearly developed examples of the attitude view arise in the context of theories of action that accept the guise of the good thesis, or "scholastic" views. According to such theories, action requires seeing the object of the action or desire as something that is in some way good. There are two kinds of scholastic theories (Tenenbaum 2007). On the first kind of view, "good" is part of the content of the practical attitude in question (Oddie 2005),14 or of another attitude, such as a belief, that is a necessary condition for having a certain practical attitude or for intentional action (Raz 2010). For instance, it may be part of the attitude of intention that the action intended is good in some way. On the second kind of view, "good" is not—at least not necessarily—part of the content of the attitude (Tenenbaum 2007, 2008, 2012, Schafer 2013). According **(p. 228)** to the second view, it is part of the nature of the practical attitude that in *having* the attitude one somehow judges the object of the attitude to be good, or is presented with its object as good, but that this judgment is not a part of the content of the attitude. We will be discussing only the second kind of view, as it has a decided advantage for our purposes.15

The upshot of section 9.3, recall, was that we wanted to identify a constitutive aim or form of agency, in order to account for the agent's active participation in the production of action. The problem is that adding such a constitutive aim seemed to put us on the second horn of our dilemma; if our view implies that the agent's reason for acting is always given by the constitutive aim of action, we face the problem of narcissism. However, if the constitutive aim of the attitude is not part of the content, then the agent could be guided by the aim without representing it. Instead, just in virtue of having formed the requisite attitude, the agent will already have been implicitly guided by the aim in question. On this proposal, when I act on the reason that someone needs help, I don't act also on the reason that I must conform my action to the normative reasons, or the reason that I must do what is good. In intentionally φ-ing, I thereby take φ-ing to be good or something that I have normative reason to do (for the reason I φ-ed). This is not a further judgment or attitude alongside my intentionally φ-ing; it is just part of what it is to φ intentionally. But this proposal also avoids the problem of guidance. In φ-ing for a certain reason I am not merely passively reacting to a certain fact or content of a desire but I am also active: I am *taking* φ-ing to be good.16

But how exactly can taking something to be good (or taking it to be a normative reason for action) be part of the nature of an attitude? We cannot give a full answer to this question here, but we hope at least to show that there is very good reason to think that this is a feasible option that should be taken seriously.

Let us start by taking a case that seems to be analogous (and that defenders of the "guise of the good" view have explicitly put forward as a fruitful analogy; see Tenenbaum 2007, 2012 and Schafer 2013): the relation between belief and truth. There is no question that "true" is not part of the content of every belief; it is not the case that if I believe that p,

the real content of my belief is "p is true." This would be a picture of belief that is every bit as unintuitive as the narcissistic account of our reasons for action. However, there seems to be an important connection between an agent believing that p and that agent accepting the truth of p; the connection is generally referred to in the claim that "belief aims at the truth." We can think of the attitude view as claiming that a similar relation holds between intention (or action) and good.

**(p. 229)** It is a matter of great controversy what exactly the nature of the relation is between belief and truth (see e.g. Velleman 1992, Wedgwood 2002, Shah and Velleman 2005, Staglich-Peterson 2006). For our purposes, a couple of points are particularly important. First, it is plausible to suppose that the relationship between belief and truth is not merely normative; that is, the relation is not exhausted by the fact that, in some sense, truth is a norm or ideal for belief.17 Let us look at a variation of Moore's paradoxical sentence: " 'It is raining' is true, but I do not believe it."18 The person who says such a thing is not just being irrational. There is nothing particularly puzzling about admitting to irrationality, even ongoing irrationality; but it is not clear how this Moore-paradoxical sentence can even be asserted (for more on this point, see Tenenbaum 2012). The paradoxicality of this kind of statement seems to imply that believing is not just being in a state which is "correct" if it is true, but instead that believing just amounts, in some sense, to *holding* the content of one's belief to be true. On this view, in saying " 'it is raining' is true," the agent expresses that they hold "it is raining" true, while in denying that they believe that it is raining, they deny that they hold "it is raining" true—thus accepting the sentence is akin to accepting a manifest contradiction. John Gibbons (2013) makes a similar point about belief using the notion of commitment. Believing that P commits us to the truth of P. Thus, discovering that P is false will also mean discovering our belief that P is defective from our own point of view.19 The idea of commitment is a helpful one, since it emphasizes the way that beliefs that fail to meet this standard are defective according to the agent's own standards. However, normally I can be fully aware that I am failing to live up to my commitments; out of laziness, I might stay at home on election days even if I am committed to the importance of the democratic process, and of voting in particular. But I cannot, at least in the paradigmatic cases, be at the same time fully aware that I believe that p and that p is not true and just "feel guilty" about my failure live up to my commitment.

Although belief involves a taking of, or commitment to, P being true, this is not an aim or goal of belief in the ordinary sense; we do not form particular beliefs in order to have true beliefs. Similarly, it is not true that all reasons for belief that p are of the form "accepting p will bring it about that I have a true belief"; instead, in accepting that q is reason to believe p, one thereby accepts that one holds p to be true on the basis of q. Thus, if reasons for action work in a similar way, then our reasons for action are not **(p. 230)** necessarily of the form "Doing φ will bring it about that I perform a good action"; instead, in accepting that P is a reason to φ, one thereby takes φ-ing to be good on the basis of P.

Of course, even if we are right that this analogy with belief holds, we cannot consider that the job of the attitude view is done at this point. As we said, the relation between belief and truth is not well understood; although it is comforting to know that other areas face similar tasks to the one faced by the attitude view, noticing this comforting thought cannot replace actually engaging in the task. The full vindication of the attitude view thus depends on whether it can provide a satisfactory account of the nature of an attitude such that in having that attitude, one judges something to be good (or is presented with something as good). Here we can only outline some possible ways in one can provide such an account. The most obvious one is to think that, given the roles of these attitudes in intentional explanations, they must be seen as necessarily expressing normative or evaluative stances. We may accept, for instance, Anscombe's view that intentional explanations are answers to a particular question, "Why?" (Anscombe 1957). In Anscombe's view, not all possible contents of motivational attitudes are candidates for a proper answer to this "Why?" question. Only some of them would make either the action or the agent intelligible. If the conditions under which an answer to Anscombe's question is intelligible turn out to be that the answer allows us to understand the agent as pursuing her evaluative or normative attitudes, then we would have an argument for the conclusion that the motivational attitudes cited in the explanation express the agent's normative or evaluative views.

A similar argument can be made if we accept Davidson's view that intentional explanations (and, in Davidson's case, the mental more generally) are informed by the "constitutive ideal of rationality." On one interpretation of this view, intentional explanations place the agent's action within "the pattern of a life led by an agent who can shape her action and thought in the light of an ideal of rationality" (McDowell 1998: 35). If understanding an action as fitting into this pattern depends on seeing the agent as trying to pursue the good or act for good reasons, we would have the makings of a similar argument. A quite different strategy is pursued by Boyle and Lavin (2010). Very roughly, they defend an Aristotelian conception of animal action as pursuing the good of the animal, and argue for the claim that intentional action is an essentially self-conscious case of animal action that is, one in which one is guided by one's self-conscious understanding of the human good. On their view, "the intentional actions of a rational agent express his regarding those actions as good in a plain enough sense: for such an agent has the power to reflect on how to act, and if on reflection he does not accept that a given way of acting has at least something good about it, he will in so doing have changed his mind about whether to do it" (p. 191).

We cannot adequately pursue any of these avenues here. But the fact that this position promises to solve the problem of guidance, and that a similar position seems to be also needed in the realm of theoretical reason, gives us good reason to think that it's worth pursuing them.

## **References**

Anscombe, Elizabeth (1957). *Intention*. Cambridge, Mass.: Harvard University Press.

Arpaly, Nomy, and Timothy Schroeder (2014). *In Praise of Desire*. Oxford: Oxford University Press.

Bishop, John (1989). *Natural Agency: An Essay on the Causal Theory of Action*. Cambridge: Cambridge University Press.

Boyle, Matthew, and Douglas Lavin (2010). "Goodness and Desire." In Sergio Tenenbaum (ed.), *Desire, Practial Reason, and the Good*, 161–201. Oxford: Oxford University Press

Chisholm, Roderick (1964). "Human Freedom and the Self." In Robert Kane (ed.), *Free Will*, 47–58. Oxford: Blackwell.

Dancy, Jonathan (2003). *Practical Reality*. Oxford: Oxford University Press.

Davidson, Donald (1963). "Actions, Reasons and Causes." *Journal of Philosophy* 60(23): 685–700.

Davidson, Donald (1980). *Essays on Actions and Events*. Oxford: Clarendon Press.

Davis, Wayne A. (2010). "The Causal Theory of Action." In Timothy O'Connor and Constantine Sandis (eds), *A Companion to the Philosophy of Action*, 32–9. Oxford: Blackwell.

Frankfurt, Harry (1971). "Freedom of the Will and the Concept of a Person." *Journal of Philosophy* 68(1): 127–44.

Frankfurt, Harry (1978). "The Problem of Action." *American Philosophical Quarterly* 15: 157–62.

Gibbons, John (2013). *The Norm of Belief*. Oxford: Oxford University Press.

Korsgaard, Christine (2008). *The Constitution of Agency: Essays on Practical Reason and Moral Psychology*. Oxford: Oxford University Press.

Lavin, Douglas (2011). "Problems of Intellectualism: Raz on Reason and its Objects." *Jurisprudence* 2(2): 367–78.

McDowell, John (1998). "The Constitutive Ideal of Rationality: Davidson and Sellars." *Crítica* 30(88): 29–48.

Millikan, Ruth G. (1989). "In Defense of Proper Functions." *Philosophy of Science* 56: 288–302.

Oddie, Graham (2005). *Value, Reality, and Desire*. Oxford: Oxford University Press.

Peacocke, Christopher (1979). *Holistic Explanation: Action, Space, and Interpretation*. Oxford: Oxford University Press.

Pendlebury, Michael (2013). "Reasons in Action." *Philosophical Papers* 42(3): 341–68.

Raz, Joseph (2002). "Agency, Reason, and the Good." In *Engaging Reason: On the Theory of Value and Action*, 22–45. Oxford: Oxford University Press.

Raz, Joseph (2010). "The Guise of the Good." In Sergio Tenenbaum (ed.), *Desire, Practical Reason and the Good*, 111–37. Oxford: Oxford University Press.

Schafer, Karl (2013). "Perception and the Rational Force of Desire." *Journal of Philosophy* 110(5): 258–81.

Sehon, Scott (1997). "Deviant Causal Chains and the Irreducibility of Teleological Explanation." *Pacific Philosophical Quarterly* 78: 195–213.

Setiya, Kieran (2007). *Reasons Without Rationalism*. Princeton, NJ: Princeton University Press.

Shah, Nishi, and David Velleman (2005). "Doxastic Deliberation." *Philosophical Review* 114(4): 497–534.

Steglich-Petersen, Asbjørn (2006). "No Norm Needed: On the Aim of Belief." *Philosophical Quarterly* 56(225): 499–516.

Tenenbaum, Sergio (2007). *Appearances of the Good: An Essay on the Nature of Practical Reason*. Cambridge: Cambridge University Press.

**(p. 232)** Tenenbaum, Sergio (2008). "Appearing Good: A Reply to Schroeder." *Social Theory and Practice* 34(1): 131–8.

Tenenbaum, Sergio (2012). "Knowing the Good and Knowing What One is Doing." *Canadian Journal of Philosophy*, suppl. vol. 35: 91–117.

Velleman, J. David (1992). "What Happens When Someone Acts?" *Mind* 101(403): 461–81.

Velleman, J. David (2000). *The Possibility of Practical Reason*. Oxford: Oxford University Press.

Wald, Benjamin (2015). "Transparency and Reasons for Belief." *Logos & Episteme* 6(4): 475–94.

Wedgwood, Ralph (2002). "The Aim Of Belief." *Noûs* 36: 267–97.

Williams, Bernard (1981). "Utilitarianism and Moral Self-Indulgence." In *Moral Luck: Philosophical Papers 1973–1980*, 40–53. Cambridge: Cambridge University Press.

Wilson, George (1989). *The Intentionality of Human Action*. Stanford, Calif.: Stanford University Press.

## **Notes:**

[^1]: If only events can be cited in causal explanations, then we can reframe this explanation in terms of the event of coming to have the relevant belief and desire.

[^2]: Bishop adds some extra caveats to deal with cases where the causal chain leads through other agents; since our objection does not deal with such cases, we will not consider these additions here.

[^3]: This criticism is made in more detail in Sehon (1997).

[^4]: This account is intended to apply only to basic actions, with complex actions receiving a different treatment. We shall focus on the basic case here.

[^5]: In fairness to Setiya, his causal theory, unlike Davidson's, does not take belief–desire pairs to be the mental state that cause intentional action, but rather intentions understood as belief-like states that also motivate. However, the problem does not seem to depend on the kind of mental state in question.

[^6]: Chisholm (1964) wrestles with a similar question.

[^7]: Velleman uses this claim to support his constitutivist metaethical position, on which normative reasons are constructed out of the constitutive aim of agency. However, accepting that agency is constituted by the presence of a certain motive does not commit one to a particular metaethical position. One can adopt Velleman's suggestion about action explanation without becoming a constitutivist. On constitutivist views, see Katsafanas, Ch. 16 in this volume.

[^8]: Davidson (1980) is arguably defending a somewhat different view, but we leave these complications aside.

[^9]: See Velleman (2000: 2, 1992: 464–5).

[^10]: See also Korsgaard (2008).

[^11]: Of course, the teleological account could try to provide an explanation of reason responsiveness; our only point here is that such explanation is needed.

[^12]: Another version of the view would claim that in having the attitude we aim to be responding to normative reasons.

[^13]: See Pendlebury (2013) for a similar (and more detailed) criticism.

[^14]: This is Oddie's view for the case of desire.

[^15]: The attitude strategy is not restricted to scholastic views. As we go on to show, it is plausible that the attitude of belief is characterized by a judgment that the content of the belief is true, and alternate views could hold that the judgment embodied in desire is not that the object of the desire is good, but some other judgment, perhaps that pursuing the object of the desire is conducive to self understanding, to adapt Velleman's view. In what follows, we will focus on scholastic views for the sake of clarity. However, despite all we say here, the judgment embodied in the attitude view could be something quite different.

[^16]: Of course this would not (or least would not *obviously*) generate reductionist account; there is no guarantee that we can provide any kind of reductive analysis of the attitude in question.

[^17]: Wald (2015) presents a further argument that the relation between belief and truth is not purely normative.

[^18]: There are certain cases that this might be less paradoxical. If, for instance, the sentence of which "is true" is predicated is not in a language that the speaker can understand, but she knows it to be true through testimony, and yet she knows that "**p**" expresses a proposition she does not know, then she would be a positon to assert such a sentence. We leave these complications aside.

[^19]: Actually, Gibbons argues that the commitment of belief is stronger: in believing P we are committed to knowing that P. This will of course includes a commitment to P's being true, but it also entails that learning that our grounds for believing P are defective will likewise force us to revise our belief, just as learning that it is false will. In any case, we only need the link between belief and truth, and so we will leave aside the question of whether belief also entails that you take yourself to know that P.

--- 

# 10. Reasons and Ability

*Bart Streumer*

### **Abstract and Keywords**

This chapter argues that there can be a reason for a person to perform an action only if this person can perform this action. The chapter gives three arguments for this claim: the argument from crazy reasons, the argument from tables and chairs, and the argument from deliberation. It also discusses several replies to these arguments. The chapter rejects three alternatives to this claim, argues that four counterexamples to this claim fail, and argues that a similar claim is true of reasons for belief. It ends by showing that these claims can help us to distinguish deontic judgments from evaluative judgments.

Keywords: reasons for action, reasons for belief, ability, deontic judgments, evaluative judgments

*Most philosophers think that "ought" implies "can": they think that

(O) It can only be the case that a person ought to perform an action if this person can perform this action.

Many philosophers also think that there is a close connection between what we ought to do and what there is reason for us to do. This suggests that "reason" may also imply "can": it suggests that

(R) There can only be a reason for a person to perform an action if this person can perform this action.

In this chapter, I will defend (R). I will begin by giving three arguments for (R). I will then reject three alternatives to (R), argue that four counterexamples to (R) fail, and argue that a similar claim is true of reasons for belief. I will end by showing that these claims can help us to distinguish deontic from evaluative judgments.

## **10.1 The Interpretation of (R)**

There are different uses of the term "reason." I will use this term to mean normative reason. I will take normative reasons to be considerations that count in favor of, or count against, having an attitude or performing an action. We should take these considerations into account in rational deliberation.

**(p. 234)** There are also different uses of the term "can." When we say that there can only be a reason for a person to perform an action if this person can perform this action, this could mean that

(R1) There can only be a reason for a person to perform an action if this person would perform this action if he or she tried to perform it.

But it could also mean that

(R2) There can only be a reason for a person to perform an action if there is a historically and nomologically accessible possible world in which this person performs this action,

where a possible world is historically and nomologically accessible if and only if it has the same past and laws of nature as the actual world. Or our claim could be weaker, and mean merely that

(R3) There can only be a reason for a person to perform an action if there is a historically and nomologically accessible *or close* possible world in which this person performs this action,

where a possible world is historically and nomologically close if and only if its past and laws of nature are similar to those of the actual world.1

There is an important difference between (R2) on the one hand and (R1) and (R3) on the other. If determinism is true, the only historically and nomologically accessible world is the actual world. This means that if (R2) is true, determinism implies that there can only be reasons for us to perform actions that we are in fact going to perform. That is hard to believe. By contrast, (R1) and (R3) do not have this implication. Determinists will therefore find these claims easier to accept.

Since (R3) is a rather weak claim, I will not interpret (R) as (R3). But I will not choose between (R1) and (R2). My arguments for (R) will therefore be arguments for the disjunction of (R1) and (R2). Since this disjunction entails (R3), my arguments will also support (R3).

## **10.2 The Argument from Crazy Reasons**

I will now give three arguments for (R). The first is what we can call *the argument from crazy reasons*. 2 Suppose that Fred is a normal human being, and consider the following claims:

**(1)** There is a reason for Fred to travel back in time to prevent the crusades, slavery, and the two world wars.

**(p. 235) (2)** There is a reason for Fred to travel to the other side of the world within thirty seconds to prevent an imminent plane crash.

**(3)** There is a reason for Fred to develop medicines against all known diseases by the end of the week.

There clearly are no such crazy reasons. (R) explains why not: because Fred cannot perform the actions (1), (2), and (3) say there are reasons for him to perform. You may nevertheless reject (R). But if so, you will need to propose other restrictions on the existence of reasons in order to make it the case that there are no such crazy reasons. You could, for example, propose the following restrictions:

There can only be a reason for a person to perform an action if this person does not have to travel back in time in order to perform this action.

There can only be a reason for a person to perform an action if this person is physically capable of performing this action.

There can only be a reason for a person to perform an action if this person is intellectually capable of performing this action.

But you will then face two problems. The first is that I could keep making further claims about crazy reasons. You will then have to keep proposing further restrictions on the existence of reasons, without there being an obvious stopping point. And (R) is clearly a simpler and less ad hoc explanation of the nonexistence of crazy reasons than your ever-expanding list of restrictions. The second problem is that for each restriction you propose, I can ask:

"Why can there only be a reason for a person to perform an action if this person does not have to travel back in time in order to perform this action?"

"Why can there only be a reason for a person to perform an action if this person is physically capable of performing this action?"

"Why can there only be a reason for a person to perform an action if this person is intellectually capable of performing this action?"

To which the obvious answers seem to be:

"Because a person *cannot* travel back in time."

"Because a person *cannot* perform an action that he or she is physically incapable of performing."

"Because a person *cannot* perform an action that he or she is intellectually incapable of performing."

In other words, what explains and unifies your ever-expanding list of restrictions seems to be (R). This suggests that instead of endorsing this ever-expanding list, you should simply endorse (R).

**(p. 236)** Some opponents of (R) deny that claims like (1), (2), and (3) are false. For example, Roger Crisp thinks that there can be reasons to perform "actions which cannot in an ordinary sense be performed, such as my flying several metres through the air to avoid a charging tiger" (Crisp 2006: 43). Crisp defends this view in two ways. First, he suggests that we think that "ought" implies "can" because of "the close relation between 'ought' and emotional responses such as guilt or blame," and he claims that "the notion of a reason is quite comprehensible independently of the emotions" (pp. 42–3). But the argument from crazy reasons does not appeal to guilt or blame, and neither will my next two arguments for (R). Second, Crisp admits that his reason to fly several metres through the air "is of course largely irrelevant to deliberation," but he claims that this does not matter, since there can be reasons of which we are unaware which are similarly irrelevant to deliberation (pp. 43, 39). I will come back to this when I give my third argument for (R).

Other opponents of (R) agree that claims like (1), (2), and (3) *seem* false, but claim that this appearance is misleading. For example, Mark Schroeder (2007: 59) defends a Humean theory of reasons, according to which

For R to be a reason for X to do A is for there to be some *p* such that X has a desire whose object is *p*, and the truth of R is part of what explains why X's doing A promotes *p*.

This theory entails that there can be some very crazy reasons. For example, it entails that it can be the case that

**(4)** There is a reason for you to eat your car,

if there is some *p* such that you have a desire whose object is *p*, and if the fact that is a reason for you to eat your car is part of what explains why your eating your car promotes *p* (Schroeder 2007: 92–7). Some people can apparently eat cars.3 But Schroeder's theory implies that (4) can be true of you even if you are not one of these people.

Schroeder admits that (4) seems false, but he suggests that this claim seems false merely because it conversationally implicates that your reason to eat your car is weighty. He thinks we can cancel this implicature by saying what your reason for you to eat your car is, and by adding that this reason has very little weight. For example, we can say that

**(4*)** The fact that your car contains your recommended daily intake of iron is a reason for you to eat your car, but this reason has very little weight.

**(p. 237)** If so, we could make similar claims about (1), (2), and (3). For example, we could cancel (1)'s implicature that Fred's reason to travel back in time is weighty by saying that

**(1*)** The fact that the crusades, slavery, and the two world wars caused an enormous amount of suffering is a reason for Fred to travel back in time to prevent these events, but this reason has very little weight.

I agree that (1*) sounds less crazy than (1). But the difference between (1) and (1*) seems to me too small to ensure that (1*) is not crazy. Schroeder may think that he needs to accept the existence of certain crazy reasons because their existence is implied by his theory. But he could easily prevent his theory from having this implication by taking A to range only over the actions that person X can perform.4 I therefore continue to think that (1), (2), and (3) are false.

## **10.3 The Argument from Tables and Chairs**

A second argument for (R) is what we can call *the argument from tables and chairs.* There are no reasons for tables or chairs to perform any action whatsoever, since inanimate objects cannot perform actions. When a person cannot perform an action, this person is in the same position with regard to *this* action that a table or a chair is in with regard to *all* actions. This suggests that just as there are no reasons for a table or a chair to perform any action whatsoever, there is no reason for this person to perform this action. In other words, it suggests that (R) is true.

If you reject (R), you could offer a different explanation of why there are no reasons for tables or chairs to perform any action whatsoever. What explains this, you could say, is not that

**(1)** There can only be a reason for an entity to perform an action if *this entity* can perform *this action*,

but is instead that

**(2)** There can only be a reason for an entity to perform an action if *entities of this kind* can perform *actions*. 5

**(p. 238)** And you could then say that the argument does not show that (R) is true, since (2) does not entail (R).

But suppose that Kate cannot perform any action whatsoever. Since persons are entities of a kind that can perform actions, if (2) is true but (1) is false, there can then be reasons for Kate to perform very many actions. But Kate *herself* cannot perform any of these actions. What makes it true that persons are entities of a kind that can perform actions is only that *other people* can perform these actions. And why would whether there are reasons for Kate to perform these actions depend on whether other people can perform them? I think it should depend on whether Kate herself can perform these actions. I therefore think that we should endorse (1) rather than (2).

If you reject (R), you could also say that what explains why there are no reasons for tables or chairs to perform any action whatsoever is that

**(3)** There can only be a reason for an entity to perform an action if this entity can perform *actions*, regardless of whether this entity can perform *this* action.

As before, you could then say that the argument does not show that (R) is true, since (3) does not entail (R).

Suppose again that Kate cannot perform any action whatsoever. In that case, (1) and (3) both entail that there is no reason for her to perform any action whatsoever. But suppose next that there is a very small change in Kate's situation, such that there are now exactly two actions that she can perform. If (3) is true but (1) is false, there can then all of a sudden be reasons for Kate to perform very many actions, all but two of which she cannot perform. Why would this very small change in Kate's situation lead to this enormous change in the number of reasons there can be for her? I think that whether there is a reason for Kate to perform an action should depend on whether she can perform *this* action. I therefore think that we should endorse (1) rather than(3).

Finally, if you reject (R), you could also say that what explains why there are no reasons for tables or chairs to perform any action whatsoever is that

**(4)** There can only be a reason for an entity to perform an action if this entity can respond to reasons.

Once again, you could then say that the argument does not show that (R) is true, since (4) does not entail (R).

We respond to a reason when we perform an action that there is a reason for us to perform because we believe that there is this reason for us to perform it. What (4) adds to (3) is therefore that

**(5)** There can only be a reason for an entity to perform an action if this entity can have beliefs about reasons.

But suppose that Kate is irreversibly paralyzed but can still have beliefs about reasons. If (5) is true but (1) is false, there can then be reasons for her to perform very many actions. If Bob **(p. 239)** asks Kate to pick him up from the train station, there can be a reason for

her to pick him up, even though she cannot do this. If Susan has had an accident outside Kate's house, there can be a reason for Kate to go outside and help Susan, even though she cannot do this. Why would whether there can be reasons for Kate to perform these actions depend only on whether she can have beliefs about reasons? I think it should also depend on whether Kate can actually perform these actions. I therefore think that we should endorse (1) rather than (5).

I conclude that (1) is the best explanation of why there are no reasons for tables or chairs to perform any action whatsoever. Since (1) entails (R), this explanation supports (R).6

## **10.4 The Argument from Deliberation**

A third argument for (R) is what we can call *the argument from deliberation.* Suppose that (R) were false. In that case, when you engage in rational deliberation about what to do, you would need to take into account not only reasons to perform actions that you can perform, but also reasons to perform actions that you cannot perform. Since you know that the crusades, slavery, and the two world wars caused an enormous amount of suffering, you would then almost always have to conclude that there is most reason for you to travel back in time and prevent the crusades, slavery, and the two world wars. And you would then have to try to travel back in time to prevent the crusades, slavery, and the two world wars. This shows that if (R) were false, rational deliberation would almost always result in your trying to perform actions that you cannot perform. But rational deliberation clearly should not have such pointless results. This suggests that (R) is true.

You may think that this argument assumes the truth of consequentialism. But it does not. The argument merely assumes that rational deliberation should take into account the amount of suffering that an action would prevent, and that the larger this amount of suffering is, the more likely it should be that rational deliberation results in your trying to perform this action. That is true according to any defensible moral view.

If you reject (R), you could propose a different restriction on rational deliberation that prevents it from having such pointless results. You could, for example, propose one of the following restrictions:

**(1)** When judging which reasons there are for or against performing an action, a person should only take into account reasons to perform actions that he or she can perform.

**(p. 240) (2)** When judging which action there is most reason for him or her to perform, a person should only take into account reasons to perform actions that he or she can perform.

**(3)** A person should only try to perform actions that he or she can perform.

But if (1), (2), or (3) were true, the only reasons that could make a difference to the result of rational deliberation would be reasons to perform actions that a person can perform.7 In that case, why should we think that there are also reasons to perform actions that a person cannot perform? Part of what makes a consideration a reason for a person is that this person should take this consideration into account in rational deliberation. If a consideration cannot make a difference to the result of rational deliberation, it therefore does not seem to be a reason at all.

As we have seen, Roger Crisp denies this. He admits that reasons to perform actions that we cannot perform are "largely irrelevant to deliberation," but he claims that this does not matter, since there can be reasons of which we are unaware which are similarly irrelevant to deliberation (Crisp 2006: 43, 39). But reasons of which we are unaware merely *do not* make a difference to the result of rational deliberation. Since these reasons *would* make a difference to this result if we were aware of them, we should not deny that they exist. By contrast, if (1), (2), or (3) were true, reasons to perform actions that we cannot perform *could not* make a difference to the result of rational deliberation. This suggests that such reasons do not exist.

John Gardner also denies this. According to Gardner, if you see a man drowning in a stormy sea, there is a reason for you to rescue this man even if you cannot rescue him. But Gardner endorses a variant of (3) by saying that there is then *no* reason for you to *try* to rescue this man (Gardner 2004: 55). Why should we think that there is a reason for you to actually rescue this man, even though there is no reason for you to try to rescue him? According to Gardner, we should think this because this reason explains why you should feel "horrified at the realisation that it would be so utterly futile" to try to rescue this man, and why you should not "walk past without compunction" (pp. 55–6). But if that is what this reason explains, it seems to be a reason to feel horrified and to refrain from walking past without compunction rather than a reason to actually rescue this man.

Of course, rational deliberation should sometimes result in a person's trying to perform an action that this person cannot perform: namely, if this person does not know that he or she cannot perform this action and has the justified belief that there is most reason for him or her to perform this action.8 For example, if you do not know that you **(p. 241)** cannot rescue this drowning man and you have the justified belief that there is most reason for you to rescue him, rational deliberation should result in your trying to rescue him. But this is compatible with (R): (R) allows that if you do not know that you cannot rescue this man, you can be justified in believing that there is most reason for you to rescue him. By contrast, if (R) were false, rational deliberation would not merely sometimes but *almost always* result in your trying to perform actions that you cannot perform.

In addition to supporting (R), the argument from deliberation also suggests that

(RA) There can only be a reason *against* a person's performing an action if this person can perform this action.

For example, consider the action of producing a round square. Since inconsistent propositions entail everything, the production of a round square entails the destruction of the world. If (RA) were false, there would therefore be an extremely weighty reason against your producing a round square.9 But there clearly is no such reason. For just as reasons

to perform actions that you cannot perform cannot make a difference to the result of rational deliberation, neither can reasons against performing actions that you cannot perform. The relation between reasons and rational deliberation therefore not only supports (R), but also supports (RA).

## **10.5 Alternatives to (R)?**

Some philosophers reject (R) because they endorse an alternative to (R) that they take to be more defensible. For example, you may reject (R) because you think that

**(1)** There can only be a reason for a person to perform an action if this person *believes* that he or she can perform this action.

But suppose that Bob has the deluded belief that he is Napoleon. If Bob thinks that he can win the Battle of Waterloo tomorrow, can there be a reason for him to win this battle? Of course not. He may believe that there is a reason for him to win this battle, but that does not mean there actually is a reason for him to do this. I therefore think that (1) is not a defensible alternative to (R).

You may also reject (R) because you think that

**(2)** There can only be a reason for a person to perform an action if this person has the *justified* belief that he or she can perform this action.

**(p. 242)** But suppose that Bob's belief that he is Napoleon is justified, since he has unwittingly taken a powerful drug that makes his surroundings look like a muddy field in Belgium in 1815 and that makes the people around him look like members of the Imperial Guard. If Bob now thinks that he can win the Battle of Waterloo tomorrow, can there be a reason for him to win this battle?10 You may think there can be. But suppose that Bob asks you what there is reason for him to do tomorrow. You clearly should not answer: "There is a reason for you to win the Battle of Waterloo." Instead, you should tell him that there is a reason for him to seek urgent medical help. I therefore think that (3) is not a defensible alternative to (R) either.11

Finally, you may reject (R) because you think that

**(3)** There can only be a reason for a person to perform an action if this person has *sufficient evidence* that he or she can perform this action.

But (3) clearly faces the same problem as (2).12

More generally, we should ask the following question: why is whether a person believes, has the justified belief, or has sufficient evidence that he or she can perform an action relevant to whether there is a reason for this person to perform this action? The answer seems to be: because whether this person can *actually* perform this action is relevant to whether there is a reason for him or her to perform this action. I therefore think that instead of endorsing (1), (2), or (3), we should endorse (R).

## **10.6 Counterexamples to (R)?**

Other philosophers reject (R) because they think there are counterexamples to (R).13 Two of these examples have been given by Ulrike Heuer. In Heuer's first example, **(p. 243)** someone cannot perform an action at time t , but can perform this action at a later time t after gaining a new ability. Heuer writes: 1 2

I cannot play the piano, say. Is there, therefore, no reason for me to do it? If there was no reason to play the piano for someone who can't play it already, there would presumably be no reason to learn to play it either. Reasons for learning something require that there is a reason for doing what (as yet) one cannot do. (Heuer 2010: 237)14

But this example merely shows that (R) should be indexed to time.15 If we take "t " and "t " to refer to any two subsequent points in time, we should take (R) to say that 1 2

(R*) There can only be a reason at t for a person to perform an action at t if this person can at t perform this action at t . 1 2 1 2

What does this mean? If we interpret (R) as (R1), it means that

(R1*) There can only be a reason at t for a person to perform an action at t if this person would perform this action at t if he or she tried to perform a certain series of actions between t and t . 1 2 2 1 2

And if we interpret (R) as (R2), it means that

(R2*) There can only be a reason at t for a person to perform an action at t if there is at t a historically and nomologically accessible possible world in which this person performs this action at t . 1 2 1 2

Suppose that it would take me two years to learn to play the piano. In that case, there can be a reason for me today to play the piano in two years' time, since I can start taking lessons today that will enable me to play the piano in two years' time. And this reason can give rise to a reason for me to start taking lessons today. If we take (R) to be indexed to time, this example therefore does not refute (R).

In Heuer's second example, there is a reason at t for a person to perform an action at t , but this person then makes it impossible for him- or herself to perform this action at t . She writes: 1 2 2

A person, call her Lilly, has a reason to attend a meeting which she dreads, but she can make it impossible that she will attend by, say, locking herself into a room and **(p. 244)** throwing the key away. Is it now true that she doesn't have a reason to go to the meeting? After all, she can't. If so, it would be unclear why she has a reason not to disable herself, or to overcome the self-inflicted obstacle once it exists. (Heuer 2010: 237)16

Suppose that the meeting will start at 10.00 and finish at 10.30, and that Lilly locks herself in and throws away the key at 9.00. In that case, (R) says that after 9.00 it is no longer true that there is a reason for Lilly to attend the meeting. But if you reject (R), you cannot defensibly say that it *never* ceases to be true that there is a reason for Lilly to attend the meeting.17 Instead, you will presumably say that this ceases to be true at 10.30, since the meeting finishes at 10.30 and after 10.30 Lilly can therefore only attend the meeting by changing the past. But since Lilly locked herself in and threw away the key at 9.00, it is *already true after 9.00* that she can only attend the meeting by changing the past. This suggests that the time at which it ceases to be true that there is a reason for Lilly to attend the meeting is 9.00 rather than 10.30, exactly as (R) says.

According to Heuer, if there is no longer a reason for Lilly to attend the meeting once she has made it impossible for herself to attend it, it is "unclear why she has a reason not to disable herself" (Heuer 2010: 237). But I think this is clear: if a consideration is a reason for a person to perform an action, this very same consideration is also a reason for this person not to make it impossible for him- or herself to perform this action. For example, suppose that the reason for Lilly to attend the meeting is the fact that an important decision will be taken at the meeting. If so, this very same fact is also a reason for her not to make it impossible for herself to attend the meeting.18

Moreover, (R) allows that after 9.00 the following claims are still true:

There *was* a reason for Lilly to attend the meeting.

Because there was a reason for Lilly to attend the meeting, there was a reason for her not to make it impossible for herself to attend the meeting.

Because there was a reason for Lilly to attend the meeting, she can be blamed for not having attended the meeting.

Because Lilly did not attend the meeting, there is a reason for her to apologize and to make sure that she attends the next meeting.

**(p. 245)** Since (R) allows that after 9.00 these claims are still true, and since any defensible view has to say that there is *some* time at which it ceases to be true that there is a reason for Lilly to attend the meeting, we should conclude that after 9.00 there is no longer a reason for her to attend the meeting. I therefore think that this example does not refute (R) either.

So-called Frankfurt cases can also be regarded as counterexamples to (R).19 Suppose that Black is a powerful neurosurgeon who has implanted a device in Susan's brain that enables him to manipulate her decisions, without Susan being aware of this. Black wants Susan to kill Fred. But Black can accurately predict what Susan will decide to do, and he predicts that Susan will kill Fred all by herself, without Black having to intervene. This is in fact what happens. Since Black did not intervene, Susan seems blameworthy for having killed Fred. But she could not have avoided killing Fred, since if Black had predicted that Susan was not going to decide to kill Fred, he would have used the device in her brain to make her decide to kill Fred. This seems to show that

**(A)** A person can be blameworthy for having performed an action even if this person could not have avoided performing this action.20

And it is often thought that

**(B)** A person can only be blameworthy for having performed an action if there was a reason for this person not to perform this action.

If (B) is true and if Susan is blameworthy for having killed Fred, this implies that there was a reason for Susan not to kill Fred. But if (R) is true, there was no reason for Susan not to kill Fred, since she could not have avoided killing him. This suggests that Frankfurt cases are counterexamples to (R).21

But instead of rejecting (R), I think we should reject (A) or (B). We can reject (B) by endorsing a different claim about blame, such as the claim that

**(B*)** A person can only be blameworthy for having performed an action if this person *should have believed* that there was a reason for him or her not to perform this action.22

**(p. 246)** Since Susan was unaware of Black's ability to manipulate her decisions, she should have believed that there was a reason for her not to kill Fred. (B*) therefore allows that Susan is blameworthy for having killed Fred.

Alternatively, we can reject (A). Since Susan would not have been blameworthy for having killed Fred if Black had made her decide to kill Fred, we can say that what Susan is really blameworthy for is not simply *having killed Fred*, but is instead *having killed Fred all by herself*. 23 If that is so, Frankfurt cases do not show that (A) is false. For Susan *could* have avoided killing Fred all by herself, by not deciding all by herself to kill Fred and thereby forcing Black to use the device in her brain to make her decide to kill Fred. You may object that it makes no sense to say that Susan is responsible for having killed Fred all by herself without thereby being responsible for having killed Fred.24 If "responsible" means causally responsible, that is true, since we cannot cause X in a particular way without thereby causing X. But (A) is a claim about blameworthiness, and we *can* be blameworthy for having done X in a particular way without thereby being blameworthy for having done X. For example, suppose that I promise to read your book closely, but that I then break my promise and only read your book superficially. In that case, I am not blameworthy for having read your book, but I am blameworthy for having read your book superficially. Similarly, Susan may not be blameworthy for having killed Fred, but she may be blameworthy

for having killed Fred all by herself. I therefore think that Frankfurt cases do not refute (R) either.

Finally, R. M. Hare gives an apparent counterexample to the claim that "ought" implies "can" that may also seem to be a counterexample to (R). Suppose that my friend Bob has fallen ill and is in hospital. I could then say:

"I ought to visit Bob in hospital, but unfortunately I can't."

Similarly, I could say:

"The fact that Bob is my friend is a reason for me to visit him in hospital, but unfortunately I can't."

Does this show that (R) is false? Hare argues that it does not show that "ought" does not imply "can." He writes:

When I say "I ought but I can't", I am prescribing in general for cases like mine; I certainly think that a man in my situation ought, *if he can*, to do the act in question; but the prescription fails to apply in my case because of the impossibility of acting on it. It **(p. 247)** is as if I said "If I were able, it would be the case that I ought (full force); but since I am not able, that lets me out." (Hare 1963: 53)

Similarly, when I say that the fact that Bob is my friend is a reason for me to visit him in hospital, I am saying that this consideration is a reason for Bob's friends to visit him in hospital *if they can*. Since I cannot visit Bob in hospital, that "lets me out," as Hare puts it. You may object that this leaves it unclear why I should apologize to Bob for not visiting him in hospital. But if Bob and I both know that I cannot visit him in hospital, such an apology is mere politeness. A real apology is only required if I failed to do something I could have done, such as phoning Bob in hospital or sending him a get-well card. I therefore think that this example does not refute (R) either.

## **10.6 Extending (R) to Reasons for Belief**

If the arguments I have given show that (R) is true, similar arguments may show that

(RB) There can only be a reason for a person to have a belief if this person can have this belief.

For if (R) is the simplest and least ad hoc explanation of the nonexistence of crazy reasons for action, (RB) is likewise the simplest and least ad hoc explanation of the nonexistence of crazy reasons for belief, such as reasons for people with limited mathematical abilities to believe complex mathematical theorems. If a generalized version of (R) is the best explanation of the fact that there are no reasons for inanimate objects like tables and chairs to perform actions, a generalized version of (RB) is likewise the best explanation of the fact that that are no reasons for inanimate objects to have beliefs. And if (R) is the best explanation of the fact that rational practical deliberation should not result in a per

son pointlessly trying to do what he or she cannot do, (RB) is likewise the best explanation of the fact that rational epistemic deliberation should not result in a person pointlessly trying to believe what he or she cannot believe.

If you think that (RB) is false, this may be because you think that a reason for a belief is a consideration that is evidence for this belief, and because a consideration can be evidence for a belief regardless of whether anyone can have this belief. But I think that reasons for belief are not the same thing as evidence. Evidence for a belief often counts in favor of having this belief, but not if we are not currently attending to this evidence and forming this belief would be a waste of our cognitive resources (see Harman 1986: 12).25 **(p. 248)** Similarly, if (RB) is true, evidence for a belief often counts in favor of this belief, but not if we cannot have this belief.

You may also think that (RB) is false because our beliefs are not under our voluntary control. But "can" in (RB) need not mean "can merely by trying to do so." In other words, we need not interpret (RB) as saying that

(RB1) There can only be a reason for a person to have a belief if this person would have this belief if he or she tried to have it.

That is clearly false. Instead, we should interpret (RB) as saying that

(RB2) There can only be a reason for a person to have a belief if there is a historically and nomologically accessible possible world in which this person has this belief,

or perhaps as saying that

(RB3) There can only be a reason for a person to have a belief if this person would have this belief if he or she was aware of sufficient evidence for this belief.

You may object to (RB3) that Bob could be so irrational that he would not believe that *p* if he was aware of sufficient evidence for this belief, even though it may be true that Bob *can* believe that *p*. This objection may show that we should not interpret (RB) as (RB3). But in a similar way, Bob could be so weak-willed that he would not perform a certain action if he tried to perform this action, even though it may nevertheless be true that Bob *can* perform this action. This may similarly show that we should not interpret (R) as saying that

(R1) There can only be a reason for a person to perform an action if this person would perform this action if he or she tried to perform it.

If this objection is sound, it therefore does not drive a wedge between reasons for action and reasons for belief. Instead, it identifies a problem for conditional analyses of "can" of the kind that (R1) and (RB3) incorporate.

## **10.7 Deontic and Evaluative Judgments**

Many philosophers make a distinction between deontic and evaluative normative judgments. Deontic judgments include judgments about an action or attitude's being obligatory, prohibited, right, wrong, someone's duty, or such that someone ought or ought not to perform or have it. Evaluative judgments include judgments **(p. 249)** about something's being good, bad, or such that it ought or ought not to obtain (see Tappolet 2013).

Philosophers who think that "ought" implies "can" usually make analogous claims about other deontic judgments. For example, they also think that

A person can only have an obligation to perform an action if this person can perform this action.

A person can only be prohibited from performing an action if this person can refrain from performing this action.

A person can only have a duty to have an attitude if this person can have this attitude.

By contrast, most philosophers would not make such claims about evaluative judgments. For example, they would not say that

A state of affairs can only be good if someone can make this state of affairs obtain.

It can only be true that a state of affairs ought to obtain if someone can make this state of affairs obtain.

A character trait is bad only if its possessor can avoid having this character trait.

Why is this? If (R) and (RB) are true, it may more generally be true that

(RG) There can only be a reason for a person to perform an action or to have an attitude if this person can perform this action or have this attitude.

Now suppose that

(D) A judgment is deontic if and only if this judgment entails the claim that there is a reason for the person the judgment is about to perform the action or have the attitude the judgment is about.26

For example, the judgment that Bob has an obligation to keep his promise is deontic, since it entails the claim that there is a reason for Bob to keep his promise. But the judgment that it would be good if Bob kept his promise is evaluative, since it does not entail the claim that there is a reason for Bob to keep his promise.27

**(p. 250)** If (D) is true, deontic judgments entail the claim that there is a reason for the person these judgments are about to perform the action or have the attitude these judgments are about. And if (RG) is true, there can only be such a reason if this person can perform this action or have this attitude. By contrast, evaluative judgments do not entail this. This may explain why claims that are analogous to the claim that "ought" implies "can" seem true of deontic judgments but not of evaluative judgments.

This explanation faces two problem cases. The first is that many deontic judgments, such as the judgment that keeping one's promises is obligatory, are not about a specific person. But we can perhaps take such judgments to be about everyone *who can keep his or her promises*. These judgments could then be true even if no one could keep his or her promises, but they would then be vacuously true, in the sense that the set of people they are about is empty.

The second problem case are judgments about permissibility. Philosophers often take such judgments to be deontic, but (D) is not true of these judgments: the judgment that it is permissible for a person to perform an action or to have an attitude does not entail the claim that there is a reason for this person to perform this action or to have this attitude. But perhaps we should say that judgments about permissibility are evaluative rather than deontic. Philosophers may take these judgments to be deontic because they take them to be equivalent to certain judgments about obligations: they take an action to be permissible if and only if not performing this action is not obligatory. But these judgments may not in fact be equivalent: whereas the first judgment ascribes a normative property to an object, the second judgment may merely say that the *absence* of an object *lacks* a normative property.28 If so, judgments about permissibility are not equivalent to judgments about obligations.

## **10.8 Conclusion**

I conclude that there can only be a reason for a person to perform an action if this person can perform this action. I also conclude, more tentatively, that there can only be a reason for a person to have a belief if this person can have this belief. And I also conclude, even more tentatively, that the truth of these claims can help us to distinguish deontic from evaluative normative judgments.

## **References**

Copp, David (1997). "Defending the Principle of Alternate Possibilities: Blameworthiness and Moral Responsibility." *Noûs* 31: 441–56.

**(p. 251)** Crisp, Roger (2006). *Reasons and the Good*. Oxford: Oxford University Press.

Fischer, John Martin (2011). "Frankfurt-Type Examples and Semicompatibilism: New Work." In Robert Kane (ed.), *The Oxford Handbook of Free Will*, 2nd edn, 243–65. Oxford: Oxford University Press.

Frankfurt, Harry (1969). "Alternate Possibilities and Moral Responsibility." *Journal of Philosophy* 66: 829–39.

Gardner, John (2004). "The Wrongdoing that Gets Results." *Philosophical Perspectives* 18: 53–88.

Haji, Ishtiyaque (1998). *Moral Appraisability*. Oxford: Oxford University Press.

Haji, Ishtiyaque (2002). *Deontic Morality and Control*. Cambridge: Cambridge University Press.

Hare, R. M. (1963). *Freedom and Reason*. Oxford: Oxford University Press.

Harman, Gilbert (1986). *Change in View*. Cambridge, Mass.: MIT Press.

Heuer, Ulrike (2010). "Reasons and Impossibility." *Philosophical Studies* 147: 235–46.

Howard-Snyder, Frances (2006). "'Cannot' Implies 'Not Ought.' " *Philosophical Studies* 130: 233–46.

Kane, Robert (1998). *The Significance of Free Will*. Oxford: Oxford University Press.

Kane, Robert (2005). *A Contemporary Introduction to Free Will*. Oxford: Oxford University Press.

Kearns, Stephen, and Daniel Star (2009). "Reasons as Evidence." *Oxford Studies in Metaethics* 4: 215–42.

Kelly, Thomas (2003). "Epistemic Rationality as Instrumental Rationality: A Critique." *Philosophy and Phenomenological Research* 66: 612–40.

Naylor, Margery Bedford (1984). "Frankfurt on the Principle of Alternate Possibilities." *Philosophical Studies* 46: 249–58.

Schroeder, Mark (2007). *Slaves of the Passions*. Oxford: Oxford University Press.

Shah, Nishi (2002). "Clearing Space for Doxastic Voluntarism." *The Monist* 85: 436–45.

Sinnott-Armstrong, Walter (1984). " 'Ought' Conversationally Implies 'Can.' " *Philosophical Review* 93: 249–61.

Streumer, Bart (2007). "Reasons and Impossibility." *Philosophical Studies* 136: 351–84.

Streumer, Bart (2010). "Reasons, Impossibility and Efficient Steps: Reply to Heuer." *Philosophical Studies* 151: 79–86.

Streumer, Bart (2017). *Unbelievable Errors: An Error Theory about All Normative Judgements*. Oxford: Oxford University Press.

Tappolet, Christine (2013). "Evaluative vs. Deontic Concepts." In Hugh LaFollette (ed.), *The International Encyclopedia of Ethics*, 1791–9. Oxford: Wiley-Blackwell.

Vranas, Peter (2007). "I Ought, Therefore I Can." *Philosophical Studies* 136: 167–216.

White, Alan R. (1975). *Modal Thinking*. Oxford: Blackwell.

Widerker, David (1991). "Frankfurt on 'Ought Implies Can' and Alternative Possibilities." *Analysis* 51: 222–4.

Zimmerman, Michael (1996). *The Concept of Moral Obligation*. Cambridge: Cambridge University Press. **(p. 252)**

## **Notes:**

[^000]: For helpful comments on earlier versions of this chapter, I am grateful to Samuel Asarnow, Alex Gregory, the participants in my Spring 2013 graduate class at the University of Reading, and audiences at Eindhoven University of Technology, the University of Groningen, the Fourth Annual Dutch Conference on Practical Philosophy, and the 2013 Saint Louis Annual Conference on Reasons and Rationality. I am especially grateful to Daniel Star for discussion and comments on this chapter.

[^1]: In (R2) and (R3), I use "this person" to mean "this person or his or her counterpart."

[^2]: I gave earlier versions of this argument and my next two arguments in Streumer (2007).

[^3]: The French entertainer Michel Lotito is said to have eaten a Cessna 150 airplane by cutting it up into very small pieces. Presumably he could have eaten a car as well.

[^4]: If Schroeder took A to range only over the actions that X can perform, however, this would not fully solve what he calls the "too many reasons problem" (2007: 84–7). He would still need to solve this problem by saying that the claim that there is a reason for X to do A conversationally implicates that this reason is weighty.

[^5]: I use the term "entity" to cover both inanimate objects and persons.

[^6]: According to Ulrike Heuer, the argument from tables and chairs is ultimately "just the argument [from crazy reasons] under a different guise" (2010: 240). But there is a clear difference between these arguments: whereas the argument from crazy reasons says that there are no reasons of a certain kind and suggests that (R) is the best explanation of the nonexistence of these reasons, the argument from tables and chairs says that there is a difference between agents and non-agents and suggests that (R) is the best explanation of this difference.

[^7]: Alternatively, you may make the more general claim that the less likely it is that a person will successfully perform an action, the less likely it should be that this person's rational deliberation results in his or her trying to perform this action. Like (1), (2), and (3), this claim also entails that the only reasons that can make a difference to the result of rational deliberation are reasons to perform actions that a person can perform.

[^8]: Kearns and Star (2009: 236) give an example of this kind. They suggest that in such cases there is a reason for you to perform the action that you cannot perform, since when you realize afterwards that you could not perform this action it still seems natural to say that there was a reason for you to perform it. But I doubt this. It seems more natural to say that you were right to *think* that there was a reason for you to perform this action, but that in fact there was no such reason because you could not perform this action.

[^9]: I owe this point to Roy Sorensen.

[^10]: You may object that since Bob is hallucinating, when he uses the phrase "the Battle of Waterloo" he does not refer to the actual Battle of Waterloo. But this does not matter. For the purpose of the example, we can stipulate that we are using the phrase "the Battle of Waterloo" to refer to whatever it refers to when Bob uses it.

[^11]: You may think that you should not answer "There is a reason for you to win the Battle of Waterloo" because this conversationally implicates that this is Bob's strongest reason, whereas in fact there is a much stronger reason for him to seek urgent medical help. But it would clearly also be strange to answer: "There is some reason for you to win the Battle of Waterloo, but there is more reason for you to seek urgent medical help."

[^12]: If you follow Kearns and Star (2009) in thinking that reasons for a person to perform an action are evidence that this person ought to perform this action, you may say that there can be a reason for Bob to win the Battle of Waterloo, since if he is sufficiently deluded there can be (misleading) evidence that he ought to win this battle even though he cannot actually win this battle. But this would commit you to telling Bob that there is a reason for him to win the Battle of Waterloo, which strikes me as implausible.

[^13]: If these examples are counterexamples to (R), they are also counterexamples to the claim that "ought" implies "can." For exhaustive and compelling answers to purported counterexamples and other objections to the claim that "ought" implies "can," see Vranas (2007).

[^14]: Heuer draws a general distinction between what she calls "derivative reasons," which exist only because of the existence of other reasons, and what she calls "non-derivative reasons" (p. 236). She claims that her reason to learn to play the piano is a derivative reason. I discuss Heuer's arguments in Streumer (2010).

[^15]: It has often been pointed out that the claim that "ought" implies "can" should similarly be indexed to time. See Zimmerman (1996) and Vranas (2007: 171).

[^16]: Such examples have often been put forward as counterexamples to the claim that "ought" implies "can." See e.g. White (1975: 149) and Sinnott-Armstrong (1984). For responses, see Zimmerman (1996: 97–100), Haji (2002: 47–9), Howard-Snyder (2006: 235– 6), and Vranas (2007: 175–82).

[^17]: See Vranas (2007: 176–7, 201 n. 10). Of course, if you want to reject (R), you could dig in your heels and say that this never ceases to be true. But that strikes me as very implausible. Does it remain true hundreds of years from now, after Lilly has died, that there is a reason for her to attend the meeting?

[^18]: Heuer also writes that if there is no longer a reason for Lilly to attend the meeting once she has made it impossible for herself to attend it, it is "unclear why she has a reason [ . . . ] to overcome the self-inflicted obstacle once it exists." But this example can only be a counterexample to (R) if Lilly cannot overcome this self-inflicted obstacle. If (R) is true, there is therefore no reason for Lilly to overcome this obstacle.

[^19]: Examples of this kind were first given by Frankfurt (1969). For a brief overview of the extensive literature about them, see Fischer (2011).

[^20]: This is the negation of what Copp (1997) calls the "blameworthiness reading" of Frankfurt's principle of alternate possibilities.

[^21]: Widerker (1991) and Copp (1997: 445) show that (A), the claim that "ought" implies "can," and a claim that is analogous to (B) are an inconsistent triad. The same is true of (A), (B), and (R). For discussion, see Haji (2002: 36–58).

[^22]: Haji (1998) proposes a view along these lines. Copp (1997: 448) criticizes it.

[^23]: This point is made by Naylor (1984), though she puts it in terms of responsibility rather than in terms of blameworthiness. Copp (1997: 444) similarly denies that the person in a Frankfurt case is blameworthy for the action he or she performs, and adds that this person "may deserve blame for something else," such as "permitting herself to be the kind of person" who would perform an action of this kind. For critical discussion of such views, see Fischer (2011).

[^24]: See Kane (2005: 85) and Kane (1998: 41–2).

[^25]: Kelly (2003: 625) claims that when I "stumble upon strong evidence" for a trivial or useless belief, there is a reason for me to have this belief. I think this is plausible only because I am then attending to this evidence.

[^26]: This is compatible with the existence of false deontic judgments: deontic judgments entail the claim that there is a reason for the person the judgment is about to perform the action or have the attitude the judgment is about, but if the judgment is false this claim may be false as well.

[^27]: Of course, the judgment that it would be good if Bob kept his promise may conversationally implicate that there is a reason for him to keep his promise, especially if we express it in Bob's presence. But unlike a relation of entailment, this conversational implicature can be cancelled.

[^28]: In that case, the judgment that not performing an action is not obligatory conversationally implicates that this action is permissible. I say more about this in Streumer (2017).

--- 

